{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b08343",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_file_data(file_path):\n",
    "    file = open(file_path)\n",
    "    data = json.load(file)\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "def lookup_table(data):\n",
    "    lookup_dict = {}\n",
    "    for temp in data:\n",
    "        lookup_dict[temp['id']] = temp\n",
    "    return lookup_dict\n",
    "\n",
    "def write_to_file(file_path, data):\n",
    "    with open(file_path, \"w\") as outfile:\n",
    "        json.dump(data, outfile, indent=4)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    data1 = get_file_data('data/layer1.json')\n",
    "    data2 = get_file_data('data/layer2.json')\n",
    "\n",
    "    lookup = lookup_table(data1)\n",
    "    partition_map = {'train':0, 'test':1, 'val':2} \n",
    "    text_data, image_data = [list(), list(), list()], [list(), list(), list()]\n",
    "    for row in data2:\n",
    "        if row['id'] in lookup:\n",
    "            text = lookup[row['id']]\n",
    "            image = row\n",
    "            image['images'] = [i['id']for i in row['images']]\n",
    "            partition = partition_map[text['partition']]\n",
    "            text_data[partition].append(text)\n",
    "            image_data[partition].append(image)\n",
    "\n",
    "    partition_map = ['train', 'test', 'val']\n",
    "    for idx, text in enumerate(text_data):\n",
    "        file_path = 'data/' + partition_map[idx] + '/text.json'\n",
    "        write_to_file(file_path, text)\n",
    "    for idx, images in enumerate(image_data):\n",
    "        file_path = 'data/' + partition_map[idx] + '/image.json'\n",
    "        write_to_file(file_path, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4f7eb",
   "metadata": {},
   "source": [
    "# Image Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecdce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle\n",
    "\n",
    "# making sure that the whole embedding tensor is printed in output\n",
    "torch.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ab717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure the feature extraction runs on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "last_layer = model_conv._modules.get('avgpool')\n",
    "\n",
    "# transforming each image\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.CenterCrop((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# test_dataset = MyDataset(\"D:/Projects/ML Project/test/\", \"E:/data/test/image.json\", data_transforms)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c03ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function that hooks to the layer before the FCN in ResNet and extracts the output embedding from it\"\"\"\n",
    "\n",
    "def get_vector(img):\n",
    "    my_embedding = torch.zeros(2048)\n",
    "    \n",
    "    def copy_data(m, i, o):\n",
    "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
    "\n",
    "    h = last_layer.register_forward_hook(copy_data)\n",
    "    model_conv(img)\n",
    "    h.remove()\n",
    "\n",
    "    return my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file containing preprocessed image and text data\n",
    "# file path to be changed for different embeddings\n",
    "\n",
    "test_file = open('E:/data/test/image.json')\n",
    "test_data = json.load(test_file)\n",
    "test_file.close()\n",
    "output = []\n",
    "\n",
    "# feature extraction logic\n",
    "for row in test_data:\n",
    "    id = row[\"id\"]\n",
    "    for image in row[\"images\"]:\n",
    "        image_path = \"D:/Projects/ML Project/test/\" + image[0] + \"/\" + image[1] + \"/\" + image[2] + \"/\" + image[3] + \"/\" + image\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        transformed_image = data_transforms(img)\n",
    "        emb = get_vector(transformed_image.unsqueeze(0))    \n",
    "        \n",
    "        # store embedding as (id, image_file_name, embedding)\n",
    "        output.append((id, image, emb))\n",
    "        \n",
    "        if len(output) % 1000 == 0:\n",
    "            print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(output, \"E:/test_emb.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73526b3",
   "metadata": {},
   "source": [
    "# Text Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE FILENAME HERE\n",
    "test_file = open('E:/data/train/text.json')\n",
    "test_data = json.load(test_file)\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7608c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonDataset(IterableDataset):\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    def __iter__(self):\n",
    "        for row in self.file:\n",
    "            id = row[\"id\"]\n",
    "            title = row[\"title\"]\n",
    "            ingredients = row[\"ingredients\"]\n",
    "            instructions = row[\"instructions\"]\n",
    "\n",
    "            ingredient_text = \"\"\n",
    "            instructions_text = \"\"\n",
    "\n",
    "            ingredient_text = \" \".join(ingredient[\"text\"] for ingredient in ingredients)\n",
    "            instructions_text = \" \".join(instruction[\"text\"] for instruction in instructions)\n",
    "            \n",
    "            full_text = title + \" \" + ingredient_text + \" \" + instructions_text\n",
    "\n",
    "            yield id, title, ingredient_text, instructions_text, full_text\n",
    "\n",
    "    \n",
    "dataset = JsonDataset(test_data)\n",
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "# in case error occurs, a range of rows to start from\n",
    "# batch_start = \n",
    "# batch_end = 100000\n",
    "\n",
    "for (id, title, ingredient_text, instructions_text, full_text) in dataloader:\n",
    "    \n",
    "#     if (counter in range(batch_start, batch_end)):\n",
    "    # encode title\n",
    "    encoded_title = tokenizer(title, return_tensors='pt', max_length=512, truncation = True)\n",
    "    output_title = model(**encoded_title)\n",
    "    output_title = torch.mean(output_title[\"last_hidden_state\"], dim = 1)\n",
    "\n",
    "    with open('E:/train_text_title_6.pkl', 'ab') as f:\n",
    "        pickle.dump((id, output_title.squeeze(0)), f)\n",
    "\n",
    "    # encode ingredients\n",
    "    encoded_ingredients = tokenizer(ingredient_text, return_tensors='pt', max_length=512, truncation = True)\n",
    "    output_ingredients = model(**encoded_ingredients)\n",
    "    output_ingredients = torch.mean(output_ingredients[\"last_hidden_state\"], dim = 1)\n",
    "\n",
    "    with open('E:/train_text_ingredients_6.pkl', 'ab') as f:\n",
    "        pickle.dump((id, output_ingredients.squeeze(0)), f)\n",
    "\n",
    "    # encode instructions\n",
    "    encoded_instructions = tokenizer(instructions_text, return_tensors='pt', max_length=512, truncation = True)\n",
    "    output_instructions = model(**encoded_instructions)\n",
    "    output_instructions = torch.mean(output_instructions[\"last_hidden_state\"], dim = 1)\n",
    "\n",
    "    with open('E:/train_text_instructions_6.pkl', 'ab') as f:\n",
    "        pickle.dump((id, output_instructions.squeeze(0)), f)\n",
    "\n",
    "    #encode everything\n",
    "    encoded_full = tokenizer(full_text, return_tensors='pt', max_length=512, truncation = True)\n",
    "    output_full = model(**encoded_full)\n",
    "    output_full = torch.mean(output_full[\"last_hidden_state\"], dim = 1)\n",
    "\n",
    "    with open('E:/train_text_full_6.pkl', 'ab') as f:\n",
    "        pickle.dump((id, output_full.squeeze(0)), f)\n",
    "\n",
    "    print(counter)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061348bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if encodings generated properly\n",
    "emb = []\n",
    "with open('E:/train_text_title_2.pkl', 'rb') as f:\n",
    "    while True:\n",
    "        emb.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593c47d",
   "metadata": {},
   "source": [
    "# Aligning Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0aad0-954a-4b04-8ae5-f2ccc4fb9318",
   "metadata": {},
   "source": [
    "## Image Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e43ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = torch.load(\"E:/train_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f02ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_val = torch.load(\"E:/val_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = torch.load(\"E:/test_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d25ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test_full = []\n",
    "with open('E:/test_text_full.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_test_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_test_ingredients = []\n",
    "with open('E:/test_text_ingredients.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_test_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_test_instructions = []\n",
    "with open('E:/test_text_instructions.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_test_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_test_title = []\n",
    "with open('E:/test_text_title.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_test_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_val_title = []\n",
    "with open('E:/val_text_title.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_val_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_val_instructions = []\n",
    "with open('E:/val_text_instructions.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_val_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_val_ingredients = []\n",
    "with open('E:/val_text_ingredients.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_val_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_val_full = []\n",
    "with open('E:/val_text_full.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_val_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c4a90",
   "metadata": {},
   "source": [
    "## Text Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 0, 0\n",
    "text_test_full_final = []\n",
    "text_test_ingredients_final = []\n",
    "text_test_instructions_final = []\n",
    "text_test_title_final = []\n",
    "\n",
    "while i < len(img_test):\n",
    "    id = img_test[i][0]\n",
    "\n",
    "    if text_test_full[j][0][0] == id and text_test_ingredients[j][0][0] == id and \\\n",
    "    text_test_instructions[j][0][0] == id and text_test_title[j][0][0] == id:\n",
    "        text_test_full_final.append(text_test_full[j][1])\n",
    "        text_test_ingredients_final.append(text_test_ingredients[j][1])\n",
    "        text_test_instructions_final.append(text_test_instructions[j][1])\n",
    "        text_test_title_final.append(text_test_title[j][1])\n",
    "\n",
    "        i += 1\n",
    "    else:\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964443fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:/text_test_full_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_test_full_final ,f)\n",
    "with open('E:/text_test_instructions_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_test_instructions_final ,f)\n",
    "with open('E:/text_test_ingredients_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_test_ingredients_final ,f)\n",
    "with open('E:/text_test_title_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_test_title_final ,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e50d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(text_val_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9f4e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i, j = 0, 0\n",
    "text_val_full_final = []\n",
    "text_val_ingredients_final = []\n",
    "text_val_instructions_final = []\n",
    "text_val_title_final = []\n",
    "\n",
    "while i < len(img_val):\n",
    "    id = img_val[i][0]\n",
    "#     print(id, text_val_full[j][0][0])\n",
    "    if text_val_full[j][0][0] == id:\n",
    "        text_val_full_final.append(text_val_full[j][1])\n",
    "        text_val_ingredients_final.append(text_val_ingredients[j][1])\n",
    "        text_val_instructions_final.append(text_val_instructions[j][1])\n",
    "        text_val_title_final.append(text_val_title[j][1])\n",
    "\n",
    "        i += 1\n",
    "    else:\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_val_full_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb8f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:/text_val_full_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_val_full_final ,f)\n",
    "with open('E:/text_val_instructions_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_val_instructions_final ,f)\n",
    "with open('E:/text_val_ingredients_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_val_ingredients_final ,f)\n",
    "with open('E:/text_val_title_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_val_title_final ,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee037d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_title = []\n",
    "with open('E:/train_text_title_1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_title2.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_title_3.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_title_200000.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "text_train_ingredients = []\n",
    "with open('E:/train_text_ingredients_1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_ingredients2.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_ingredients_3.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_ingredients_200000.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "text_train_instructions = []\n",
    "with open('E:/train_text_instructions_1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_instructions2.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_instructions_3.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_instructions_200000.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_train_full = []\n",
    "with open('E:/train_text_full_1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_full2.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_full_3.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_full_200000.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "x = [y[0][0] for y in text_train_full]\n",
    "while i < len(img_train):\n",
    "    id = img_train[i][0]\n",
    "    if id not in x:\n",
    "        img_train.pop(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 0, 0\n",
    "text_train_full_final = []\n",
    "text_train_ingredients_final = []\n",
    "text_train_instructions_final = []\n",
    "text_train_title_final = []\n",
    "\n",
    "while i < len(img_train):\n",
    "    id = img_train[i][0]\n",
    "#     print(id, text_train_full[j][0][0])\n",
    "    if text_train_full[j][0][0] == id and text_train_ingredients[j][0][0] == id and \\\n",
    "    text_train_instructions[j][0][0] == id and text_train_title[j][0][0] == id:\n",
    "        text_train_full_final.append(text_train_full[j][1])\n",
    "        text_train_ingredients_final.append(text_train_ingredients[j][1])\n",
    "        text_train_instructions_final.append(text_train_instructions[j][1])\n",
    "        text_train_title_final.append(text_train_title[j][1])\n",
    "\n",
    "        i += 1\n",
    "    else:\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_final = [img_train[i][2] for i in range(len(img_train))]\n",
    "img_val_final = [img_val[i][2] for i in range(len(img_val))]\n",
    "img_test_final = [img_test[i][2] for i in range(len(img_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7609d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(img_train_final, \"E:/img_train_final.pt\")\n",
    "torch.save(img_val_final, \"E:/img_val_final.pt\")\n",
    "torch.save(img_test_final, \"E:/img_test_final.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c3733",
   "metadata": {},
   "source": [
    "# Professor's Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DATA\n",
    "prof_train_data_full = []\n",
    "with open('E:/embeddings_train1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_train_data_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "prof_test_data_full = []\n",
    "with open('E:/embeddings_test1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_test_data_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "prof_val_data_full = []\n",
    "with open('E:/embeddings_val1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_val_data_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# INGREDIENTS DATA\n",
    "prof_train_data_ingredients = []\n",
    "with open('E:/ingredients_embeddings_train.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_train_data_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "prof_test_data_ingredients = []\n",
    "with open('E:/ingredients_embeddings_test.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_test_data_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "prof_val_data_ingredients = []\n",
    "with open('E:/ingredients_embeddings_val.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_val_data_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# INSTRUCTIONS DATA\n",
    "prof_train_data_instructions = []\n",
    "with open('E:/instructions_embeddings_train.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_train_data_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "prof_val_data_instructions = []\n",
    "with open('E:/instructions_embeddings_val.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_val_data_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "prof_test_data_instructions = []\n",
    "with open('E:/instructions_embeddings_test.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_test_data_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# TITLE DATA \n",
    "prof_train_data_title = []\n",
    "with open('E:/title_embeddings_train.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_train_data_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "prof_val_data_title = []\n",
    "with open('E:/title_embeddings_val.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_val_data_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "prof_test_data_title = []\n",
    "with open('E:/title_embeddings_test.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            prof_test_data_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf0db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep changing file name\n",
    "embeddings = []\n",
    "for i in range(len(prof_val_data_title[0][0])):\n",
    "    embeddings.append(prof_val_data_title[0][0][i])\n",
    "\n",
    "torch.save(embeddings, \"E:/val_title.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
