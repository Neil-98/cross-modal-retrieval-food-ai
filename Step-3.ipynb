{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle\n",
    "\n",
    "# making sure that the whole embedding tensor is printed in output\n",
    "torch.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu102'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! set CUDA_VISIBLE_DEVICES = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure the feature extraction runs on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, txt_file, img_file, img_dir_path, transforms):\n",
    "        self.text_file = txt_file\n",
    "        self.image_file = img_file\n",
    "        self.ingredients = []\n",
    "        self.txt_ids = []\n",
    "        self.img_id_map = {}\n",
    "\n",
    "        self.img_dir = img_dir_path\n",
    "        self.transforms = transforms\n",
    "\n",
    "        for row in self.text_file:\n",
    "            id = row[\"id\"]\n",
    "            self.txt_ids.append(id)\n",
    "            # title = row[\"title\"]\n",
    "            # ingredients = row[\"ingredients\"]\n",
    "            instructions = row[\"instructions\"]\n",
    "\n",
    "            ingredient_text = \"\"\n",
    "            # instructions_text = \"\"\n",
    "\n",
    "            ingredient_text = \" \".join(instruction[\"text\"] for instruction in instructions)\n",
    "\n",
    "            self.ingredients.append(ingredient_text)\n",
    "\n",
    "        for row in self.image_file:\n",
    "            self.img_id_map[row[\"id\"]] = row[\"images\"][0]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ingredients)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.ingredients[idx]\n",
    "        image_file = self.img_id_map[self.txt_ids[idx]]\n",
    "        image_path = self.img_dir + image_file[0] + \"/\" + image_file[1] + \"/\" + image_file[2] + \"/\" + image_file[3] + \"/\" + image_file\n",
    "        img = Image.open(image_path)\n",
    "        img = self.transforms(img)\n",
    "        return img, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming each image\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_dataset = Dataset(json.load(open(\"/common/users/kcm161/data/train/text.json\")), json.load(open(\"/common/users/kcm161/data/train/image.json\")), \\\n",
    "    \"/common/users/kcm161/train/\", data_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "val_dataset = Dataset(json.load(open(\"/common/users/kcm161/data/val/text.json\")), json.load(open(\"/common/users/kcm161/data/val/image.json\")), \\\n",
    "    \"/common/users/kcm161/val/\", data_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "test_dataset = Dataset(json.load(open(\"/common/users/kcm161/data/test/text.json\")), json.load(open(\"/common/users/kcm161/data/test/image.json\")), \\\n",
    "    \"/common/users/kcm161/test/\", data_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For triplet finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets(images, texts):\n",
    "    triplet_images = torch.zeros((16, 3, 224, 224))\n",
    "    triplet_pos_text = []\n",
    "    triplet_neg_text = []\n",
    "    \n",
    "#     print(images.shape[0])\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        triplet_images[i] = images[i]\n",
    "        triplet_pos_text.append(texts[i])\n",
    "        \n",
    "#     print(len(triplet_pos_text))\n",
    "        \n",
    "    for i in range(images.shape[0]):\n",
    "        neg_idx = random.randint(0, images.shape[0] - 1)\n",
    "#         print(neg_idx)\n",
    "        while neg_idx == i:\n",
    "            neg_idx = random.randint(0, images.shape[0] - 1)\n",
    "#             print(neg_idx)\n",
    "\n",
    "        triplet_neg_text.append(triplet_pos_text[neg_idx])\n",
    "        \n",
    "    return triplet_images, triplet_pos_text, triplet_neg_text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "img_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "for param in img_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in img_model.encoder.layer[11].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in img_model.layernorm.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in img_model.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "img_model = nn.DataParallel(img_model, device_ids = [0])\n",
    "img_model = img_model.to(f'cuda:{img_model.device_ids[0]}')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "for param in text_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in text_model.encoder.layer[11].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in text_model.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "text_model = nn.DataParallel(text_model, device_ids = [0])\n",
    "text_model = text_model.to(f'cuda:{text_model.device_ids[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    # Utility function for timers\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_image = torch.optim.Adam(img_model.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "optimizer_text = torch.optim.Adam(text_model.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "\n",
    "optimizer_total = torch.optim.Adam(list(text_model.parameters()) + list(img_model.parameters()), lr=1e-4, weight_decay=0.0)\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "criterion.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def triplet_train(triplet_loader, img_model, text_model, criterion, optimizer_image, optimizer_text,  optimizer_total, epoch):\n",
    "    print('Starting training epoch {}'.format(epoch))\n",
    "    img_model.train()\n",
    "    text_model.train()\n",
    "    \n",
    "    batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "#     optimizer_image.zero_grad()\n",
    "#     optimizer_text.zero_grad()\n",
    "    optimizer_total.zero_grad()\n",
    "    \n",
    "    train_loss, total_samples, running_loss = 0, 0, 0\n",
    "    \n",
    "    batch = 1\n",
    "    \n",
    "    with tqdm(total = len(triplet_loader)) as pbar:\n",
    "        for img, text in triplet_loader:\n",
    "            \n",
    "            img, pos_text, neg_text = generate_triplets(img, text)\n",
    "\n",
    "            image_encodings = img_model(img.to(f'cuda:{text_model.device_ids[0]}'))\n",
    "            \n",
    "            pos_encoded_ingredients = tokenizer(pos_text, return_tensors='pt', max_length=512, truncation = True, padding = True).to(f'cuda:{text_model.device_ids[0]}')\n",
    "            pos_output_ingredients = text_model(**pos_encoded_ingredients)\n",
    "\n",
    "            neg_encoded_ingredients = tokenizer(neg_text, return_tensors='pt', max_length=512, truncation = True, padding = True).to(f'cuda:{text_model.device_ids[0]}')\n",
    "            neg_output_ingredients = text_model(**neg_encoded_ingredients)\n",
    "\n",
    "            loss = criterion(image_encodings[\"last_hidden_state\"][:, 0, :], pos_output_ingredients[\"last_hidden_state\"][:, 0, :], \n",
    "                             neg_output_ingredients[\"last_hidden_state\"][:, 0, :])\n",
    "\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            # Compute gradient and optimize\n",
    "#             optimizer_image.zero_grad()\n",
    "#             optimizer_text.zero_grad()\n",
    "            optimizer_total.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "#             optimizer_image.step()\n",
    "#             optimizer_text.step()\n",
    "            optimizer_total.step()\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            running_loss += loss.item() * img.shape[0]\n",
    "            total_samples += img.shape[0]\n",
    "\n",
    "            train_loss += running_loss\n",
    "\n",
    "            if batch % 50 == 0:\n",
    "                print('  batch {} loss: {}'.format(batch, running_loss / 50))\n",
    "                running_loss = 0.\n",
    "\n",
    "            if batch % 50 == 0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                    'Time {batch_time.val} ({batch_time.avg})\\t'\n",
    "                    'Data {data_time.val} ({data_time.avg})\\t'.format(\n",
    "                      epoch, batch, len(train_loader), batch_time=batch_time,\n",
    "                     data_time=data_time)) \n",
    "                pbar.update(50)\n",
    "\n",
    "            batch += 1\n",
    "\n",
    "        print('Finished training epoch {}'.format(epoch))\n",
    "        print('Epoch Loss:', train_loss / total_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {\n",
    "    \"image_vit_encoder\": img_model.state_dict(),\n",
    "    \"text_encoder\": text_model.state_dict(),\n",
    "}\n",
    "\n",
    "torch.save(save_dict, f'/common/users/kcm161/step3_models_instructions_onlytriplet_e1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_weights = torch.load(\"/common/users/kcm161/step3_models_onlytriplet_e1.pt\", map_location = \"cuda:0\")\n",
    "\n",
    "img_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "for param in img_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in img_model.encoder.layer[11].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in img_model.layernorm.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in img_model.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "img_model = nn.DataParallel(img_model, device_ids = [0])\n",
    "img_model.load_state_dict(model_weights[\"image_vit_encoder\"])\n",
    "img_model = img_model.to(f'cuda:{img_model.device_ids[0]}')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "for param in text_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in text_model.encoder.layer[11].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in text_model.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "text_model = nn.DataParallel(text_model, device_ids = [0])\n",
    "text_model.load_state_dict(model_weights[\"text_encoder\"])\n",
    "text_model = text_model.to(f'cuda:{text_model.device_ids[0]}')\n",
    "\n",
    "optimizer_image = torch.optim.Adam(img_model.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "optimizer_text = torch.optim.Adam(text_model.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "\n",
    "optimizer_total = torch.optim.Adam(list(text_model.parameters()) + list(img_model.parameters()), lr=1e-4, weight_decay=0.0)\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "criterion.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c680019db84439a87eca621de22de5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 50 loss: 15.886473064422608\n",
      "Epoch: [1][50/17600]\tTime 0.875758171081543 (0.9893178224563599)\tData 0.8578240871429443 (0.9697428941726685)\t\n",
      "  batch 100 loss: 15.594302463531495\n",
      "Epoch: [1][100/17600]\tTime 0.6010310649871826 (0.940607397556305)\tData 0.5835087299346924 (0.9218562650680542)\t\n",
      "  batch 150 loss: 11.192723121643066\n",
      "Epoch: [1][150/17600]\tTime 1.110100507736206 (0.948008599281311)\tData 1.0920896530151367 (0.929504861831665)\t\n",
      "  batch 200 loss: 8.379649143218995\n",
      "Epoch: [1][200/17600]\tTime 1.1579561233520508 (0.9301448488235473)\tData 1.1392502784729004 (0.9116637527942657)\t\n",
      "  batch 250 loss: 8.228947830200195\n",
      "Epoch: [1][250/17600]\tTime 1.06022310256958 (0.9674950437545776)\tData 1.0425007343292236 (0.9490633420944213)\t\n",
      "  batch 300 loss: 7.131164169311523\n",
      "Epoch: [1][300/17600]\tTime 1.0772957801818848 (1.0032671268781026)\tData 1.0597848892211914 (0.9849181588490804)\t\n",
      "  batch 350 loss: 7.641985130310059\n",
      "Epoch: [1][350/17600]\tTime 1.1193079948425293 (1.0308578743253436)\tData 1.1016950607299805 (1.0124576902389526)\t\n",
      "  batch 400 loss: 6.453643283843994\n",
      "Epoch: [1][400/17600]\tTime 1.020374059677124 (1.043164244890213)\tData 1.0027849674224854 (1.0247371637821197)\t\n",
      "  batch 450 loss: 5.66140510559082\n",
      "Epoch: [1][450/17600]\tTime 0.9351165294647217 (1.0611103163825142)\tData 0.9145736694335938 (1.0426889144049751)\t\n",
      "  batch 500 loss: 6.175624656677246\n",
      "Epoch: [1][500/17600]\tTime 1.6746439933776855 (1.0779195833206177)\tData 1.6568560600280762 (1.0594739427566529)\t\n",
      "  batch 550 loss: 6.030432052612305\n",
      "Epoch: [1][550/17600]\tTime 1.2765564918518066 (1.088584687059576)\tData 1.2586009502410889 (1.070162896676497)\t\n",
      "  batch 600 loss: 5.172923126220703\n",
      "Epoch: [1][600/17600]\tTime 1.6657967567443848 (1.1011708172162373)\tData 1.6441919803619385 (1.0827264551321665)\t\n",
      "  batch 650 loss: 5.287444839477539\n",
      "Epoch: [1][650/17600]\tTime 1.4716603755950928 (1.1030587460444523)\tData 1.454045295715332 (1.0846255705906795)\t\n",
      "  batch 700 loss: 5.049184017181396\n",
      "Epoch: [1][700/17600]\tTime 1.1839609146118164 (1.1150207086971828)\tData 1.166341781616211 (1.096564016682761)\t\n",
      "  batch 750 loss: 4.9371255683898925\n",
      "Epoch: [1][750/17600]\tTime 0.9792752265930176 (1.1165776767730713)\tData 0.9552547931671143 (1.0981636927922567)\t\n",
      "  batch 800 loss: 5.398402824401855\n",
      "Epoch: [1][800/17600]\tTime 1.2977237701416016 (1.1226340425014496)\tData 1.2801165580749512 (1.1042650619149208)\t\n",
      "  batch 850 loss: 5.1915340232849125\n",
      "Epoch: [1][850/17600]\tTime 0.6777956485748291 (1.1227934377333697)\tData 0.6604197025299072 (1.1044301439734066)\t\n",
      "  batch 900 loss: 4.185893917083741\n",
      "Epoch: [1][900/17600]\tTime 1.6176836490631104 (1.1257250102361043)\tData 1.5996975898742676 (1.1073776536517672)\t\n",
      "  batch 950 loss: 4.609979190826416\n",
      "Epoch: [1][950/17600]\tTime 1.0270435810089111 (1.131005311263235)\tData 1.0093019008636475 (1.1126787022540443)\t\n",
      "  batch 1000 loss: 4.915526580810547\n",
      "Epoch: [1][1000/17600]\tTime 1.0680768489837646 (1.1346553995609283)\tData 1.0504844188690186 (1.1163448476791382)\t\n",
      "  batch 1050 loss: 4.49498664855957\n",
      "Epoch: [1][1050/17600]\tTime 1.4841232299804688 (1.1403329036349341)\tData 1.4664967060089111 (1.1220349305016655)\t\n",
      "  batch 1100 loss: 4.469945812225342\n",
      "Epoch: [1][1100/17600]\tTime 1.1189360618591309 (1.1403517441316084)\tData 1.1015949249267578 (1.1220549628951333)\t\n",
      "  batch 1150 loss: 4.371041431427002\n",
      "Epoch: [1][1150/17600]\tTime 1.1415624618530273 (1.1439788975922958)\tData 1.1234219074249268 (1.1256904228873874)\t\n",
      "  batch 1200 loss: 4.484669361114502\n",
      "Epoch: [1][1200/17600]\tTime 1.5753488540649414 (1.151509442925453)\tData 1.5576896667480469 (1.1332318349679311)\t\n",
      "  batch 1250 loss: 4.575005378723144\n",
      "Epoch: [1][1250/17600]\tTime 0.8651225566864014 (1.150217798805237)\tData 0.8471999168395996 (1.1319554662704467)\t\n",
      "  batch 1300 loss: 4.235989189147949\n",
      "Epoch: [1][1300/17600]\tTime 1.2094318866729736 (1.1486850868738614)\tData 1.1916248798370361 (1.1304269223946792)\t\n",
      "  batch 1350 loss: 4.113131275177002\n",
      "Epoch: [1][1350/17600]\tTime 0.9075660705566406 (1.1478892638948228)\tData 0.8897204399108887 (1.1296343773382682)\t\n",
      "  batch 1400 loss: 3.8477166748046874\n",
      "Epoch: [1][1400/17600]\tTime 1.4781339168548584 (1.148562617642539)\tData 1.4602713584899902 (1.1303133046627045)\t\n",
      "  batch 1450 loss: 4.351848602294922\n",
      "Epoch: [1][1450/17600]\tTime 0.9989824295043945 (1.1476549638550857)\tData 0.9808790683746338 (1.129404849348397)\t\n",
      "  batch 1500 loss: 4.270805816650391\n",
      "Epoch: [1][1500/17600]\tTime 1.3691368103027344 (1.1491622776985169)\tData 1.3512585163116455 (1.130901407877604)\t\n",
      "  batch 1550 loss: 4.0036116981506344\n",
      "Epoch: [1][1550/17600]\tTime 0.6914350986480713 (1.1491567834731071)\tData 0.6736857891082764 (1.1308988289679252)\t\n",
      "  batch 1600 loss: 3.981603488922119\n",
      "Epoch: [1][1600/17600]\tTime 1.0606908798217773 (1.1486410962045193)\tData 1.0396544933319092 (1.1303484542667865)\t\n",
      "  batch 1650 loss: 3.8638175392150877\n",
      "Epoch: [1][1650/17600]\tTime 1.447561264038086 (1.1479989719390868)\tData 1.4296855926513672 (1.1296877231019915)\t\n",
      "  batch 1700 loss: 3.6234503555297852\n",
      "Epoch: [1][1700/17600]\tTime 0.8168661594390869 (1.1490484058155732)\tData 0.7988152503967285 (1.1307313115456525)\t\n",
      "  batch 1750 loss: 3.8335204887390137\n",
      "Epoch: [1][1750/17600]\tTime 1.231034755706787 (1.1519924463544573)\tData 1.212289571762085 (1.1336774123055595)\t\n",
      "  batch 1800 loss: 3.565877094268799\n",
      "Epoch: [1][1800/17600]\tTime 1.5091969966888428 (1.1531196505493588)\tData 1.4909536838531494 (1.1347886926598019)\t\n",
      "  batch 1850 loss: 3.6088151359558105\n",
      "Epoch: [1][1850/17600]\tTime 0.8811969757080078 (1.1515087426675332)\tData 0.8636088371276855 (1.1331827903438259)\t\n",
      "  batch 1900 loss: 3.5643749618530274\n",
      "Epoch: [1][1900/17600]\tTime 1.3000562191009521 (1.151642716809323)\tData 1.2818818092346191 (1.1333069827682094)\t\n",
      "  batch 1950 loss: 3.510026741027832\n",
      "Epoch: [1][1950/17600]\tTime 1.168245792388916 (1.1520580642651288)\tData 1.1495885848999023 (1.133721251365466)\t\n",
      "  batch 2000 loss: 3.67523229598999\n",
      "Epoch: [1][2000/17600]\tTime 1.319594383239746 (1.1509182523488999)\tData 1.3011260032653809 (1.132586509346962)\t\n",
      "  batch 2050 loss: 3.7935775756835937\n",
      "Epoch: [1][2050/17600]\tTime 1.1979491710662842 (1.151874378018263)\tData 1.1800615787506104 (1.1335431644393177)\t\n",
      "  batch 2100 loss: 2.785702304840088\n",
      "Epoch: [1][2100/17600]\tTime 1.0111455917358398 (1.1522455246107919)\tData 0.9937210083007812 (1.1339205622673034)\t\n",
      "  batch 2150 loss: 3.7912016105651856\n",
      "Epoch: [1][2150/17600]\tTime 1.1016724109649658 (1.1526917916674946)\tData 1.083815574645996 (1.1343684900638669)\t\n",
      "  batch 2200 loss: 3.5032511138916016\n",
      "Epoch: [1][2200/17600]\tTime 1.8082785606384277 (1.1544002426754345)\tData 1.7907445430755615 (1.1360741634802385)\t\n",
      "  batch 2250 loss: 3.381294288635254\n",
      "Epoch: [1][2250/17600]\tTime 1.0973565578460693 (1.1552513093948364)\tData 1.079385757446289 (1.1369278690550062)\t\n",
      "  batch 2300 loss: 3.7431247901916502\n",
      "Epoch: [1][2300/17600]\tTime 1.5159692764282227 (1.1562117713430653)\tData 1.4983141422271729 (1.1378935601400293)\t\n",
      "  batch 2350 loss: 3.656438694000244\n",
      "Epoch: [1][2350/17600]\tTime 1.1135938167572021 (1.157306522308512)\tData 1.095533847808838 (1.1389855104811648)\t\n",
      "  batch 2400 loss: 4.033233661651611\n",
      "Epoch: [1][2400/17600]\tTime 1.0867118835449219 (1.1579049762090048)\tData 1.0691213607788086 (1.1395814515153566)\t\n",
      "  batch 2450 loss: 3.401723041534424\n",
      "Epoch: [1][2450/17600]\tTime 1.2643039226531982 (1.1580167081404706)\tData 1.245919942855835 (1.1396952843179509)\t\n",
      "  batch 2500 loss: 3.3225482749938964\n",
      "Epoch: [1][2500/17600]\tTime 0.9882712364196777 (1.1581409790992736)\tData 0.9694089889526367 (1.1398248032569884)\t\n",
      "  batch 2550 loss: 3.9190922355651856\n",
      "Epoch: [1][2550/17600]\tTime 1.948923110961914 (1.1580329282611024)\tData 1.9314494132995605 (1.1397223099540261)\t\n",
      "  batch 2600 loss: 3.5215999984741213\n",
      "Epoch: [1][2600/17600]\tTime 1.2423086166381836 (1.1586484868709859)\tData 1.2244064807891846 (1.1403374358323903)\t\n",
      "  batch 2650 loss: 4.33600736618042\n",
      "Epoch: [1][2650/17600]\tTime 1.1636059284210205 (1.1593456695664603)\tData 1.1459143161773682 (1.1410451021734274)\t\n",
      "  batch 2700 loss: 3.56075080871582\n",
      "Epoch: [1][2700/17600]\tTime 1.2812769412994385 (1.1596994593408372)\tData 1.2638485431671143 (1.141392483887849)\t\n",
      "  batch 2750 loss: 3.039384002685547\n",
      "Epoch: [1][2750/17600]\tTime 1.3730051517486572 (1.1594996328353881)\tData 1.3552320003509521 (1.1411933685649525)\t\n",
      "  batch 2800 loss: 3.2722784233093263\n",
      "Epoch: [1][2800/17600]\tTime 1.4914426803588867 (1.1598817400421415)\tData 1.4737000465393066 (1.1415818736382892)\t\n",
      "  batch 2850 loss: 3.2102274322509765\n",
      "Epoch: [1][2850/17600]\tTime 1.0788402557373047 (1.161541779585052)\tData 1.0614452362060547 (1.1432461825588294)\t\n",
      "  batch 2900 loss: 3.436900520324707\n",
      "Epoch: [1][2900/17600]\tTime 1.3410413265228271 (1.160959497895734)\tData 1.3229925632476807 (1.142668884211573)\t\n",
      "  batch 2950 loss: 3.2889536666870116\n",
      "Epoch: [1][2950/17600]\tTime 1.0936529636383057 (1.1600445879920054)\tData 1.0759708881378174 (1.1417583803403175)\t\n",
      "  batch 3000 loss: 3.576385250091553\n",
      "Epoch: [1][3000/17600]\tTime 1.3340895175933838 (1.15929798579216)\tData 1.3160953521728516 (1.141013288895289)\t\n",
      "  batch 3050 loss: 3.6409229469299316\n",
      "Epoch: [1][3050/17600]\tTime 0.9036228656768799 (1.1606875868312647)\tData 0.8854875564575195 (1.142397277316109)\t\n",
      "  batch 3100 loss: 3.3110412979125976\n",
      "Epoch: [1][3100/17600]\tTime 0.8602395057678223 (1.1611857158906997)\tData 0.8427450656890869 (1.142894670117286)\t\n",
      "  batch 3150 loss: 2.523882884979248\n",
      "Epoch: [1][3150/17600]\tTime 1.0329532623291016 (1.161637711827717)\tData 1.0149335861206055 (1.1433419396385314)\t\n",
      "  batch 3200 loss: 3.1452557754516604\n",
      "Epoch: [1][3200/17600]\tTime 1.2667648792266846 (1.1620454323291778)\tData 1.2487423419952393 (1.1437534173578023)\t\n",
      "  batch 3250 loss: 2.771435890197754\n",
      "Epoch: [1][3250/17600]\tTime 1.655031442642212 (1.1624090759570782)\tData 1.6370580196380615 (1.1441190808369563)\t\n",
      "  batch 3300 loss: 3.4500647926330568\n",
      "Epoch: [1][3300/17600]\tTime 1.3484470844268799 (1.1630886656587773)\tData 1.3307459354400635 (1.1448020948063244)\t\n",
      "  batch 3350 loss: 2.5653981018066405\n",
      "Epoch: [1][3350/17600]\tTime 0.9649837017059326 (1.163550259035025)\tData 0.9472815990447998 (1.1452722797820818)\t\n",
      "  batch 3400 loss: 3.1763236236572268\n",
      "Epoch: [1][3400/17600]\tTime 1.1457200050354004 (1.1644064359103932)\tData 1.1281566619873047 (1.1461362483922173)\t\n",
      "  batch 3450 loss: 2.964900531768799\n",
      "Epoch: [1][3450/17600]\tTime 1.2332663536071777 (1.1645952149404997)\tData 1.2157258987426758 (1.1463335424920786)\t\n",
      "  batch 3500 loss: 2.7681937789916993\n",
      "Epoch: [1][3500/17600]\tTime 0.8806157112121582 (1.1635211943217687)\tData 0.8628113269805908 (1.1452667664800371)\t\n",
      "  batch 3550 loss: 3.169884834289551\n",
      "Epoch: [1][3550/17600]\tTime 1.3196218013763428 (1.1636047290748275)\tData 1.3019211292266846 (1.1453535188083916)\t\n",
      "  batch 3600 loss: 2.8702398681640626\n",
      "Epoch: [1][3600/17600]\tTime 1.268040418624878 (1.1629595890972348)\tData 1.2505788803100586 (1.1447162643406126)\t\n",
      "  batch 3650 loss: 2.833169994354248\n",
      "Epoch: [1][3650/17600]\tTime 1.0461995601654053 (1.1637713599531618)\tData 1.0275022983551025 (1.145532916996577)\t\n",
      "  batch 3700 loss: 2.8605668449401858\n",
      "Epoch: [1][3700/17600]\tTime 2.1231601238250732 (1.164211897205662)\tData 2.1054089069366455 (1.1459740718635354)\t\n",
      "  batch 3750 loss: 3.072289981842041\n",
      "Epoch: [1][3750/17600]\tTime 0.9892432689666748 (1.1640893431345622)\tData 0.9717037677764893 (1.1458582639694215)\t\n",
      "  batch 3800 loss: 2.6022971534729002\n",
      "Epoch: [1][3800/17600]\tTime 0.9083631038665771 (1.1645159304141999)\tData 0.89052414894104 (1.1462863409519195)\t\n",
      "  batch 3850 loss: 2.9612949752807616\n",
      "Epoch: [1][3850/17600]\tTime 0.9502651691436768 (1.1645098162316656)\tData 0.9325108528137207 (1.1462820323101885)\t\n",
      "  batch 3900 loss: 2.866844310760498\n",
      "Epoch: [1][3900/17600]\tTime 1.1963083744049072 (1.1646972692929782)\tData 1.17732834815979 (1.1464692061986679)\t\n",
      "  batch 3950 loss: 3.045516128540039\n",
      "Epoch: [1][3950/17600]\tTime 1.42252516746521 (1.1656959068926074)\tData 1.4041996002197266 (1.1474674117414256)\t\n",
      "  batch 4000 loss: 2.5696277809143067\n",
      "Epoch: [1][4000/17600]\tTime 1.047370433807373 (1.1663353588581085)\tData 1.029397964477539 (1.1481018895506858)\t\n",
      "  batch 4050 loss: 2.780918827056885\n",
      "Epoch: [1][4050/17600]\tTime 1.0117714405059814 (1.1661673797795802)\tData 0.9937756061553955 (1.147927793337975)\t\n",
      "  batch 4100 loss: 2.829510364532471\n",
      "Epoch: [1][4100/17600]\tTime 1.248518943786621 (1.167230641085927)\tData 1.2301297187805176 (1.1489907568838538)\t\n",
      "  batch 4150 loss: 3.124376449584961\n",
      "Epoch: [1][4150/17600]\tTime 1.0560941696166992 (1.167983221490699)\tData 1.0380704402923584 (1.1497426628779217)\t\n",
      "  batch 4200 loss: 2.721226634979248\n",
      "Epoch: [1][4200/17600]\tTime 1.167041301727295 (1.168625761611121)\tData 1.1491570472717285 (1.150385314793814)\t\n",
      "  batch 4250 loss: 2.93533992767334\n",
      "Epoch: [1][4250/17600]\tTime 1.0718662738800049 (1.1696334060781142)\tData 1.0386369228363037 (1.1513884703692268)\t\n",
      "  batch 4300 loss: 2.5015881156921385\n",
      "Epoch: [1][4300/17600]\tTime 1.6873250007629395 (1.1696987302358761)\tData 1.6694517135620117 (1.1514580205429432)\t\n",
      "  batch 4350 loss: 2.405686283111572\n",
      "Epoch: [1][4350/17600]\tTime 1.9233121871948242 (1.1698777381853125)\tData 1.9056682586669922 (1.1516301785392322)\t\n",
      "  batch 4400 loss: 3.1753811836242676\n",
      "Epoch: [1][4400/17600]\tTime 1.5371325016021729 (1.1702758736502041)\tData 1.5187656879425049 (1.1520291332223198)\t\n",
      "  batch 4450 loss: 2.5805247688293456\n",
      "Epoch: [1][4450/17600]\tTime 1.6160790920257568 (1.170873202527507)\tData 1.598412036895752 (1.1526213413945745)\t\n",
      "  batch 4500 loss: 2.9649732398986814\n",
      "Epoch: [1][4500/17600]\tTime 1.7081599235534668 (1.1723795489205255)\tData 1.689866065979004 (1.1541277205679152)\t\n",
      "  batch 4550 loss: 2.938576831817627\n",
      "Epoch: [1][4550/17600]\tTime 1.5837175846099854 (1.172289612371843)\tData 1.565962553024292 (1.1540390988234634)\t\n",
      "  batch 4600 loss: 2.7704113960266112\n",
      "Epoch: [1][4600/17600]\tTime 0.9368536472320557 (1.1727359947950944)\tData 0.9188997745513916 (1.1544887874437415)\t\n",
      "  batch 4650 loss: 3.449399681091309\n",
      "Epoch: [1][4650/17600]\tTime 0.7304153442382812 (1.1731929854423768)\tData 0.7126255035400391 (1.1549477083452286)\t\n",
      "  batch 4700 loss: 3.109678611755371\n",
      "Epoch: [1][4700/17600]\tTime 1.1568453311920166 (1.1733846946472817)\tData 1.1391713619232178 (1.155132470942558)\t\n",
      "  batch 4750 loss: 2.7997591209411623\n",
      "Epoch: [1][4750/17600]\tTime 1.324491262435913 (1.1741092388253462)\tData 1.306114673614502 (1.1558570138529727)\t\n",
      "  batch 4800 loss: 2.74000545501709\n",
      "Epoch: [1][4800/17600]\tTime 1.1890575885772705 (1.1744624199469884)\tData 1.17148756980896 (1.1562088458240032)\t\n",
      "  batch 4850 loss: 2.8781314659118653\n",
      "Epoch: [1][4850/17600]\tTime 0.9268720149993896 (1.1750841805369583)\tData 0.9090011119842529 (1.156829286457337)\t\n",
      "  batch 4900 loss: 2.4639790153503416\n",
      "Epoch: [1][4900/17600]\tTime 0.9194850921630859 (1.174689762154404)\tData 0.901287317276001 (1.15643069019123)\t\n",
      "  batch 4950 loss: 2.766112461090088\n",
      "Epoch: [1][4950/17600]\tTime 1.1439321041107178 (1.1750505148762405)\tData 1.1248455047607422 (1.1567471790795374)\t\n",
      "  batch 5000 loss: 2.760836753845215\n",
      "Epoch: [1][5000/17600]\tTime 1.2677946090698242 (1.1749763077735902)\tData 1.2501425743103027 (1.1566750969409942)\t\n",
      "  batch 5050 loss: 2.7230878257751465\n",
      "Epoch: [1][5050/17600]\tTime 0.9975919723510742 (1.1754280078529131)\tData 0.9797635078430176 (1.1571268602408986)\t\n",
      "  batch 5100 loss: 2.895981330871582\n",
      "Epoch: [1][5100/17600]\tTime 1.3608102798461914 (1.1764919335234398)\tData 1.3432579040527344 (1.1581963981834111)\t\n",
      "  batch 5150 loss: 2.4505742263793944\n",
      "Epoch: [1][5150/17600]\tTime 0.8804869651794434 (1.176715710880687)\tData 0.8630387783050537 (1.1584219395535664)\t\n",
      "  batch 5200 loss: 2.592316970825195\n",
      "Epoch: [1][5200/17600]\tTime 1.113765001296997 (1.1763889569044113)\tData 1.0952696800231934 (1.158098300924668)\t\n",
      "  batch 5250 loss: 2.38127010345459\n",
      "Epoch: [1][5250/17600]\tTime 1.2396793365478516 (1.1771496392658778)\tData 1.221742868423462 (1.1588570479438418)\t\n",
      "  batch 5300 loss: 2.988942737579346\n",
      "Epoch: [1][5300/17600]\tTime 0.8991448879241943 (1.1770908459627403)\tData 0.8808043003082275 (1.1587976443092778)\t\n",
      "  batch 5350 loss: 2.6532218742370604\n",
      "Epoch: [1][5350/17600]\tTime 1.1133840084075928 (1.178348689970569)\tData 1.0956199169158936 (1.1600563843005172)\t\n",
      "  batch 5400 loss: 2.2990850830078124\n",
      "Epoch: [1][5400/17600]\tTime 0.9595210552215576 (1.1787045679269013)\tData 0.9401404857635498 (1.1604132994457528)\t\n",
      "  batch 5450 loss: 2.9101747131347655\n",
      "Epoch: [1][5450/17600]\tTime 1.3201649188995361 (1.179709857144487)\tData 1.2878296375274658 (1.161418309299224)\t\n",
      "  batch 5500 loss: 2.7536432266235353\n",
      "Epoch: [1][5500/17600]\tTime 1.2134678363800049 (1.1800244157097557)\tData 1.195878267288208 (1.161733213077892)\t\n",
      "  batch 5550 loss: 2.761837329864502\n",
      "Epoch: [1][5550/17600]\tTime 1.2227609157562256 (1.1804264374037046)\tData 1.1970856189727783 (1.162134859110858)\t\n",
      "  batch 5600 loss: 2.2727475547790528\n",
      "Epoch: [1][5600/17600]\tTime 1.1366291046142578 (1.1799833593623978)\tData 1.1190142631530762 (1.1616901620371)\t\n",
      "  batch 5650 loss: 3.0593768310546876\n",
      "Epoch: [1][5650/17600]\tTime 1.2616620063781738 (1.1809701725866941)\tData 1.243208408355713 (1.1626766618374174)\t\n",
      "  batch 5700 loss: 2.831621265411377\n",
      "Epoch: [1][5700/17600]\tTime 1.0414514541625977 (1.1816080557254323)\tData 1.0236034393310547 (1.1633172141041672)\t\n",
      "  batch 5750 loss: 3.1600593185424803\n",
      "Epoch: [1][5750/17600]\tTime 1.3272762298583984 (1.1814938556422359)\tData 1.3087515830993652 (1.163204782900603)\t\n",
      "  batch 5800 loss: 3.1398686218261718\n",
      "Epoch: [1][5800/17600]\tTime 0.9679758548736572 (1.181980373571659)\tData 0.9501097202301025 (1.1636908061751003)\t\n",
      "  batch 5850 loss: 2.7293311882019045\n",
      "Epoch: [1][5850/17600]\tTime 2.5278353691101074 (1.1825122754186645)\tData 2.509186267852783 (1.1642203628507435)\t\n",
      "  batch 5900 loss: 2.8081696891784667\n",
      "Epoch: [1][5900/17600]\tTime 1.6199276447296143 (1.1834570258754795)\tData 1.6020538806915283 (1.1651657775297004)\t\n",
      "  batch 5950 loss: 2.5357047843933107\n",
      "Epoch: [1][5950/17600]\tTime 1.734095811843872 (1.184090339476321)\tData 1.7158429622650146 (1.1658019779509856)\t\n",
      "  batch 6000 loss: 3.144976177215576\n",
      "Epoch: [1][6000/17600]\tTime 0.7729787826538086 (1.184311693429947)\tData 0.755518913269043 (1.1660225354830425)\t\n",
      "  batch 6050 loss: 3.152812671661377\n",
      "Epoch: [1][6050/17600]\tTime 1.1844115257263184 (1.1846061197785307)\tData 1.1644885540008545 (1.1663160562515258)\t\n",
      "  batch 6100 loss: 2.5582846450805663\n",
      "Epoch: [1][6100/17600]\tTime 0.9030766487121582 (1.1846349199091801)\tData 0.8854019641876221 (1.1663429740608715)\t\n",
      "  batch 6150 loss: 2.691604232788086\n",
      "Epoch: [1][6150/17600]\tTime 1.4446220397949219 (1.1850169226018394)\tData 1.4268238544464111 (1.166725690345454)\t\n",
      "  batch 6200 loss: 2.7301079559326173\n",
      "Epoch: [1][6200/17600]\tTime 0.7638506889343262 (1.1848069604750602)\tData 0.7451186180114746 (1.1665120334394516)\t\n",
      "  batch 6250 loss: 2.4498690223693846\n",
      "Epoch: [1][6250/17600]\tTime 1.92376708984375 (1.1850670204162597)\tData 1.9054999351501465 (1.1667762565231323)\t\n",
      "  batch 6300 loss: 2.860236015319824\n",
      "Epoch: [1][6300/17600]\tTime 1.1256885528564453 (1.185056228032188)\tData 1.1080451011657715 (1.1667682057713706)\t\n",
      "  batch 6350 loss: 2.08649133682251\n",
      "Epoch: [1][6350/17600]\tTime 1.1371972560882568 (1.1849240807660921)\tData 1.1192095279693604 (1.1666359766637246)\t\n",
      "  batch 6400 loss: 3.0449130439758303\n",
      "Epoch: [1][6400/17600]\tTime 1.2360203266143799 (1.1854681581258775)\tData 1.2172176837921143 (1.1671801812201739)\t\n",
      "  batch 6450 loss: 2.7910873794555666\n",
      "Epoch: [1][6450/17600]\tTime 1.0883510112762451 (1.185565380828325)\tData 1.0701582431793213 (1.167276749056439)\t\n",
      "  batch 6500 loss: 2.307714595794678\n",
      "Epoch: [1][6500/17600]\tTime 1.009974479675293 (1.1858982818310078)\tData 0.9920825958251953 (1.1676107836870047)\t\n",
      "  batch 6550 loss: 2.695019874572754\n",
      "Epoch: [1][6550/17600]\tTime 1.625943899154663 (1.1865015652707516)\tData 1.6083791255950928 (1.1682159303344843)\t\n",
      "  batch 6600 loss: 3.034720706939697\n",
      "Epoch: [1][6600/17600]\tTime 1.2457499504089355 (1.1868127274513245)\tData 1.2277629375457764 (1.1685279339010066)\t\n",
      "  batch 6650 loss: 3.217581386566162\n",
      "Epoch: [1][6650/17600]\tTime 1.484978199005127 (1.1869230237401518)\tData 1.4672307968139648 (1.1686377599544095)\t\n",
      "  batch 6700 loss: 2.00721887588501\n",
      "Epoch: [1][6700/17600]\tTime 1.9402084350585938 (1.187122992508447)\tData 1.922342300415039 (1.1688371023491246)\t\n",
      "  batch 6750 loss: 2.6106440353393556\n",
      "Epoch: [1][6750/17600]\tTime 0.9488155841827393 (1.1870697687643545)\tData 0.9302504062652588 (1.1687860195725053)\t\n",
      "  batch 6800 loss: 3.0079433250427248\n",
      "Epoch: [1][6800/17600]\tTime 1.261826515197754 (1.187309055503677)\tData 1.238600254058838 (1.1690277114335228)\t\n",
      "  batch 6850 loss: 2.78928747177124\n",
      "Epoch: [1][6850/17600]\tTime 1.5252811908721924 (1.1875646890863014)\tData 1.5070068836212158 (1.1692852043235389)\t\n",
      "  batch 6900 loss: 2.648100643157959\n",
      "Epoch: [1][6900/17600]\tTime 0.9430491924285889 (1.1874302076947862)\tData 0.9253954887390137 (1.1691516991629116)\t\n",
      "  batch 6950 loss: 2.6927809143066406\n",
      "Epoch: [1][6950/17600]\tTime 0.8338391780853271 (1.1878249092925366)\tData 0.8163073062896729 (1.1695458103769976)\t\n",
      "  batch 7000 loss: 2.9351040077209474\n",
      "Epoch: [1][7000/17600]\tTime 1.4730463027954102 (1.1882631648608617)\tData 1.454920768737793 (1.16998563010352)\t\n",
      "  batch 7050 loss: 3.0104767799377443\n",
      "Epoch: [1][7050/17600]\tTime 0.9350118637084961 (1.1881231868013422)\tData 0.9173946380615234 (1.1698473766002249)\t\n",
      "  batch 7100 loss: 2.573922233581543\n",
      "Epoch: [1][7100/17600]\tTime 0.8446164131164551 (1.1885757321035357)\tData 0.8265447616577148 (1.1703006131212477)\t\n",
      "  batch 7150 loss: 2.737531223297119\n",
      "Epoch: [1][7150/17600]\tTime 1.1263325214385986 (1.1884477436625873)\tData 1.108802318572998 (1.1701725230517088)\t\n",
      "  batch 7200 loss: 2.2943959045410156\n",
      "Epoch: [1][7200/17600]\tTime 2.017375946044922 (1.1887945491406653)\tData 1.9992315769195557 (1.170519961118698)\t\n",
      "  batch 7250 loss: 2.5125676345825196\n",
      "Epoch: [1][7250/17600]\tTime 1.135514259338379 (1.1892689874583278)\tData 1.1177868843078613 (1.1709959558289627)\t\n",
      "  batch 7300 loss: 2.7435192489624023\n",
      "Epoch: [1][7300/17600]\tTime 1.3885695934295654 (1.1889669042090847)\tData 1.3706045150756836 (1.1706950231774214)\t\n",
      "  batch 7350 loss: 2.3649631118774415\n",
      "Epoch: [1][7350/17600]\tTime 1.1840546131134033 (1.1890723774708858)\tData 1.1661717891693115 (1.1708016509425883)\t\n",
      "  batch 7400 loss: 2.2572397422790527\n",
      "Epoch: [1][7400/17600]\tTime 1.0307683944702148 (1.1895527208173597)\tData 1.012272596359253 (1.1712805513433509)\t\n",
      "  batch 7450 loss: 2.729288921356201\n",
      "Epoch: [1][7450/17600]\tTime 1.1978645324707031 (1.1888957586544473)\tData 1.180126667022705 (1.1706245628139316)\t\n",
      "  batch 7500 loss: 3.067833003997803\n",
      "Epoch: [1][7500/17600]\tTime 1.439098834991455 (1.189162591425578)\tData 1.420966625213623 (1.1708900019963582)\t\n",
      "  batch 7550 loss: 2.3791983985900877\n",
      "Epoch: [1][7550/17600]\tTime 1.5026443004608154 (1.190380350296071)\tData 1.483640193939209 (1.1721064195885564)\t\n",
      "  batch 7600 loss: 2.5870082664489744\n",
      "Epoch: [1][7600/17600]\tTime 1.1409339904785156 (1.1899799467074244)\tData 1.1230175495147705 (1.171704011873195)\t\n",
      "  batch 7650 loss: 2.648303813934326\n",
      "Epoch: [1][7650/17600]\tTime 1.215660572052002 (1.1896801726023356)\tData 1.1974616050720215 (1.171402396563611)\t\n",
      "  batch 7700 loss: 2.224829616546631\n",
      "Epoch: [1][7700/17600]\tTime 0.9165589809417725 (1.1894750271834336)\tData 0.8988113403320312 (1.1711965078502506)\t\n",
      "  batch 7750 loss: 2.508782482147217\n",
      "Epoch: [1][7750/17600]\tTime 1.1024644374847412 (1.1901226806025351)\tData 1.0845420360565186 (1.1718458428229055)\t\n",
      "  batch 7800 loss: 3.041017532348633\n",
      "Epoch: [1][7800/17600]\tTime 1.7254424095153809 (1.1904227518424009)\tData 1.7075245380401611 (1.172144269179075)\t\n",
      "  batch 7850 loss: 2.6916741561889648\n",
      "Epoch: [1][7850/17600]\tTime 1.025470495223999 (1.1909429731186787)\tData 1.0073232650756836 (1.1726650088304167)\t\n",
      "  batch 7900 loss: 2.2922386360168456\n",
      "Epoch: [1][7900/17600]\tTime 1.3862090110778809 (1.1911016799226593)\tData 1.3678927421569824 (1.1728238169452812)\t\n",
      "  batch 7950 loss: 2.3136445236206056\n",
      "Epoch: [1][7950/17600]\tTime 1.3961045742034912 (1.1909835651985505)\tData 1.377551555633545 (1.1727055298907203)\t\n",
      "  batch 8000 loss: 2.4268262672424314\n",
      "Epoch: [1][8000/17600]\tTime 0.8417327404022217 (1.1916018027365207)\tData 0.8239524364471436 (1.1733110737502574)\t\n",
      "  batch 8050 loss: 2.4745093154907227\n",
      "Epoch: [1][8050/17600]\tTime 1.2122440338134766 (1.19131722719773)\tData 1.1944539546966553 (1.1730245018597716)\t\n",
      "  batch 8100 loss: 2.7791723251342773\n",
      "Epoch: [1][8100/17600]\tTime 1.199427843093872 (1.1917626040953178)\tData 1.181840181350708 (1.1734714526894652)\t\n",
      "  batch 8150 loss: 2.2926441383361817\n",
      "Epoch: [1][8150/17600]\tTime 1.6894145011901855 (1.1917042327365992)\tData 1.6711921691894531 (1.173413129701205)\t\n",
      "  batch 8200 loss: 2.3381725120544434\n",
      "Epoch: [1][8200/17600]\tTime 1.132603406906128 (1.1917605256743546)\tData 1.114835262298584 (1.1734722060401266)\t\n",
      "  batch 8250 loss: 2.5757075691223146\n",
      "Epoch: [1][8250/17600]\tTime 0.951362133026123 (1.1913205455433238)\tData 0.9335739612579346 (1.1730343903050278)\t\n",
      "  batch 8300 loss: 1.9511900329589844\n",
      "Epoch: [1][8300/17600]\tTime 1.0909950733184814 (1.1914083384318523)\tData 1.073148250579834 (1.1731251234893338)\t\n",
      "  batch 8350 loss: 2.3282674026489256\n",
      "Epoch: [1][8350/17600]\tTime 0.7858223915100098 (1.1916682523167776)\tData 0.7671864032745361 (1.1733876598666528)\t\n",
      "  batch 8400 loss: 2.8989200019836425\n",
      "Epoch: [1][8400/17600]\tTime 1.2181224822998047 (1.1919047432570231)\tData 1.2006568908691406 (1.1736274501823243)\t\n",
      "  batch 8450 loss: 3.116804485321045\n",
      "Epoch: [1][8450/17600]\tTime 1.0951182842254639 (1.191837363892053)\tData 1.0774919986724854 (1.1735625081372685)\t\n",
      "  batch 8500 loss: 2.75515625\n",
      "Epoch: [1][8500/17600]\tTime 1.0894203186035156 (1.1921731953059926)\tData 1.0718517303466797 (1.1739003444839926)\t\n",
      "  batch 8550 loss: 2.66274055480957\n",
      "Epoch: [1][8550/17600]\tTime 1.23972487449646 (1.1923551806511237)\tData 1.2221064567565918 (1.1740857814208805)\t\n",
      "  batch 8600 loss: 2.0347756004333495\n",
      "Epoch: [1][8600/17600]\tTime 1.0606071949005127 (1.192292595575022)\tData 1.0430448055267334 (1.1740266588122346)\t\n",
      "  batch 8650 loss: 2.2972593688964844\n",
      "Epoch: [1][8650/17600]\tTime 0.9822325706481934 (1.1920724188523486)\tData 0.964463472366333 (1.1738094267817591)\t\n",
      "  batch 8700 loss: 1.877215633392334\n",
      "Epoch: [1][8700/17600]\tTime 0.9239990711212158 (1.1919391447922278)\tData 0.9064598083496094 (1.1736778493311213)\t\n",
      "  batch 8750 loss: 2.631262722015381\n",
      "Epoch: [1][8750/17600]\tTime 1.3035662174224854 (1.1919934911182948)\tData 1.2858939170837402 (1.1737361427852087)\t\n",
      "  batch 8800 loss: 2.435107955932617\n",
      "Epoch: [1][8800/17600]\tTime 0.9652431011199951 (1.1919702567837456)\tData 0.9476470947265625 (1.1737158853357488)\t\n",
      "  batch 8850 loss: 2.2784559822082517\n",
      "Epoch: [1][8850/17600]\tTime 1.1249804496765137 (1.19155227550679)\tData 1.1073594093322754 (1.1733011621270477)\t\n",
      "  batch 8900 loss: 2.4037041664123535\n",
      "Epoch: [1][8900/17600]\tTime 1.0967869758605957 (1.1916285889336233)\tData 1.0791761875152588 (1.1733790055285678)\t\n",
      "  batch 8950 loss: 2.3142993354797365\n",
      "Epoch: [1][8950/17600]\tTime 0.9356837272644043 (1.191549747243274)\tData 0.9181723594665527 (1.1733038660933852)\t\n",
      "  batch 9000 loss: 2.3745868492126463\n",
      "Epoch: [1][9000/17600]\tTime 1.2979815006256104 (1.191426745971044)\tData 1.2800846099853516 (1.173183758629693)\t\n",
      "  batch 9050 loss: 2.6890655517578126\n",
      "Epoch: [1][9050/17600]\tTime 0.9815769195556641 (1.1917910952067508)\tData 0.9639296531677246 (1.1735513197124334)\t\n",
      "  batch 9100 loss: 2.3492219161987307\n",
      "Epoch: [1][9100/17600]\tTime 0.8344430923461914 (1.1917914785395611)\tData 0.8159162998199463 (1.1735537058180505)\t\n",
      "  batch 9150 loss: 2.5943515586853025\n",
      "Epoch: [1][9150/17600]\tTime 1.1653032302856445 (1.191920506836938)\tData 1.147517442703247 (1.173684030986223)\t\n",
      "  batch 9200 loss: 2.5218970489501955\n",
      "Epoch: [1][9200/17600]\tTime 0.8819165229797363 (1.1922742808383444)\tData 0.8629815578460693 (1.1740344422796498)\t\n",
      "  batch 9250 loss: 2.187018146514893\n",
      "Epoch: [1][9250/17600]\tTime 0.9342687129974365 (1.192139066670392)\tData 0.9165065288543701 (1.1738993716884303)\t\n",
      "  batch 9300 loss: 2.7130162811279295\n",
      "Epoch: [1][9300/17600]\tTime 1.1191186904907227 (1.1923364890519008)\tData 1.1014814376831055 (1.174095674689098)\t\n",
      "  batch 9350 loss: 2.9866477966308596\n",
      "Epoch: [1][9350/17600]\tTime 1.0342729091644287 (1.192039787833066)\tData 1.016577959060669 (1.1738011510104418)\t\n",
      "  batch 9400 loss: 2.5395052146911623\n",
      "Epoch: [1][9400/17600]\tTime 1.1599109172821045 (1.1922446544373289)\tData 1.1423404216766357 (1.1740081159865603)\t\n",
      "  batch 9450 loss: 2.3419032859802247\n",
      "Epoch: [1][9450/17600]\tTime 1.105010986328125 (1.1926536620104755)\tData 1.0874300003051758 (1.1744201593550425)\t\n",
      "  batch 9500 loss: 2.64923828125\n",
      "Epoch: [1][9500/17600]\tTime 1.0372276306152344 (1.1924943705358004)\tData 1.0196239948272705 (1.1742630170520982)\t\n",
      "  batch 9550 loss: 2.8078116607666015\n",
      "Epoch: [1][9550/17600]\tTime 1.2009813785552979 (1.1924009890830953)\tData 1.183506727218628 (1.1741720034814005)\t\n",
      "  batch 9600 loss: 2.551768569946289\n",
      "Epoch: [1][9600/17600]\tTime 1.4029796123504639 (1.19275580269595)\tData 1.38543701171875 (1.174526001935204)\t\n",
      "  batch 9650 loss: 3.0044479370117188\n",
      "Epoch: [1][9650/17600]\tTime 1.156017541885376 (1.1931730151794118)\tData 1.1381487846374512 (1.1749459916692941)\t\n",
      "  batch 9700 loss: 2.380033130645752\n",
      "Epoch: [1][9700/17600]\tTime 1.1708259582519531 (1.1931920926595472)\tData 1.1531996726989746 (1.174966331978434)\t\n",
      "  batch 9750 loss: 2.2470282745361327\n",
      "Epoch: [1][9750/17600]\tTime 1.3273794651031494 (1.1934141288170448)\tData 1.3095881938934326 (1.1751871464313606)\t\n",
      "  batch 9800 loss: 2.3433010673522947\n",
      "Epoch: [1][9800/17600]\tTime 1.600142002105713 (1.1937199049823137)\tData 1.5824310779571533 (1.1754926724823154)\t\n",
      "  batch 9850 loss: 2.5619319534301757\n",
      "Epoch: [1][9850/17600]\tTime 1.289560317993164 (1.1936752203152265)\tData 1.27180814743042 (1.1754498731545386)\t\n",
      "  batch 9900 loss: 2.0731048011779785\n",
      "Epoch: [1][9900/17600]\tTime 1.0264010429382324 (1.193560911790289)\tData 1.0088739395141602 (1.1753378918195012)\t\n",
      "  batch 9950 loss: 2.6471427726745604\n",
      "Epoch: [1][9950/17600]\tTime 0.8379213809967041 (1.193533371105865)\tData 0.8202869892120361 (1.1753130310863706)\t\n",
      "  batch 10000 loss: 2.4155622482299806\n",
      "Epoch: [1][10000/17600]\tTime 0.8058462142944336 (1.1936065793991089)\tData 0.787879467010498 (1.1753875166416168)\t\n",
      "  batch 10050 loss: 2.3015400695800783\n",
      "Epoch: [1][10050/17600]\tTime 1.566734790802002 (1.1937374752433738)\tData 1.5488624572753906 (1.1755211766798104)\t\n",
      "  batch 10100 loss: 2.269341926574707\n",
      "Epoch: [1][10100/17600]\tTime 1.1013383865356445 (1.193894478070854)\tData 1.0838136672973633 (1.1756806468491507)\t\n",
      "  batch 10150 loss: 2.7285407638549803\n",
      "Epoch: [1][10150/17600]\tTime 1.0450186729431152 (1.1937084103805091)\tData 1.0272581577301025 (1.1754961998944211)\t\n",
      "  batch 10200 loss: 2.1376767539978028\n",
      "Epoch: [1][10200/17600]\tTime 1.4161856174468994 (1.1940946474028569)\tData 1.398493766784668 (1.175884176866681)\t\n",
      "  batch 10250 loss: 2.3614754486083984\n",
      "Epoch: [1][10250/17600]\tTime 1.2174842357635498 (1.1938111915588379)\tData 1.1999094486236572 (1.1756030841455227)\t\n",
      "  batch 10300 loss: 2.1215548515319824\n",
      "Epoch: [1][10300/17600]\tTime 1.313509464263916 (1.1936658544447816)\tData 1.295595407485962 (1.1754607068219232)\t\n",
      "  batch 10350 loss: 2.565714168548584\n",
      "Epoch: [1][10350/17600]\tTime 0.9360964298248291 (1.1936543950712046)\tData 0.9171366691589355 (1.175451553731725)\t\n",
      "  batch 10400 loss: 2.2629390716552735\n",
      "Epoch: [1][10400/17600]\tTime 1.1501009464263916 (1.193700663126432)\tData 1.1323010921478271 (1.1754982584027143)\t\n",
      "  batch 10450 loss: 2.2617594528198244\n",
      "Epoch: [1][10450/17600]\tTime 1.4953415393829346 (1.1933472699297671)\tData 1.4776413440704346 (1.1751473478152992)\t\n",
      "  batch 10500 loss: 2.265391845703125\n",
      "Epoch: [1][10500/17600]\tTime 1.2425549030303955 (1.1932008497828528)\tData 1.2248311042785645 (1.1750031587509882)\t\n",
      "  batch 10550 loss: 2.6071861839294432\n",
      "Epoch: [1][10550/17600]\tTime 0.8850357532501221 (1.1930823926564076)\tData 0.867290735244751 (1.1748872711760172)\t\n",
      "  batch 10600 loss: 2.930576858520508\n",
      "Epoch: [1][10600/17600]\tTime 1.7441723346710205 (1.193281037132695)\tData 1.7264583110809326 (1.1750883944079562)\t\n",
      "  batch 10650 loss: 2.3135423851013184\n",
      "Epoch: [1][10650/17600]\tTime 0.7254915237426758 (1.1928072016675708)\tData 0.7079248428344727 (1.174616081927304)\t\n",
      "  batch 10700 loss: 2.321767978668213\n",
      "Epoch: [1][10700/17600]\tTime 0.9168241024017334 (1.1923861100740523)\tData 0.8991653919219971 (1.1741968014307111)\t\n",
      "  batch 10750 loss: 2.1782210159301756\n",
      "Epoch: [1][10750/17600]\tTime 1.0851647853851318 (1.1924325523820034)\tData 1.067650318145752 (1.1742458074924558)\t\n",
      "  batch 10800 loss: 2.243775291442871\n",
      "Epoch: [1][10800/17600]\tTime 1.4457213878631592 (1.1923546016878552)\tData 1.428086519241333 (1.1741702123483022)\t\n",
      "  batch 10850 loss: 2.410651454925537\n",
      "Epoch: [1][10850/17600]\tTime 0.7325055599212646 (1.1921329184501401)\tData 0.7150394916534424 (1.1739511134547571)\t\n",
      "  batch 10900 loss: 2.077899398803711\n",
      "Epoch: [1][10900/17600]\tTime 1.7306790351867676 (1.1920822740476065)\tData 1.7128901481628418 (1.1739029955426488)\t\n",
      "  batch 10950 loss: 2.694262351989746\n",
      "Epoch: [1][10950/17600]\tTime 1.3252861499786377 (1.1920987931778442)\tData 1.307615041732788 (1.173921414553847)\t\n",
      "  batch 11000 loss: 2.5112473297119142\n",
      "Epoch: [1][11000/17600]\tTime 0.7664918899536133 (1.1920380302125757)\tData 0.74896240234375 (1.1738621051094749)\t\n",
      "  batch 11050 loss: 2.4495582389831543\n",
      "Epoch: [1][11050/17600]\tTime 1.1783738136291504 (1.1917236198019658)\tData 1.160963773727417 (1.1735495447788842)\t\n",
      "  batch 11100 loss: 2.2215262413024903\n",
      "Epoch: [1][11100/17600]\tTime 1.2807269096374512 (1.191110705642013)\tData 1.2631378173828125 (1.172938636530627)\t\n",
      "  batch 11150 loss: 2.4688639068603515\n",
      "Epoch: [1][11150/17600]\tTime 0.999614953994751 (1.1911359816709441)\tData 0.9816689491271973 (1.1729646450949356)\t\n",
      "  batch 11200 loss: 1.877016544342041\n",
      "Epoch: [1][11200/17600]\tTime 1.382497787475586 (1.1904845721381052)\tData 1.3648722171783447 (1.1723156295716763)\t\n",
      "  batch 11250 loss: 2.23332332611084\n",
      "Epoch: [1][11250/17600]\tTime 0.9037163257598877 (1.1900691415362887)\tData 0.8849804401397705 (1.1719017143885295)\t\n",
      "  batch 11300 loss: 2.6397183036804197\n",
      "Epoch: [1][11300/17600]\tTime 1.4685883522033691 (1.1899877193121784)\tData 1.4508731365203857 (1.1718209052085877)\t\n",
      "  batch 11350 loss: 2.186008949279785\n",
      "Epoch: [1][11350/17600]\tTime 1.25830078125 (1.1898988356779325)\tData 1.2407474517822266 (1.1717343147630734)\t\n",
      "  batch 11400 loss: 1.9276313591003418\n",
      "Epoch: [1][11400/17600]\tTime 0.7744114398956299 (1.1898501527309417)\tData 0.7567980289459229 (1.1716875220390788)\t\n",
      "  batch 11450 loss: 1.8013558959960938\n",
      "Epoch: [1][11450/17600]\tTime 1.2176949977874756 (1.1896364969145263)\tData 1.1997764110565186 (1.1714752246823372)\t\n",
      "  batch 11500 loss: 2.1424148750305174\n",
      "Epoch: [1][11500/17600]\tTime 1.0615315437316895 (1.1894648041932478)\tData 1.0439631938934326 (1.1713046254489732)\t\n",
      "  batch 11550 loss: 2.3310712814331054\n",
      "Epoch: [1][11550/17600]\tTime 1.3474977016448975 (1.1895537108673162)\tData 1.3297457695007324 (1.171395566432507)\t\n",
      "  batch 11600 loss: 2.222030563354492\n",
      "Epoch: [1][11600/17600]\tTime 1.583392858505249 (1.189408084976262)\tData 1.5627832412719727 (1.1712515621349728)\t\n",
      "  batch 11650 loss: 2.3405134582519533\n",
      "Epoch: [1][11650/17600]\tTime 0.9616794586181641 (1.1893761715049906)\tData 0.9439451694488525 (1.1712211249110014)\t\n",
      "  batch 11700 loss: 2.365408763885498\n",
      "Epoch: [1][11700/17600]\tTime 1.0298206806182861 (1.1891029530101351)\tData 1.0121700763702393 (1.1709477961165273)\t\n",
      "  batch 11750 loss: 2.064996738433838\n",
      "Epoch: [1][11750/17600]\tTime 0.9309830665588379 (1.1890041870563588)\tData 0.9132280349731445 (1.1708484308567453)\t\n",
      "  batch 11800 loss: 2.553841304779053\n",
      "Epoch: [1][11800/17600]\tTime 1.260723352432251 (1.188720198425196)\tData 1.2428898811340332 (1.1705660600177312)\t\n",
      "  batch 11850 loss: 2.3862878608703615\n",
      "Epoch: [1][11850/17600]\tTime 0.9596874713897705 (1.1887458054425848)\tData 0.9406378269195557 (1.1705932030496717)\t\n",
      "  batch 11900 loss: 2.316165256500244\n",
      "Epoch: [1][11900/17600]\tTime 1.6046793460845947 (1.1888983591264035)\tData 1.587252140045166 (1.1707476420362457)\t\n",
      "  batch 11950 loss: 2.501518669128418\n",
      "Epoch: [1][11950/17600]\tTime 1.3649346828460693 (1.1886642777470864)\tData 1.347156286239624 (1.1705155584901945)\t\n",
      "  batch 12000 loss: 2.863421459197998\n",
      "Epoch: [1][12000/17600]\tTime 1.3811135292053223 (1.1888924406766892)\tData 1.3633434772491455 (1.1707448256015778)\t\n",
      "  batch 12050 loss: 2.6384801483154297\n",
      "Epoch: [1][12050/17600]\tTime 1.1886959075927734 (1.1886888852257946)\tData 1.171022891998291 (1.1705424035337455)\t\n",
      "  batch 12100 loss: 2.3944157218933104\n",
      "Epoch: [1][12100/17600]\tTime 0.780125617980957 (1.188293090871543)\tData 0.7611474990844727 (1.1701466274261474)\t\n",
      "  batch 12150 loss: 2.6247847175598142\n",
      "Epoch: [1][12150/17600]\tTime 1.242136001586914 (1.1883392020017522)\tData 1.2245657444000244 (1.1701927679752617)\t\n",
      "  batch 12200 loss: 2.0791132926940916\n",
      "Epoch: [1][12200/17600]\tTime 1.2027783393859863 (1.1882035498736334)\tData 1.1849753856658936 (1.1700587315442132)\t\n",
      "  batch 12250 loss: 2.0595792388916014\n",
      "Epoch: [1][12250/17600]\tTime 1.2418735027313232 (1.1882201464322149)\tData 1.2241196632385254 (1.1700768329659286)\t\n",
      "  batch 12300 loss: 2.1827771949768064\n",
      "Epoch: [1][12300/17600]\tTime 1.4149930477142334 (1.188370302208071)\tData 1.3972110748291016 (1.170228426882891)\t\n",
      "  batch 12350 loss: 2.3687307357788088\n",
      "Epoch: [1][12350/17600]\tTime 1.0632498264312744 (1.188270427669108)\tData 1.0457243919372559 (1.170130140269816)\t\n",
      "  batch 12400 loss: 2.817388553619385\n",
      "Epoch: [1][12400/17600]\tTime 1.2256708145141602 (1.1885645741608835)\tData 1.2079548835754395 (1.170426181093339)\t\n",
      "  batch 12450 loss: 2.539942512512207\n",
      "Epoch: [1][12450/17600]\tTime 1.3815116882324219 (1.1886184238142756)\tData 1.3637611865997314 (1.170481788891865)\t\n",
      "  batch 12500 loss: 2.64450740814209\n",
      "Epoch: [1][12500/17600]\tTime 1.3192594051361084 (1.188696943359375)\tData 1.3014895915985107 (1.1705618201828003)\t\n",
      "  batch 12550 loss: 2.502919464111328\n",
      "Epoch: [1][12550/17600]\tTime 1.2379417419433594 (1.1887782931042858)\tData 1.2202439308166504 (1.1706449882347745)\t\n",
      "  batch 12600 loss: 2.5757970428466797\n",
      "Epoch: [1][12600/17600]\tTime 0.7617702484130859 (1.1887586196452853)\tData 0.7441587448120117 (1.170626897528058)\t\n",
      "  batch 12650 loss: 2.308289604187012\n",
      "Epoch: [1][12650/17600]\tTime 1.3715825080871582 (1.1887761645260535)\tData 1.3540008068084717 (1.1706454277792466)\t\n",
      "  batch 12700 loss: 2.1878280639648438\n",
      "Epoch: [1][12700/17600]\tTime 1.1473641395568848 (1.1888567090034485)\tData 1.1292617321014404 (1.1707277970426664)\t\n",
      "  batch 12750 loss: 2.2681150817871094\n",
      "Epoch: [1][12750/17600]\tTime 1.8138628005981445 (1.1890516137328802)\tData 1.7959599494934082 (1.170924109066234)\t\n",
      "  batch 12800 loss: 2.2750960540771485\n",
      "Epoch: [1][12800/17600]\tTime 1.0081028938293457 (1.1893091763742267)\tData 0.9902760982513428 (1.1711828144825995)\t\n",
      "  batch 12850 loss: 2.2499312019348143\n",
      "Epoch: [1][12850/17600]\tTime 2.2325246334075928 (1.1890309344377035)\tData 2.2146964073181152 (1.1709060653731054)\t\n",
      "  batch 12900 loss: 1.8459837341308594\n",
      "Epoch: [1][12900/17600]\tTime 1.5639820098876953 (1.1893360104671744)\tData 1.546227216720581 (1.1712120432816735)\t\n",
      "  batch 12950 loss: 2.29874418258667\n",
      "Epoch: [1][12950/17600]\tTime 2.0378530025482178 (1.1897598188356082)\tData 2.0202155113220215 (1.171636869769299)\t\n",
      "  batch 13000 loss: 2.259695415496826\n",
      "Epoch: [1][13000/17600]\tTime 0.9768610000610352 (1.1896894463209005)\tData 0.9587142467498779 (1.17156744654362)\t\n",
      "  batch 13050 loss: 1.9509216499328614\n",
      "Epoch: [1][13050/17600]\tTime 1.370434284210205 (1.1898306193479633)\tData 1.351344108581543 (1.171708271147191)\t\n",
      "  batch 13100 loss: 2.2202063751220704\n",
      "Epoch: [1][13100/17600]\tTime 1.4849538803100586 (1.1897718962458255)\tData 1.467209815979004 (1.1716506490634597)\t\n",
      "  batch 13150 loss: 2.3103590774536134\n",
      "Epoch: [1][13150/17600]\tTime 0.9795529842376709 (1.1897791589258289)\tData 0.961967945098877 (1.1716579879826012)\t\n",
      "  batch 13200 loss: 2.251173458099365\n",
      "Epoch: [1][13200/17600]\tTime 1.4822967052459717 (1.189678598263047)\tData 1.4646422863006592 (1.1715565979480744)\t\n",
      "  batch 13250 loss: 2.3101095008850097\n",
      "Epoch: [1][13250/17600]\tTime 0.9407296180725098 (1.1896225894352175)\tData 0.9227159023284912 (1.1715019187567368)\t\n",
      "  batch 13300 loss: 2.0123169517517088\n",
      "Epoch: [1][13300/17600]\tTime 1.2197189331054688 (1.189712315555802)\tData 1.20233154296875 (1.1715919467201807)\t\n",
      "  batch 13350 loss: 2.592997417449951\n",
      "Epoch: [1][13350/17600]\tTime 1.1429600715637207 (1.189850449651368)\tData 1.1250078678131104 (1.1717319284574816)\t\n",
      "  batch 13400 loss: 2.173094482421875\n",
      "Epoch: [1][13400/17600]\tTime 0.9504086971282959 (1.1898587196976391)\tData 0.931208610534668 (1.171740570175114)\t\n",
      "  batch 13450 loss: 2.2537082290649413\n",
      "Epoch: [1][13450/17600]\tTime 1.9355227947235107 (1.1900592447656682)\tData 1.9178674221038818 (1.1719425848425542)\t\n",
      "  batch 13500 loss: 2.1164248275756834\n",
      "Epoch: [1][13500/17600]\tTime 1.1988122463226318 (1.1903350586891175)\tData 1.1809163093566895 (1.172220086009414)\t\n",
      "  batch 13550 loss: 2.353076248168945\n",
      "Epoch: [1][13550/17600]\tTime 1.595365047454834 (1.190432667327543)\tData 1.5777511596679688 (1.1723186716030445)\t\n",
      "  batch 13600 loss: 2.7362446212768554\n",
      "Epoch: [1][13600/17600]\tTime 1.5131971836090088 (1.1905465946127387)\tData 1.4955353736877441 (1.1724333928788409)\t\n",
      "  batch 13650 loss: 2.3725185775756836\n",
      "Epoch: [1][13650/17600]\tTime 1.0255751609802246 (1.1907029367977884)\tData 1.0077688694000244 (1.1725909642509489)\t\n",
      "  batch 13700 loss: 2.274484329223633\n",
      "Epoch: [1][13700/17600]\tTime 1.739187240600586 (1.1906219755472058)\tData 1.7217133045196533 (1.1725105385188639)\t\n",
      "  batch 13750 loss: 1.9205536460876464\n",
      "Epoch: [1][13750/17600]\tTime 1.385338544845581 (1.190501039539684)\tData 1.3676533699035645 (1.1723891180211847)\t\n",
      "  batch 13800 loss: 2.1725972175598143\n",
      "Epoch: [1][13800/17600]\tTime 1.2070364952087402 (1.1906524325972019)\tData 1.189476728439331 (1.1725414038913837)\t\n",
      "  batch 13850 loss: 2.316339416503906\n",
      "Epoch: [1][13850/17600]\tTime 0.9930365085601807 (1.1906584286087256)\tData 0.9744582176208496 (1.1725460851063367)\t\n",
      "  batch 13900 loss: 2.8790258598327636\n",
      "Epoch: [1][13900/17600]\tTime 0.8834977149963379 (1.190854187886492)\tData 0.8657126426696777 (1.172742764795427)\t\n",
      "  batch 13950 loss: 2.2478450775146483\n",
      "Epoch: [1][13950/17600]\tTime 0.8181440830230713 (1.190860163131495)\tData 0.8004124164581299 (1.172748854493582)\t\n",
      "  batch 14000 loss: 2.0921971702575686\n",
      "Epoch: [1][14000/17600]\tTime 1.1872100830078125 (1.1910490236963545)\tData 1.1697754859924316 (1.1729386171443121)\t\n",
      "  batch 14050 loss: 1.9398120498657228\n",
      "Epoch: [1][14050/17600]\tTime 2.0719974040985107 (1.191169909955768)\tData 2.0543224811553955 (1.1730590054827652)\t\n",
      "  batch 14100 loss: 1.6042585182189941\n",
      "Epoch: [1][14100/17600]\tTime 1.209873914718628 (1.191035474902349)\tData 1.192399263381958 (1.1729264477296923)\t\n",
      "  batch 14150 loss: 1.7067189598083496\n",
      "Epoch: [1][14150/17600]\tTime 1.6090619564056396 (1.1909981710076754)\tData 1.5913820266723633 (1.1728909118099684)\t\n",
      "  batch 14200 loss: 2.0510679054260255\n",
      "Epoch: [1][14200/17600]\tTime 1.1113231182098389 (1.191045557545944)\tData 1.0936646461486816 (1.1729401091790534)\t\n",
      "  batch 14250 loss: 2.2115924644470213\n",
      "Epoch: [1][14250/17600]\tTime 0.9073069095611572 (1.1912984444300334)\tData 0.8896489143371582 (1.173193766460084)\t\n",
      "  batch 14300 loss: 2.0922888946533202\n",
      "Epoch: [1][14300/17600]\tTime 1.0068066120147705 (1.1912868818536504)\tData 0.9892330169677734 (1.1731822683594444)\t\n",
      "  batch 14350 loss: 1.9225049018859863\n",
      "Epoch: [1][14350/17600]\tTime 0.9977648258209229 (1.1912440593400484)\tData 0.9802491664886475 (1.1731378977639335)\t\n",
      "  batch 14400 loss: 2.1912261962890627\n",
      "Epoch: [1][14400/17600]\tTime 1.2227809429168701 (1.1912947924931845)\tData 1.2039003372192383 (1.1731894604033895)\t\n",
      "  batch 14450 loss: 2.1874333572387696\n",
      "Epoch: [1][14450/17600]\tTime 1.662672996520996 (1.1913284406859983)\tData 1.6407725811004639 (1.173224140583025)\t\n",
      "  batch 14500 loss: 2.125603427886963\n",
      "Epoch: [1][14500/17600]\tTime 1.6101436614990234 (1.1913657842997847)\tData 1.5924959182739258 (1.1732630862531992)\t\n",
      "  batch 14550 loss: 2.3935587882995604\n",
      "Epoch: [1][14550/17600]\tTime 1.1261951923370361 (1.1915425910327033)\tData 1.108454942703247 (1.1734412477598157)\t\n",
      "  batch 14600 loss: 2.941566352844238\n",
      "Epoch: [1][14600/17600]\tTime 0.9787378311157227 (1.1914162837479212)\tData 0.9612395763397217 (1.1733139382976374)\t\n",
      "  batch 14650 loss: 2.656605911254883\n",
      "Epoch: [1][14650/17600]\tTime 1.5827927589416504 (1.1916598684226287)\tData 1.565176248550415 (1.1735579463809016)\t\n",
      "  batch 14700 loss: 1.892801856994629\n",
      "Epoch: [1][14700/17600]\tTime 0.9047329425811768 (1.1915615102709556)\tData 0.8871986865997314 (1.173459495492533)\t\n",
      "  batch 14750 loss: 2.1248178672790528\n",
      "Epoch: [1][14750/17600]\tTime 1.253504991531372 (1.1914713989839716)\tData 1.2357451915740967 (1.1733710185067128)\t\n",
      "  batch 14800 loss: 2.5294189643859863\n",
      "Epoch: [1][14800/17600]\tTime 1.242333173751831 (1.1914513802045101)\tData 1.223757266998291 (1.1733520889282227)\t\n",
      "  batch 14850 loss: 2.55850793838501\n",
      "Epoch: [1][14850/17600]\tTime 0.8764078617095947 (1.1917454376445475)\tData 0.8587448596954346 (1.1736449998316139)\t\n",
      "  batch 14900 loss: 2.390986976623535\n",
      "Epoch: [1][14900/17600]\tTime 1.5018806457519531 (1.1920324846722135)\tData 1.4842462539672852 (1.1739330373034382)\t\n",
      "  batch 14950 loss: 2.241143894195557\n",
      "Epoch: [1][14950/17600]\tTime 1.3820922374725342 (1.1919676385037477)\tData 1.3642113208770752 (1.1738689697705782)\t\n",
      "  batch 15000 loss: 2.482188415527344\n",
      "Epoch: [1][15000/17600]\tTime 0.9338338375091553 (1.192186916399002)\tData 0.9163758754730225 (1.1740898164908091)\t\n",
      "  batch 15050 loss: 2.0568712043762205\n",
      "Epoch: [1][15050/17600]\tTime 1.3845551013946533 (1.192047400015137)\tData 1.3669707775115967 (1.1739514094729757)\t\n",
      "  batch 15100 loss: 2.4099177932739257\n",
      "Epoch: [1][15100/17600]\tTime 1.5087518692016602 (1.191899105681489)\tData 1.491025447845459 (1.1738037123585379)\t\n",
      "  batch 15150 loss: 1.7088755035400391\n",
      "Epoch: [1][15150/17600]\tTime 0.8974285125732422 (1.191865167240105)\tData 0.8798656463623047 (1.1737711829478197)\t\n",
      "  batch 15200 loss: 2.215221977233887\n",
      "Epoch: [1][15200/17600]\tTime 0.9601750373840332 (1.1918612282997683)\tData 0.9427375793457031 (1.1737686092445725)\t\n",
      "  batch 15250 loss: 1.9472923278808594\n",
      "Epoch: [1][15250/17600]\tTime 2.366987943649292 (1.1920394623553168)\tData 2.349210262298584 (1.1739479753932014)\t\n",
      "  batch 15300 loss: 2.1859698486328125\n",
      "Epoch: [1][15300/17600]\tTime 1.1327407360076904 (1.1920364292306838)\tData 1.1151275634765625 (1.173944593769273)\t\n",
      "  batch 15350 loss: 2.1844644927978516\n",
      "Epoch: [1][15350/17600]\tTime 1.1853947639465332 (1.1918729432009718)\tData 1.1679601669311523 (1.1737824215562802)\t\n",
      "  batch 15400 loss: 2.637330341339111\n",
      "Epoch: [1][15400/17600]\tTime 0.985358715057373 (1.1918260485320897)\tData 0.9678702354431152 (1.1737370200745472)\t\n",
      "  batch 15450 loss: 2.1356611824035645\n",
      "Epoch: [1][15450/17600]\tTime 0.7904999256134033 (1.1917362819288926)\tData 0.772956132888794 (1.1736486794184713)\t\n",
      "  batch 15500 loss: 2.3302789688110352\n",
      "Epoch: [1][15500/17600]\tTime 1.7155089378356934 (1.191907539136948)\tData 1.6979095935821533 (1.173821176298203)\t\n",
      "  batch 15550 loss: 1.8371879196166991\n",
      "Epoch: [1][15550/17600]\tTime 1.0434186458587646 (1.1919526457096603)\tData 1.0257453918457031 (1.1738676796235457)\t\n",
      "  batch 15600 loss: 1.9792271423339844\n",
      "Epoch: [1][15600/17600]\tTime 1.5281836986541748 (1.1918289878276678)\tData 1.5104899406433105 (1.1737447506342178)\t\n",
      "  batch 15650 loss: 2.0341079521179197\n",
      "Epoch: [1][15650/17600]\tTime 0.9018912315368652 (1.1917441526997965)\tData 0.8784966468811035 (1.1736611167158182)\t\n",
      "  batch 15700 loss: 2.3141978645324706\n",
      "Epoch: [1][15700/17600]\tTime 1.6256704330444336 (1.1918206840108154)\tData 1.6080825328826904 (1.1737388928528805)\t\n",
      "  batch 15750 loss: 2.4427974700927733\n",
      "Epoch: [1][15750/17600]\tTime 1.2171947956085205 (1.1917709128364684)\tData 1.1995084285736084 (1.1736905471559556)\t\n",
      "  batch 15800 loss: 2.841341552734375\n",
      "Epoch: [1][15800/17600]\tTime 0.9936063289642334 (1.1914029668705373)\tData 0.9759998321533203 (1.1733240411854997)\t\n",
      "  batch 15850 loss: 2.095540885925293\n",
      "Epoch: [1][15850/17600]\tTime 1.4750287532806396 (1.1913040373227575)\tData 1.453805923461914 (1.1732255205371027)\t\n",
      "  batch 15900 loss: 2.0130147743225097\n",
      "Epoch: [1][15900/17600]\tTime 1.0119900703430176 (1.1912600973567122)\tData 0.9941933155059814 (1.1731828048244213)\t\n",
      "  batch 15950 loss: 1.9746844100952148\n",
      "Epoch: [1][15950/17600]\tTime 1.0867748260498047 (1.1911200372103987)\tData 1.0692346096038818 (1.1730440846954393)\t\n",
      "  batch 16000 loss: 2.10156551361084\n",
      "Epoch: [1][16000/17600]\tTime 1.0021381378173828 (1.1911799143254758)\tData 0.9831676483154297 (1.1731028569936752)\t\n",
      "  batch 16050 loss: 2.110824718475342\n",
      "Epoch: [1][16050/17600]\tTime 1.34757399559021 (1.1909943412174688)\tData 1.329972743988037 (1.1729167366622022)\t\n",
      "  batch 16100 loss: 2.385477352142334\n",
      "Epoch: [1][16100/17600]\tTime 1.6300864219665527 (1.1911409290680974)\tData 1.6122851371765137 (1.173064303294472)\t\n",
      "  batch 16150 loss: 2.332144718170166\n",
      "Epoch: [1][16150/17600]\tTime 1.2037687301635742 (1.191258078787718)\tData 1.1860077381134033 (1.1731814239785399)\t\n",
      "  batch 16200 loss: 2.1444097328186036\n",
      "Epoch: [1][16200/17600]\tTime 1.4037435054779053 (1.1911260283876348)\tData 1.3860220909118652 (1.1730498825326379)\t\n",
      "  batch 16250 loss: 2.5434531021118163\n",
      "Epoch: [1][16250/17600]\tTime 1.2571947574615479 (1.1909305530988252)\tData 1.2394931316375732 (1.1728552402936496)\t\n",
      "  batch 16300 loss: 1.7681503105163574\n",
      "Epoch: [1][16300/17600]\tTime 0.9097588062286377 (1.1907752865223797)\tData 0.8922469615936279 (1.1727009649803302)\t\n",
      "  batch 16350 loss: 2.025654926300049\n",
      "Epoch: [1][16350/17600]\tTime 1.2630982398986816 (1.1907430880951955)\tData 1.2454137802124023 (1.1726701269383095)\t\n",
      "  batch 16400 loss: 2.3565023612976073\n",
      "Epoch: [1][16400/17600]\tTime 1.262481689453125 (1.1910246499718689)\tData 1.2447683811187744 (1.172953129338055)\t\n",
      "  batch 16450 loss: 2.265766716003418\n",
      "Epoch: [1][16450/17600]\tTime 1.1205878257751465 (1.1911164458834291)\tData 1.103193759918213 (1.1730463042302697)\t\n",
      "  batch 16500 loss: 2.0912760162353514\n",
      "Epoch: [1][16500/17600]\tTime 1.219198226928711 (1.1909533594882848)\tData 1.201805591583252 (1.172884293194973)\t\n",
      "  batch 16550 loss: 2.0245071601867677\n",
      "Epoch: [1][16550/17600]\tTime 1.0050055980682373 (1.191003221889277)\tData 0.9872779846191406 (1.1729344692114978)\t\n",
      "  batch 16600 loss: 2.541485652923584\n",
      "Epoch: [1][16600/17600]\tTime 1.1904399394989014 (1.1911089069297516)\tData 1.1729514598846436 (1.1730412952009455)\t\n",
      "  batch 16650 loss: 2.300503578186035\n",
      "Epoch: [1][16650/17600]\tTime 0.9676773548126221 (1.1912327470865336)\tData 0.9500281810760498 (1.1731659449471368)\t\n",
      "  batch 16700 loss: 2.0972551918029785\n",
      "Epoch: [1][16700/17600]\tTime 1.0312175750732422 (1.1912531083501028)\tData 1.0115716457366943 (1.1731869921570053)\t\n",
      "  batch 16750 loss: 2.3243532180786133\n",
      "Epoch: [1][16750/17600]\tTime 1.6080052852630615 (1.1911149055281682)\tData 1.5904431343078613 (1.173049779820798)\t\n",
      "  batch 16800 loss: 1.9751774597167968\n",
      "Epoch: [1][16800/17600]\tTime 1.0216224193572998 (1.1909411817221414)\tData 1.0039823055267334 (1.1728768729170163)\t\n",
      "  batch 16850 loss: 2.552218647003174\n",
      "Epoch: [1][16850/17600]\tTime 1.1297869682312012 (1.1909555976963893)\tData 1.1109938621520996 (1.1728923438352363)\t\n",
      "  batch 16900 loss: 1.8023420143127442\n",
      "Epoch: [1][16900/17600]\tTime 1.389249563217163 (1.1909577502442534)\tData 1.371535301208496 (1.1728940110516972)\t\n",
      "  batch 16950 loss: 2.221843414306641\n",
      "Epoch: [1][16950/17600]\tTime 0.85207200050354 (1.190805559552173)\tData 0.8344008922576904 (1.1727429578437918)\t\n",
      "  batch 17000 loss: 2.204527187347412\n",
      "Epoch: [1][17000/17600]\tTime 1.3512117862701416 (1.1907741207795985)\tData 1.3336312770843506 (1.1727125238671023)\t\n",
      "  batch 17050 loss: 2.0517811965942383\n",
      "Epoch: [1][17050/17600]\tTime 1.0447556972503662 (1.1908558420281956)\tData 1.0272722244262695 (1.1727953193474374)\t\n",
      "  batch 17100 loss: 1.9763455772399903\n",
      "Epoch: [1][17100/17600]\tTime 1.0998508930206299 (1.190888085518664)\tData 1.0822532176971436 (1.1728287144292864)\t\n",
      "  batch 17150 loss: 1.8396319770812988\n",
      "Epoch: [1][17150/17600]\tTime 1.351834774017334 (1.1910993541850987)\tData 1.3343770503997803 (1.1730407049218003)\t\n",
      "  batch 17200 loss: 1.906627712249756\n",
      "Epoch: [1][17200/17600]\tTime 1.2776012420654297 (1.1909945332172305)\tData 1.2599289417266846 (1.1729370951791143)\t\n",
      "  batch 17250 loss: 2.2038353157043455\n",
      "Epoch: [1][17250/17600]\tTime 1.1537063121795654 (1.191118050146794)\tData 1.1362135410308838 (1.1730618406516917)\t\n",
      "  batch 17300 loss: 1.7946329498291016\n",
      "Epoch: [1][17300/17600]\tTime 1.3303422927856445 (1.1910981506005878)\tData 1.312685251235962 (1.1730432912242206)\t\n",
      "  batch 17350 loss: 1.9533511734008788\n",
      "Epoch: [1][17350/17600]\tTime 0.8113560676574707 (1.191147225638288)\tData 0.7927699089050293 (1.173091902045764)\t\n",
      "  batch 17400 loss: 1.8872174644470214\n",
      "Epoch: [1][17400/17600]\tTime 1.3222124576568604 (1.19119999174414)\tData 1.304750680923462 (1.1731454913780608)\t\n",
      "  batch 17450 loss: 2.2139062690734863\n",
      "Epoch: [1][17450/17600]\tTime 1.1099212169647217 (1.1910375250513028)\tData 1.0923867225646973 (1.172983902914818)\t\n",
      "  batch 17500 loss: 2.021024074554443\n",
      "Epoch: [1][17500/17600]\tTime 1.1143341064453125 (1.19124955670493)\tData 1.0967586040496826 (1.17319576688494)\t\n",
      "  batch 17550 loss: 1.9678034782409668\n",
      "Epoch: [1][17550/17600]\tTime 1.1507914066314697 (1.1910892600143737)\tData 1.1333062648773193 (1.1730356921497573)\t\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (14) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d938911eaa1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtriplet_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     save_dict = {\n",
      "\u001b[0;32m<ipython-input-16-d1f08352405b>\u001b[0m in \u001b[0;36mtriplet_train\u001b[0;34m(triplet_loader, img_model, text_model, criterion, optimizer_image, optimizer_text, optimizer_total, epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mneg_output_ingredients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mneg_encoded_ingredients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             loss = criterion(image_encodings[\"last_hidden_state\"][:, 0, :], pos_output_ingredients[\"last_hidden_state\"][:, 0, :], \n\u001b[0m\u001b[1;32m     33\u001b[0m                              neg_output_ingredients[\"last_hidden_state\"][:, 0, :])\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, anchor, positive, negative)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m         return F.triplet_margin_loss(anchor, positive, negative, margin=self.margin, p=self.p,\n\u001b[0m\u001b[1;32m   1484\u001b[0m                                      eps=self.eps, swap=self.swap, reduction=self.reduction)\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mtriplet_margin_loss\u001b[0;34m(anchor, positive, negative, margin, p, eps, swap, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   4558\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4559\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4560\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriplet_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (14) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    triplet_train(triplet_train_loader, img_model, text_model, criterion, optimizer_image, optimizer_text, optimizer_total, epoch)\n",
    "    \n",
    "    save_dict = {\n",
    "        \"image_vit_encoder\": img_model.state_dict(),\n",
    "        \"text_encoder\": text_model.state_dict(),\n",
    "    }\n",
    "    \n",
    "    torch.save(save_dict, f'/common/users/kcm161/step3_models_instructions_onlytriplet_e{epoch}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Embeddings - ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "img_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in img_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in img_model.encoder.layer[11].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in img_model.layernorm.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in img_model.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "img_model = nn.DataParallel(img_model, device_ids = [0])\n",
    "img_model = img_model.to(f'cuda:{img_model.device_ids[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embeddings - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "for param in text_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in text_model.encoder.layer[11].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in text_model.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "text_model = nn.DataParallel(text_model, device_ids = [0])\n",
    "text_model = text_model.to(f'cuda:{text_model.device_ids[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ViT and BERT weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_weights = torch.load(\"/common/users/kcm161/step3_models_instructions_onlytriplet_e1.pt\", map_location = \"cuda:0\")\n",
    "\n",
    "img_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "for param in img_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "img_model = nn.DataParallel(img_model, device_ids = [0])\n",
    "img_model.load_state_dict(model_weights[\"image_vit_encoder\"])\n",
    "img_model = img_model.to(f'cuda:{img_model.device_ids[0]}')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "for param in text_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "text_model = nn.DataParallel(text_model, device_ids = [0])\n",
    "text_model.load_state_dict(model_weights[\"text_encoder\"])\n",
    "text_model = text_model.to(f'cuda:{text_model.device_ids[0]}')\n",
    "\n",
    "optimizer_image = torch.optim.Adam(img_model.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "optimizer_text = torch.optim.Adam(text_model.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "\n",
    "optimizer_total = torch.optim.Adam(list(text_model.parameters()) + list(img_model.parameters()), lr=1e-4, weight_decay=0.0)\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "criterion.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout = 0.1, max_len = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout( p = dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        pe = torch.transpose(pe, 0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[0, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossModalAttention(nn.Module):\n",
    "    def __init__(self, model_dim = 768, n_heads = 2, n_layers = 2, num_image_patches = 197, num_classes = 2, drop_rate = 0.1):\n",
    "        super().__init__()\n",
    "        self.text_positional = SinusoidalPositionalEncoding(model_dim, dropout= drop_rate)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, model_dim))\n",
    "        self.sep_token = nn.Parameter(torch.zeros(1, 1, model_dim))\n",
    "        self.image_positional = nn.Parameter(torch.zeros(1, num_image_patches + 1, model_dim))\n",
    "        self.image_positional_drop = nn.Dropout(p = drop_rate)\n",
    "        layers = nn.TransformerEncoderLayer(d_model = model_dim, nhead = n_heads, batch_first= True)\n",
    "        self.encoder = nn.TransformerEncoder(layers, num_layers = n_layers)\n",
    "        self.cls_projection = nn.Linear(model_dim, num_classes)\n",
    "\n",
    "    def forward(self, image_features, text_features, src_key_padding_mask = None):\n",
    "        # image_features = image_features.to(device)\n",
    "\n",
    "        image_features *= math.sqrt(768)\n",
    "        text_features *= math.sqrt(768)\n",
    "\n",
    "        batch_size = image_features.shape[0]\n",
    "\n",
    "        cls_token = self.cls_token.expand(batch_size, -1, -1)\n",
    "        image_features = torch.cat((cls_token, image_features), dim = 1)\n",
    "        image_features = image_features + self.image_positional\n",
    "        image_features = self.image_positional_drop(image_features)\n",
    "\n",
    "        text_features = self.text_positional(text_features)\n",
    "        sep_token = self.sep_token.expand(batch_size, -1, -1)\n",
    "\n",
    "        transformer_input = torch.cat((image_features, sep_token, text_features), dim = 1)\n",
    "        if src_key_padding_mask is not None:\n",
    "            src_key_padding_mask = torch.cat((torch.zeros(image_features.shape[0], image_features.shape[1] + 1).to(f'cuda:{transformer.device_ids[0]}'), \n",
    "                                              src_key_padding_mask.to(f'cuda:{transformer.device_ids[0]}')), dim  = 1)\n",
    "\n",
    "        transformer_outputs = self.encoder(transformer_input, src_key_padding_mask = src_key_padding_mask)\n",
    "        projected_output = transformer_outputs[:, 0, :]\n",
    "        \n",
    "        return self.cls_projection(projected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = CrossModalAttention()\n",
    "transformer = nn.DataParallel(transformer, device_ids=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    # Utility function for timers\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_image = torch.optim.SGD(img_model.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "optimizer_text = torch.optim.SGD(text_model.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "optimizer_transformer = torch.optim.SGD(transformer.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "img_model.to(device);\n",
    "text_model.to(device);\n",
    "transformer.to(device);\n",
    "criterion.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train(train_loader, img_model, text_model, transformer, criterion, optimizer_image, optimizer_text, optimizer_transformer, epoch):\n",
    "    print('Starting training epoch {}'.format(epoch))\n",
    "    img_model.train()\n",
    "    text_model.train()\n",
    "    transformer.train()\n",
    "    \n",
    "    batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    optimizer_image.zero_grad()\n",
    "    optimizer_text.zero_grad()\n",
    "    optimizer_transformer.zero_grad()\n",
    "    \n",
    "    train_loss, total_samples, running_loss = 0, 0, 0\n",
    "    \n",
    "    batch = 1\n",
    "    \n",
    "    with tqdm(total = len(train_loader)) as pbar:\n",
    "        for img, text in train_loader:\n",
    "        \n",
    "            # Run forward pass\n",
    "    #         print(img.shape)\n",
    "            image_encodings = img_model(img.to(f'cuda:{text_model.device_ids[0]}'))\n",
    "\n",
    "            encoded_ingredients = tokenizer(text, return_tensors='pt', max_length=512, truncation = True, padding = True).to(f'cuda:{text_model.device_ids[0]}')\n",
    "            output_ingredients = text_model(**encoded_ingredients)\n",
    "\n",
    "            transformer_image_inputs, transformer_text_inputs, output_attention_mask, ground_truth = get_transformer_input (image_encodings[\"last_hidden_state\"], \n",
    "                                                                                                                            output_ingredients[\"last_hidden_state\"], \n",
    "                                                                                                                            encoded_ingredients.attention_mask)\n",
    "            text_padding_mask = ~output_attention_mask.bool()\n",
    "            outputs = transformer(transformer_image_inputs.to(f'cuda:{transformer.device_ids[0]}'), transformer_text_inputs.to(f'cuda:{transformer.device_ids[0]}'), \n",
    "                                  text_padding_mask.to(f'cuda:{transformer.device_ids[0]}'))\n",
    "\n",
    "            loss = criterion(outputs, ground_truth.to(f'cuda:{transformer.device_ids[0]}')) \n",
    "\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            # Compute gradient and optimize\n",
    "            optimizer_image.zero_grad()\n",
    "            optimizer_text.zero_grad()\n",
    "            optimizer_transformer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer_image.step()\n",
    "            optimizer_text.step()\n",
    "            optimizer_transformer.step()\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            running_loss += loss.item() * img.shape[0]\n",
    "            total_samples += img.shape[0]\n",
    "\n",
    "            train_loss += running_loss\n",
    "\n",
    "            if batch % 50 == 0:\n",
    "                print('  batch {} loss: {}'.format(batch, running_loss / 50))\n",
    "                running_loss = 0.\n",
    "\n",
    "            if batch % 50 == 0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                    'Time {batch_time.val} ({batch_time.avg})\\t'\n",
    "                    'Data {data_time.val} ({data_time.avg})\\t'.format(\n",
    "                      epoch, batch, len(train_loader), batch_time=batch_time,\n",
    "                     data_time=data_time)) \n",
    "                pbar.update(50)\n",
    "\n",
    "            batch += 1\n",
    "\n",
    "        print('Finished training epoch {}'.format(epoch))\n",
    "        print('Epoch Loss:', train_loss / total_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_input(image_features, text_features, input_attention_mask):\n",
    "    neg_to_pos_ratio = 2\n",
    "    \n",
    "    input_batch_size = image_features.shape[0]\n",
    "    output_batch_size = (neg_to_pos_ratio + 1) * input_batch_size\n",
    "    ground_truths = torch.zeros(output_batch_size)\n",
    "    ground_truths[:input_batch_size] = 1\n",
    "        \n",
    "    final_image_features = torch.zeros(output_batch_size, *image_features.shape[1:])\n",
    "    final_text_features = torch.zeros(output_batch_size, *text_features.shape[1:])\n",
    "    output_attention_mask = torch.zeros(output_batch_size, *input_attention_mask.shape[1:])\n",
    "    \n",
    "    final_image_features[: input_batch_size] = image_features\n",
    "    final_text_features[:input_batch_size] = text_features\n",
    "    output_attention_mask[:input_batch_size] = input_attention_mask\n",
    "    \n",
    "    for n in range(neg_to_pos_ratio):\n",
    "        a = torch.randperm(input_batch_size)\n",
    "        b = torch.zeros(input_batch_size).to(dtype = torch.int64)\n",
    "        \n",
    "        for idx in range(input_batch_size):\n",
    "            c = random.randint(0, input_batch_size - 1)\n",
    "            while c == a[idx]:\n",
    "                c = random.randint(0, input_batch_size - 1)\n",
    "            \n",
    "            b[idx] = c\n",
    "            \n",
    "        final_image_features[((1 + n) * input_batch_size): (2 + n) * input_batch_size] = image_features[a]\n",
    "        final_text_features[(1 + n) * input_batch_size: (2 + n) * input_batch_size] = text_features[b]\n",
    "        output_attention_mask[(1 + n) * input_batch_size: (2 + n) * input_batch_size] = input_attention_mask[b]\n",
    "        \n",
    "    return final_image_features, final_text_features, output_attention_mask, ground_truths.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84aaae01577646678a6cfd0172506ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 50 loss: 10.386340618133545\n",
      "Epoch: [1][50/17600]\tTime 0.9003903865814209 (1.043252534866333)\tData 0.8919963836669922 (1.0347679805755616)\t\n",
      "  batch 100 loss: 10.298310947418212\n",
      "Epoch: [1][100/17600]\tTime 0.6943926811218262 (1.0010074949264527)\tData 0.6859979629516602 (0.9926024055480958)\t\n",
      "  batch 150 loss: 10.261950550079346\n",
      "Epoch: [1][150/17600]\tTime 1.1548550128936768 (1.0066885312398275)\tData 1.1466069221496582 (0.9983069960276286)\t\n",
      "  batch 200 loss: 10.236226749420165\n",
      "Epoch: [1][200/17600]\tTime 1.3503468036651611 (0.9929545593261718)\tData 1.3420495986938477 (0.9845962071418762)\t\n",
      "  batch 250 loss: 10.165457935333253\n",
      "Epoch: [1][250/17600]\tTime 1.214792013168335 (1.035047643661499)\tData 1.2064740657806396 (1.0266626243591308)\t\n",
      "  batch 300 loss: 10.127619132995605\n",
      "Epoch: [1][300/17600]\tTime 1.1201674938201904 (1.070337659517924)\tData 1.1119122505187988 (1.0619704214731853)\t\n",
      "  batch 350 loss: 10.238421554565429\n",
      "Epoch: [1][350/17600]\tTime 1.2172636985778809 (1.101286871773856)\tData 1.2089862823486328 (1.092912552697318)\t\n",
      "  batch 400 loss: 10.191855506896973\n",
      "Epoch: [1][400/17600]\tTime 1.1372838020324707 (1.1174117702245712)\tData 1.1290078163146973 (1.1090447890758515)\t\n",
      "  batch 450 loss: 10.13989459991455\n",
      "Epoch: [1][450/17600]\tTime 1.1263608932495117 (1.1347875955369737)\tData 1.1180670261383057 (1.1264303795496622)\t\n",
      "  batch 500 loss: 10.117243041992188\n",
      "Epoch: [1][500/17600]\tTime 1.8445265293121338 (1.155070198059082)\tData 1.8360586166381836 (1.1466996989250182)\t\n",
      "  batch 550 loss: 10.019612979888915\n",
      "Epoch: [1][550/17600]\tTime 1.1463191509246826 (1.1675209240479902)\tData 1.1380133628845215 (1.1591522845354947)\t\n",
      "  batch 600 loss: 10.052267589569091\n",
      "Epoch: [1][600/17600]\tTime 1.6852118968963623 (1.1787776780128478)\tData 1.6768484115600586 (1.1704111293951671)\t\n",
      "  batch 650 loss: 9.975087223052979\n",
      "Epoch: [1][650/17600]\tTime 1.6686515808105469 (1.1804522760097798)\tData 1.660348892211914 (1.1720843263772818)\t\n",
      "  batch 700 loss: 10.043127365112305\n",
      "Epoch: [1][700/17600]\tTime 1.3159024715423584 (1.1919346308708192)\tData 1.307628870010376 (1.1835710375649588)\t\n",
      "  batch 750 loss: 10.026588459014892\n",
      "Epoch: [1][750/17600]\tTime 1.1494669914245605 (1.1954694878260295)\tData 1.141007423400879 (1.187100123723348)\t\n",
      "  batch 800 loss: 10.0198264503479\n",
      "Epoch: [1][800/17600]\tTime 1.4880170822143555 (1.2026371228694916)\tData 1.4797518253326416 (1.1942662480473518)\t\n",
      "  batch 850 loss: 9.94762378692627\n",
      "Epoch: [1][850/17600]\tTime 0.8169951438903809 (1.2034026098251343)\tData 0.8087289333343506 (1.195033950805664)\t\n",
      "  batch 900 loss: 9.961646308898926\n",
      "Epoch: [1][900/17600]\tTime 1.4252469539642334 (1.2079659520255195)\tData 1.4167726039886475 (1.1995998491181268)\t\n",
      "  batch 950 loss: 9.962606601715088\n",
      "Epoch: [1][950/17600]\tTime 1.1147797107696533 (1.2132165981593885)\tData 1.106515645980835 (1.2048535379610563)\t\n",
      "  batch 1000 loss: 9.969206466674805\n",
      "Epoch: [1][1000/17600]\tTime 1.2283902168273926 (1.2171276144981384)\tData 1.2200846672058105 (1.2087629718780517)\t\n",
      "  batch 1050 loss: 9.981115341186523\n",
      "Epoch: [1][1050/17600]\tTime 1.5004568099975586 (1.222925798552377)\tData 1.4920647144317627 (1.21456357501802)\t\n",
      "  batch 1100 loss: 9.75682638168335\n",
      "Epoch: [1][1100/17600]\tTime 1.074206829071045 (1.223158841566606)\tData 1.065990924835205 (1.214800353050232)\t\n",
      "  batch 1150 loss: 9.816268100738526\n",
      "Epoch: [1][1150/17600]\tTime 1.1134650707244873 (1.2258506347822107)\tData 1.1053175926208496 (1.2174981480059417)\t\n",
      "  batch 1200 loss: 9.754167594909667\n",
      "Epoch: [1][1200/17600]\tTime 1.7111048698425293 (1.2247428901990254)\tData 1.7028417587280273 (1.21639373143514)\t\n",
      "  batch 1250 loss: 9.680698623657227\n",
      "Epoch: [1][1250/17600]\tTime 1.1765532493591309 (1.2246840656280518)\tData 1.1683332920074463 (1.2163375045776368)\t\n",
      "  batch 1300 loss: 9.758322505950927\n",
      "Epoch: [1][1300/17600]\tTime 0.8928649425506592 (1.2232445850739113)\tData 0.8845267295837402 (1.2149004714305585)\t\n",
      "  batch 1350 loss: 9.62621030807495\n",
      "Epoch: [1][1350/17600]\tTime 1.0448451042175293 (1.2219479534361097)\tData 1.0365564823150635 (1.2136044643543384)\t\n",
      "  batch 1400 loss: 9.656674728393554\n",
      "Epoch: [1][1400/17600]\tTime 1.5032460689544678 (1.2229330788339887)\tData 1.4949700832366943 (1.2145919452394758)\t\n",
      "  batch 1450 loss: 9.603392543792724\n",
      "Epoch: [1][1450/17600]\tTime 1.083259105682373 (1.2231257071988335)\tData 1.0749075412750244 (1.2147841626200182)\t\n",
      "  batch 1500 loss: 9.609197959899902\n",
      "Epoch: [1][1500/17600]\tTime 1.4766860008239746 (1.225106716632843)\tData 1.468371868133545 (1.2167676502863567)\t\n",
      "  batch 1550 loss: 9.479177207946778\n",
      "Epoch: [1][1550/17600]\tTime 0.8486802577972412 (1.2256805839846212)\tData 0.840501070022583 (1.2173436501718335)\t\n",
      "  batch 1600 loss: 9.473902111053468\n",
      "Epoch: [1][1600/17600]\tTime 1.2916700839996338 (1.2260519900918008)\tData 1.2833876609802246 (1.217715616673231)\t\n",
      "  batch 1650 loss: 9.421925182342529\n",
      "Epoch: [1][1650/17600]\tTime 1.6531989574432373 (1.2266825626835678)\tData 1.644890546798706 (1.2183471396475127)\t\n",
      "  batch 1700 loss: 9.363795566558839\n",
      "Epoch: [1][1700/17600]\tTime 0.8424906730651855 (1.2279068195118623)\tData 0.8340063095092773 (1.2195736088472253)\t\n",
      "  batch 1750 loss: 9.287004833221436\n",
      "Epoch: [1][1750/17600]\tTime 1.1744787693023682 (1.2309248192650932)\tData 1.1661300659179688 (1.222590760912214)\t\n",
      "  batch 1800 loss: 9.339597072601318\n",
      "Epoch: [1][1800/17600]\tTime 1.638744592666626 (1.232443424065908)\tData 1.6302971839904785 (1.2241092088487413)\t\n",
      "  batch 1850 loss: 9.233075523376465\n",
      "Epoch: [1][1850/17600]\tTime 0.9818768501281738 (1.2314130736686089)\tData 0.9736182689666748 (1.2230767778448157)\t\n",
      "  batch 1900 loss: 9.114802722930909\n",
      "Epoch: [1][1900/17600]\tTime 1.3787949085235596 (1.2319392137778433)\tData 1.370607614517212 (1.223600004597714)\t\n",
      "  batch 1950 loss: 9.181492080688477\n",
      "Epoch: [1][1950/17600]\tTime 1.2401115894317627 (1.2326699907351764)\tData 1.231656789779663 (1.2243318349887162)\t\n",
      "  batch 2000 loss: 9.068269510269165\n",
      "Epoch: [1][2000/17600]\tTime 1.3622746467590332 (1.231916156053543)\tData 1.3540186882019043 (1.2235785131454469)\t\n",
      "  batch 2050 loss: 8.973254680633545\n",
      "Epoch: [1][2050/17600]\tTime 1.2486236095428467 (1.233485134869087)\tData 1.240354299545288 (1.2251481721459365)\t\n",
      "  batch 2100 loss: 8.940659103393555\n",
      "Epoch: [1][2100/17600]\tTime 1.095607042312622 (1.2341957166081383)\tData 1.0871403217315674 (1.2258579493704296)\t\n",
      "  batch 2150 loss: 8.84663288116455\n",
      "Epoch: [1][2150/17600]\tTime 1.173429250717163 (1.234726573478344)\tData 1.165224313735962 (1.226389843474987)\t\n",
      "  batch 2200 loss: 8.860337982177734\n",
      "Epoch: [1][2200/17600]\tTime 1.850355863571167 (1.2366881342367693)\tData 1.8421478271484375 (1.228351225311106)\t\n",
      "  batch 2250 loss: 8.669130573272705\n",
      "Epoch: [1][2250/17600]\tTime 1.1985602378845215 (1.2378012363645765)\tData 1.1901719570159912 (1.229461505042182)\t\n",
      "  batch 2300 loss: 8.62308172225952\n",
      "Epoch: [1][2300/17600]\tTime 1.577965497970581 (1.239372002352839)\tData 1.5697267055511475 (1.2310305536311605)\t\n",
      "  batch 2350 loss: 8.690175008773803\n",
      "Epoch: [1][2350/17600]\tTime 1.2215008735656738 (1.240628364644152)\tData 1.2122933864593506 (1.232287512738654)\t\n",
      "  batch 2400 loss: 8.64143666267395\n",
      "Epoch: [1][2400/17600]\tTime 1.2195444107055664 (1.2412166045109432)\tData 1.2113940715789795 (1.2328765061497688)\t\n",
      "  batch 2450 loss: 8.589220685958862\n",
      "Epoch: [1][2450/17600]\tTime 1.3996129035949707 (1.241709598813738)\tData 1.3914015293121338 (1.2333713531494142)\t\n",
      "  batch 2500 loss: 8.587760543823242\n",
      "Epoch: [1][2500/17600]\tTime 0.9911196231842041 (1.2417699424743653)\tData 0.9828832149505615 (1.2334332392692566)\t\n",
      "  batch 2550 loss: 8.354866580963135\n",
      "Epoch: [1][2550/17600]\tTime 1.968310832977295 (1.241546805606169)\tData 1.9599480628967285 (1.233211145401001)\t\n",
      "  batch 2600 loss: 8.384684457778931\n",
      "Epoch: [1][2600/17600]\tTime 1.300135612487793 (1.2419730422129998)\tData 1.2918798923492432 (1.2336379343729753)\t\n",
      "  batch 2650 loss: 8.483702011108399\n",
      "Epoch: [1][2650/17600]\tTime 1.3819000720977783 (1.2427433111082833)\tData 1.3735992908477783 (1.234408957643329)\t\n",
      "  batch 2700 loss: 8.087194776535034\n",
      "Epoch: [1][2700/17600]\tTime 1.4270427227020264 (1.2430526410208809)\tData 1.4188096523284912 (1.2347181287518254)\t\n",
      "  batch 2750 loss: 8.292297840118408\n",
      "Epoch: [1][2750/17600]\tTime 1.2697222232818604 (1.24281609509208)\tData 1.2614796161651611 (1.2344827237562699)\t\n",
      "  batch 2800 loss: 8.344545068740844\n",
      "Epoch: [1][2800/17600]\tTime 1.6634652614593506 (1.2434457609483174)\tData 1.655182123184204 (1.2351122402293342)\t\n",
      "  batch 2850 loss: 8.124573831558228\n",
      "Epoch: [1][2850/17600]\tTime 1.1718339920043945 (1.2451317882537842)\tData 1.1634571552276611 (1.2367968830309417)\t\n",
      "  batch 2900 loss: 8.09879391670227\n",
      "Epoch: [1][2900/17600]\tTime 1.4882543087005615 (1.2445807562203244)\tData 1.4800317287445068 (1.2362457175090396)\t\n",
      "  batch 2950 loss: 8.000075674057006\n",
      "Epoch: [1][2950/17600]\tTime 1.1432762145996094 (1.243536782507169)\tData 1.1350953578948975 (1.2351996598809452)\t\n",
      "  batch 3000 loss: 8.026338090896607\n",
      "Epoch: [1][3000/17600]\tTime 1.3597114086151123 (1.2426244944731395)\tData 1.3512954711914062 (1.2342879358132681)\t\n",
      "  batch 3050 loss: 8.264065971374512\n",
      "Epoch: [1][3050/17600]\tTime 1.0070722103118896 (1.244394666718655)\tData 0.9988512992858887 (1.2360579790052821)\t\n",
      "  batch 3100 loss: 7.994254102706909\n",
      "Epoch: [1][3100/17600]\tTime 1.0667705535888672 (1.2445989565695486)\tData 1.0583319664001465 (1.2362632912974203)\t\n",
      "  batch 3150 loss: 7.7488354969024655\n",
      "Epoch: [1][3150/17600]\tTime 1.2816739082336426 (1.24506786179921)\tData 1.2734043598175049 (1.2367306143896921)\t\n",
      "  batch 3200 loss: 7.975522813796997\n",
      "Epoch: [1][3200/17600]\tTime 1.3944430351257324 (1.2457054690271616)\tData 1.3860509395599365 (1.2373666879534722)\t\n",
      "  batch 3250 loss: 7.884291734695434\n",
      "Epoch: [1][3250/17600]\tTime 1.5858995914459229 (1.2459265323785635)\tData 1.5775256156921387 (1.2375860939759475)\t\n",
      "  batch 3300 loss: 7.674179430007935\n",
      "Epoch: [1][3300/17600]\tTime 1.3269760608673096 (1.246396602861809)\tData 1.3186521530151367 (1.238056723349022)\t\n",
      "  batch 3350 loss: 7.74094217300415\n",
      "Epoch: [1][3350/17600]\tTime 1.0729730129241943 (1.247172113176602)\tData 1.0646841526031494 (1.2388328108858706)\t\n",
      "  batch 3400 loss: 7.7290417766571045\n",
      "Epoch: [1][3400/17600]\tTime 1.0624868869781494 (1.24852862126687)\tData 1.0541317462921143 (1.2401874081527486)\t\n",
      "  batch 3450 loss: 7.771046419143676\n",
      "Epoch: [1][3450/17600]\tTime 1.3528962135314941 (1.2487552525340646)\tData 1.3445987701416016 (1.240413425003273)\t\n",
      "  batch 3500 loss: 7.54996057510376\n",
      "Epoch: [1][3500/17600]\tTime 1.0182385444641113 (1.2484335851669313)\tData 1.0099315643310547 (1.240089374405997)\t\n",
      "  batch 3550 loss: 7.705026407241821\n",
      "Epoch: [1][3550/17600]\tTime 1.6355564594268799 (1.249407688933359)\tData 1.6271851062774658 (1.2410622892917043)\t\n",
      "  batch 3600 loss: 7.716636390686035\n",
      "Epoch: [1][3600/17600]\tTime 1.356928825378418 (1.249148157371415)\tData 1.347907304763794 (1.2408025210433535)\t\n",
      "  batch 3650 loss: 7.730883598327637\n",
      "Epoch: [1][3650/17600]\tTime 1.1054062843322754 (1.2498527145385743)\tData 1.097139835357666 (1.24150647522652)\t\n",
      "  batch 3700 loss: 7.654286651611328\n",
      "Epoch: [1][3700/17600]\tTime 2.2395083904266357 (1.2500367768390759)\tData 2.231004238128662 (1.2416907926507899)\t\n",
      "  batch 3750 loss: 7.630214557647705\n",
      "Epoch: [1][3750/17600]\tTime 1.0999541282653809 (1.2497497880935668)\tData 1.0915355682373047 (1.2414022356033325)\t\n",
      "  batch 3800 loss: 7.59246527671814\n",
      "Epoch: [1][3800/17600]\tTime 0.9688186645507812 (1.2497416213939065)\tData 0.9605579376220703 (1.2413935700843208)\t\n",
      "  batch 3850 loss: 7.530039215087891\n",
      "Epoch: [1][3850/17600]\tTime 0.9890711307525635 (1.2499577749549569)\tData 0.9809036254882812 (1.241607610157558)\t\n",
      "  batch 3900 loss: 7.551959972381592\n",
      "Epoch: [1][3900/17600]\tTime 1.2041468620300293 (1.2497068943121494)\tData 1.1947968006134033 (1.2413568554780423)\t\n",
      "  batch 3950 loss: 7.528604288101196\n",
      "Epoch: [1][3950/17600]\tTime 1.5174295902252197 (1.2508064250101016)\tData 1.5089480876922607 (1.2424521833733668)\t\n",
      "  batch 4000 loss: 7.300306234359741\n",
      "Epoch: [1][4000/17600]\tTime 1.0471794605255127 (1.251470114171505)\tData 1.0388643741607666 (1.2431095779538155)\t\n",
      "  batch 4050 loss: 7.712285566329956\n",
      "Epoch: [1][4050/17600]\tTime 1.1318907737731934 (1.251089969093417)\tData 1.1236507892608643 (1.2427304699391495)\t\n",
      "  batch 4100 loss: 7.456183910369873\n",
      "Epoch: [1][4100/17600]\tTime 1.29109787940979 (1.2520878823792063)\tData 1.2828521728515625 (1.2437289695623444)\t\n",
      "  batch 4150 loss: 7.440552301406861\n",
      "Epoch: [1][4150/17600]\tTime 1.1771275997161865 (1.252718954775707)\tData 1.1688120365142822 (1.2443593265924109)\t\n",
      "  batch 4200 loss: 7.455326929092407\n",
      "Epoch: [1][4200/17600]\tTime 1.1773693561553955 (1.2532312653178261)\tData 1.1686255931854248 (1.2448720396132695)\t\n",
      "  batch 4250 loss: 7.298383188247681\n",
      "Epoch: [1][4250/17600]\tTime 0.9718062877655029 (1.2539134272968069)\tData 0.9633841514587402 (1.245552624758552)\t\n",
      "  batch 4300 loss: 7.45763744354248\n",
      "Epoch: [1][4300/17600]\tTime 1.5915255546569824 (1.2539246473755947)\tData 1.5831162929534912 (1.2455618504590766)\t\n",
      "  batch 4350 loss: 7.27618106842041\n",
      "Epoch: [1][4350/17600]\tTime 1.9484059810638428 (1.2539109761139442)\tData 1.9398460388183594 (1.2455482014842416)\t\n",
      "  batch 4400 loss: 7.351746273040772\n",
      "Epoch: [1][4400/17600]\tTime 1.5235612392425537 (1.2540369913252918)\tData 1.515228271484375 (1.2456744129549373)\t\n",
      "  batch 4450 loss: 7.0821960926055905\n",
      "Epoch: [1][4450/17600]\tTime 1.7395153045654297 (1.2543918251723385)\tData 1.73103928565979 (1.2460300810953204)\t\n",
      "  batch 4500 loss: 7.360823040008545\n",
      "Epoch: [1][4500/17600]\tTime 1.7651221752166748 (1.2557956581645542)\tData 1.7567288875579834 (1.2474328196843465)\t\n",
      "  batch 4550 loss: 7.101274404525757\n",
      "Epoch: [1][4550/17600]\tTime 1.5977318286895752 (1.2556983607679932)\tData 1.589379072189331 (1.2473350986543592)\t\n",
      "  batch 4600 loss: 7.073191452026367\n",
      "Epoch: [1][4600/17600]\tTime 1.0619475841522217 (1.2561845693899238)\tData 1.0535743236541748 (1.2478217481530232)\t\n",
      "  batch 4650 loss: 7.174465169906616\n",
      "Epoch: [1][4650/17600]\tTime 0.8111178874969482 (1.256615080320707)\tData 0.802823543548584 (1.2482521413474954)\t\n",
      "  batch 4700 loss: 7.2873736763000485\n",
      "Epoch: [1][4700/17600]\tTime 1.0949339866638184 (1.2566962263431956)\tData 1.086575984954834 (1.2483333800194112)\t\n",
      "  batch 4750 loss: 7.267207622528076\n",
      "Epoch: [1][4750/17600]\tTime 1.480625867843628 (1.2573805505351017)\tData 1.4724540710449219 (1.2490183730878328)\t\n",
      "  batch 4800 loss: 7.303729753494263\n",
      "Epoch: [1][4800/17600]\tTime 1.3116185665130615 (1.2577660418550174)\tData 1.3032267093658447 (1.2494045622646808)\t\n",
      "  batch 4850 loss: 7.033325605392456\n",
      "Epoch: [1][4850/17600]\tTime 1.1042020320892334 (1.2583482360839844)\tData 1.095874309539795 (1.2499868732137778)\t\n",
      "  batch 4900 loss: 7.188091039657593\n",
      "Epoch: [1][4900/17600]\tTime 1.0117313861846924 (1.2579384008232428)\tData 1.0035462379455566 (1.2495768778178156)\t\n",
      "  batch 4950 loss: 7.136935453414917\n",
      "Epoch: [1][4950/17600]\tTime 1.2043216228485107 (1.2582493071122602)\tData 1.1960856914520264 (1.2498878892262777)\t\n",
      "  batch 5000 loss: 6.814711532592773\n",
      "Epoch: [1][5000/17600]\tTime 1.4438145160675049 (1.2584720631599426)\tData 1.4354872703552246 (1.2501115674495697)\t\n",
      "  batch 5050 loss: 7.267049531936646\n",
      "Epoch: [1][5050/17600]\tTime 1.0615739822387695 (1.259226811569516)\tData 1.0532469749450684 (1.2508662263001546)\t\n",
      "  batch 5100 loss: 7.153128252029419\n",
      "Epoch: [1][5100/17600]\tTime 1.476289987564087 (1.2605367576842215)\tData 1.4678740501403809 (1.2521739208464528)\t\n",
      "  batch 5150 loss: 7.030007200241089\n",
      "Epoch: [1][5150/17600]\tTime 0.9082181453704834 (1.260747747976803)\tData 0.899972677230835 (1.2523807792756163)\t\n",
      "  batch 5200 loss: 7.1159478950500485\n",
      "Epoch: [1][5200/17600]\tTime 1.1488990783691406 (1.2604345978681857)\tData 1.1405797004699707 (1.2520676851272583)\t\n",
      "  batch 5250 loss: 7.085400676727295\n",
      "Epoch: [1][5250/17600]\tTime 1.4889957904815674 (1.2610099379221598)\tData 1.4798521995544434 (1.2526426327115014)\t\n",
      "  batch 5300 loss: 7.0865010738372805\n",
      "Epoch: [1][5300/17600]\tTime 0.9737553596496582 (1.260822546257163)\tData 0.9654247760772705 (1.252454619632577)\t\n",
      "  batch 5350 loss: 6.785290403366089\n",
      "Epoch: [1][5350/17600]\tTime 1.1637871265411377 (1.2619434418188078)\tData 1.1555750370025635 (1.2535747135019748)\t\n",
      "  batch 5400 loss: 6.710409564971924\n",
      "Epoch: [1][5400/17600]\tTime 1.0283758640289307 (1.2622731325361465)\tData 1.0201306343078613 (1.253903837159828)\t\n",
      "  batch 5450 loss: 6.632506093978882\n",
      "Epoch: [1][5450/17600]\tTime 1.3628506660461426 (1.2630765847547338)\tData 1.3541903495788574 (1.254706577292276)\t\n",
      "  batch 5500 loss: 7.1172504711151126\n",
      "Epoch: [1][5500/17600]\tTime 1.3437917232513428 (1.2633687746741555)\tData 1.334996223449707 (1.2549973431067034)\t\n",
      "  batch 5550 loss: 6.7098953151702885\n",
      "Epoch: [1][5550/17600]\tTime 1.0820069313049316 (1.263581714372377)\tData 1.073582410812378 (1.255210123233967)\t\n",
      "  batch 5600 loss: 6.619781856536865\n",
      "Epoch: [1][5600/17600]\tTime 1.1986629962921143 (1.2628875900592123)\tData 1.1903448104858398 (1.2545160839387348)\t\n",
      "  batch 5650 loss: 6.893878087997437\n",
      "Epoch: [1][5650/17600]\tTime 1.4070522785186768 (1.2636006973064051)\tData 1.3986296653747559 (1.2552293730204085)\t\n",
      "  batch 5700 loss: 6.845663557052612\n",
      "Epoch: [1][5700/17600]\tTime 1.057784080505371 (1.2635534986278467)\tData 1.0494370460510254 (1.2551814777809276)\t\n",
      "  batch 5750 loss: 6.871654357910156\n",
      "Epoch: [1][5750/17600]\tTime 1.2569386959075928 (1.2629680458566417)\tData 1.24851393699646 (1.2545961186367534)\t\n",
      "  batch 5800 loss: 6.581066656112671\n",
      "Epoch: [1][5800/17600]\tTime 0.9999287128448486 (1.2626215940097283)\tData 0.9916372299194336 (1.2542498495660979)\t\n",
      "  batch 5850 loss: 6.8006937265396115\n",
      "Epoch: [1][5850/17600]\tTime 2.624563694000244 (1.2629150580137203)\tData 2.616046667098999 (1.2545425820554423)\t\n",
      "  batch 5900 loss: 6.847386713027954\n",
      "Epoch: [1][5900/17600]\tTime 1.580470085144043 (1.2636115256810592)\tData 1.5720586776733398 (1.2552391202166928)\t\n",
      "  batch 5950 loss: 6.877078828811645\n",
      "Epoch: [1][5950/17600]\tTime 1.908388376235962 (1.2640119036506203)\tData 1.8996424674987793 (1.2556392827955614)\t\n",
      "  batch 6000 loss: 6.985215787887573\n",
      "Epoch: [1][6000/17600]\tTime 0.7902143001556396 (1.2639844219287237)\tData 0.7818360328674316 (1.2556099548737207)\t\n",
      "  batch 6050 loss: 6.568349123001099\n",
      "Epoch: [1][6050/17600]\tTime 1.1106834411621094 (1.263616283077839)\tData 1.1023578643798828 (1.2552420169656926)\t\n",
      "  batch 6100 loss: 6.543601498603821\n",
      "Epoch: [1][6100/17600]\tTime 0.8990180492401123 (1.263099283898463)\tData 0.890873908996582 (1.254724304910566)\t\n",
      "  batch 6150 loss: 6.759879684448242\n",
      "Epoch: [1][6150/17600]\tTime 1.2542507648468018 (1.2628168892666576)\tData 1.2459619045257568 (1.2544424155475646)\t\n",
      "  batch 6200 loss: 6.985139579772949\n",
      "Epoch: [1][6200/17600]\tTime 0.7118701934814453 (1.262148474531789)\tData 0.7035176753997803 (1.253773646969949)\t\n",
      "  batch 6250 loss: 6.737355470657349\n",
      "Epoch: [1][6250/17600]\tTime 2.0272371768951416 (1.2619245072174072)\tData 2.0187509059906006 (1.2535498752212524)\t\n",
      "  batch 6300 loss: 6.865544080734253\n",
      "Epoch: [1][6300/17600]\tTime 1.2324326038360596 (1.2613575604605296)\tData 1.2242686748504639 (1.2529835711963593)\t\n",
      "  batch 6350 loss: 6.778206920623779\n",
      "Epoch: [1][6350/17600]\tTime 1.1542980670928955 (1.2606855545269222)\tData 1.146026849746704 (1.252312335705194)\t\n",
      "  batch 6400 loss: 6.728169555664063\n",
      "Epoch: [1][6400/17600]\tTime 1.1470763683319092 (1.2607382076978684)\tData 1.1385114192962646 (1.252364570684731)\t\n",
      "  batch 6450 loss: 6.499658184051514\n",
      "Epoch: [1][6450/17600]\tTime 1.1101887226104736 (1.260401198549788)\tData 1.1019232273101807 (1.2520275647880494)\t\n",
      "  batch 6500 loss: 6.3586619853973385\n",
      "Epoch: [1][6500/17600]\tTime 1.1163599491119385 (1.2601468398020819)\tData 1.1079838275909424 (1.2517712136415335)\t\n",
      "  batch 6550 loss: 6.7959644222259525\n",
      "Epoch: [1][6550/17600]\tTime 1.546797275543213 (1.260406841321756)\tData 1.5385260581970215 (1.2520316040606898)\t\n",
      "  batch 6600 loss: 6.6550822877883915\n",
      "Epoch: [1][6600/17600]\tTime 1.2122788429260254 (1.2600575057665506)\tData 1.2039284706115723 (1.251683002204606)\t\n",
      "  batch 6650 loss: 6.727956099510193\n",
      "Epoch: [1][6650/17600]\tTime 1.4868481159210205 (1.259557896556711)\tData 1.478588342666626 (1.2511836805558743)\t\n",
      "  batch 6700 loss: 6.495586910247803\n",
      "Epoch: [1][6700/17600]\tTime 1.8486502170562744 (1.2592628859406088)\tData 1.84006667137146 (1.250877561035441)\t\n",
      "  batch 6750 loss: 6.493994979858399\n",
      "Epoch: [1][6750/17600]\tTime 1.0037436485290527 (1.2587803848761099)\tData 0.9954328536987305 (1.2503951511383056)\t\n",
      "  batch 6800 loss: 6.813382167816162\n",
      "Epoch: [1][6800/17600]\tTime 1.2013959884643555 (1.2585929598177181)\tData 1.193120002746582 (1.2502076989762922)\t\n",
      "  batch 6850 loss: 6.726789693832398\n",
      "Epoch: [1][6850/17600]\tTime 1.5464091300964355 (1.2583498396142556)\tData 1.5381441116333008 (1.249964668942194)\t\n",
      "  batch 6900 loss: 6.389117794036865\n",
      "Epoch: [1][6900/17600]\tTime 0.9868838787078857 (1.2577499006105506)\tData 0.9786546230316162 (1.249365363224693)\t\n",
      "  batch 6950 loss: 6.480507888793945\n",
      "Epoch: [1][6950/17600]\tTime 0.826491117477417 (1.25766258260329)\tData 0.8181450366973877 (1.2492785915882467)\t\n",
      "  batch 7000 loss: 6.655950651168824\n",
      "Epoch: [1][7000/17600]\tTime 1.3531849384307861 (1.2575827034200942)\tData 1.3448843955993652 (1.2491990796838488)\t\n",
      "  batch 7050 loss: 6.603255233764648\n",
      "Epoch: [1][7050/17600]\tTime 0.8453555107116699 (1.2571326067768935)\tData 0.8370449542999268 (1.2487491803811797)\t\n",
      "  batch 7100 loss: 6.454407234191894\n",
      "Epoch: [1][7100/17600]\tTime 1.0507428646087646 (1.257218376179816)\tData 1.0422801971435547 (1.2488355533170028)\t\n",
      "  batch 7150 loss: 6.502660293579101\n",
      "Epoch: [1][7150/17600]\tTime 1.1633658409118652 (1.2568161446898134)\tData 1.1551084518432617 (1.248434151902899)\t\n",
      "  batch 7200 loss: 6.220252017974854\n",
      "Epoch: [1][7200/17600]\tTime 1.939023733139038 (1.2567281765407987)\tData 1.9305927753448486 (1.248346672952175)\t\n",
      "  batch 7250 loss: 6.426936302185059\n",
      "Epoch: [1][7250/17600]\tTime 1.2290394306182861 (1.2568621648262288)\tData 1.2206885814666748 (1.2484811536525857)\t\n",
      "  batch 7300 loss: 6.159074945449829\n",
      "Epoch: [1][7300/17600]\tTime 1.3585093021392822 (1.2561512348749866)\tData 1.3502485752105713 (1.2477708739777134)\t\n",
      "  batch 7350 loss: 6.313415012359619\n",
      "Epoch: [1][7350/17600]\tTime 1.1205873489379883 (1.2558580394342642)\tData 1.1122829914093018 (1.2474777439013631)\t\n",
      "  batch 7400 loss: 6.333308429718017\n",
      "Epoch: [1][7400/17600]\tTime 1.1598222255706787 (1.2559532291502566)\tData 1.1514647006988525 (1.2475722111238015)\t\n",
      "  batch 7450 loss: 6.2484055519104\n",
      "Epoch: [1][7450/17600]\tTime 1.2041592597961426 (1.2550336013704337)\tData 1.1958725452423096 (1.2466524233274012)\t\n",
      "  batch 7500 loss: 6.506343784332276\n",
      "Epoch: [1][7500/17600]\tTime 1.410478115081787 (1.2550024397850037)\tData 1.4021191596984863 (1.246620557053884)\t\n",
      "  batch 7550 loss: 6.383547644615174\n",
      "Epoch: [1][7550/17600]\tTime 1.4758741855621338 (1.2556044942337945)\tData 1.4675354957580566 (1.2472229438112272)\t\n",
      "  batch 7600 loss: 6.452479553222656\n",
      "Epoch: [1][7600/17600]\tTime 1.207289695739746 (1.254961425128736)\tData 1.1979680061340332 (1.2465788662747332)\t\n",
      "  batch 7650 loss: 6.574218306541443\n",
      "Epoch: [1][7650/17600]\tTime 1.1945090293884277 (1.2542961999170141)\tData 1.186171531677246 (1.2459137953652275)\t\n",
      "  batch 7700 loss: 5.989402174949646\n",
      "Epoch: [1][7700/17600]\tTime 1.0837745666503906 (1.2541316735589658)\tData 1.074615716934204 (1.2457439185117747)\t\n",
      "  batch 7750 loss: 6.302333827018738\n",
      "Epoch: [1][7750/17600]\tTime 1.145380973815918 (1.2546577455766739)\tData 1.1359052658081055 (1.2462565136571084)\t\n",
      "  batch 7800 loss: 6.632257356643676\n",
      "Epoch: [1][7800/17600]\tTime 1.8940951824188232 (1.254850852458905)\tData 1.8848209381103516 (1.246434741417567)\t\n",
      "  batch 7850 loss: 6.377011632919311\n",
      "Epoch: [1][7850/17600]\tTime 1.1323599815368652 (1.2554352434729315)\tData 1.1230175495147705 (1.2470052675380827)\t\n",
      "  batch 7900 loss: 6.466439847946167\n",
      "Epoch: [1][7900/17600]\tTime 1.427985429763794 (1.2557088340988642)\tData 1.4184303283691406 (1.2472654257544988)\t\n",
      "  batch 7950 loss: 6.171128273010254\n",
      "Epoch: [1][7950/17600]\tTime 1.4692885875701904 (1.2555434679835098)\tData 1.457104206085205 (1.2470871142321414)\t\n",
      "  batch 8000 loss: 6.075293340682983\n",
      "Epoch: [1][8000/17600]\tTime 0.7570393085479736 (1.2547292137145996)\tData 0.745018720626831 (1.246262331843376)\t\n",
      "  batch 8050 loss: 6.25310507774353\n",
      "Epoch: [1][8050/17600]\tTime 1.077657699584961 (1.2532058503464882)\tData 1.0682883262634277 (1.244727958448185)\t\n",
      "  batch 8100 loss: 6.326184682846069\n",
      "Epoch: [1][8100/17600]\tTime 1.047590970993042 (1.2520546944053084)\tData 1.0383422374725342 (1.2435658638565628)\t\n",
      "  batch 8150 loss: 6.099924869537354\n",
      "Epoch: [1][8150/17600]\tTime 1.4926133155822754 (1.2506539351223436)\tData 1.480745792388916 (1.242154843412294)\t\n",
      "  batch 8200 loss: 6.455636281967163\n",
      "Epoch: [1][8200/17600]\tTime 0.9975969791412354 (1.2491792773909685)\tData 0.9853918552398682 (1.2406687822574523)\t\n",
      "  batch 8250 loss: 6.181361289024353\n",
      "Epoch: [1][8250/17600]\tTime 0.8000025749206543 (1.2475037636034416)\tData 0.7906777858734131 (1.238978707891522)\t\n",
      "  batch 8300 loss: 6.399488830566407\n",
      "Epoch: [1][8300/17600]\tTime 1.0167434215545654 (1.246303830491491)\tData 0.9842038154602051 (1.237763424235654)\t\n",
      "  batch 8350 loss: 6.055380258560181\n",
      "Epoch: [1][8350/17600]\tTime 0.6363534927368164 (1.2450339077190011)\tData 0.6245706081390381 (1.236483581994108)\t\n",
      "  batch 8400 loss: 6.050914816856384\n",
      "Epoch: [1][8400/17600]\tTime 1.0544624328613281 (1.2440483721948805)\tData 1.044867753982544 (1.2354884598652522)\t\n",
      "  batch 8450 loss: 6.300062751770019\n",
      "Epoch: [1][8450/17600]\tTime 0.928227424621582 (1.2427611117109039)\tData 0.9164583683013916 (1.2341896139517339)\t\n",
      "  batch 8500 loss: 6.053064084053039\n",
      "Epoch: [1][8500/17600]\tTime 1.028801679611206 (1.2417041505084319)\tData 1.0191264152526855 (1.2331229817727032)\t\n",
      "  batch 8550 loss: 6.231960945129394\n",
      "Epoch: [1][8550/17600]\tTime 1.0998637676239014 (1.240689442701507)\tData 1.090775966644287 (1.2320962036143968)\t\n",
      "  batch 8600 loss: 6.114312252998352\n",
      "Epoch: [1][8600/17600]\tTime 0.8703906536102295 (1.239491931726766)\tData 0.8609926700592041 (1.2308886477559111)\t\n",
      "  batch 8650 loss: 6.150463209152222\n",
      "Epoch: [1][8650/17600]\tTime 0.7970538139343262 (1.2381807615577831)\tData 0.7876579761505127 (1.2295602779167925)\t\n",
      "  batch 8700 loss: 5.985781621932984\n",
      "Epoch: [1][8700/17600]\tTime 0.7052679061889648 (1.2368531892765529)\tData 0.6958692073822021 (1.2282227928062965)\t\n",
      "  batch 8750 loss: 6.134048728942871\n",
      "Epoch: [1][8750/17600]\tTime 1.2767982482910156 (1.2357458608627319)\tData 1.267493724822998 (1.2271036145074028)\t\n",
      "  batch 8800 loss: 6.287429637908936\n",
      "Epoch: [1][8800/17600]\tTime 0.8710846900939941 (1.234526095607064)\tData 0.8606116771697998 (1.2258739432692527)\t\n",
      "  batch 8850 loss: 6.058771724700928\n",
      "Epoch: [1][8850/17600]\tTime 1.0586886405944824 (1.2330864066862117)\tData 1.0451312065124512 (1.224420127518433)\t\n",
      "  batch 8900 loss: 6.100774426460266\n",
      "Epoch: [1][8900/17600]\tTime 1.108985185623169 (1.232002123688044)\tData 1.0999057292938232 (1.2233265181873623)\t\n",
      "  batch 8950 loss: 6.095735211372375\n",
      "Epoch: [1][8950/17600]\tTime 0.8486261367797852 (1.2307526230678878)\tData 0.8392717838287354 (1.2220668449082188)\t\n",
      "  batch 9000 loss: 6.005814824104309\n",
      "Epoch: [1][9000/17600]\tTime 1.2161993980407715 (1.2295436657269796)\tData 1.2066981792449951 (1.2208468663957384)\t\n",
      "  batch 9050 loss: 6.354657726287842\n",
      "Epoch: [1][9050/17600]\tTime 1.0951051712036133 (1.2290044471572117)\tData 1.082308292388916 (1.2202865692528573)\t\n",
      "  batch 9100 loss: 6.060192303657532\n",
      "Epoch: [1][9100/17600]\tTime 0.766620397567749 (1.2281143414319216)\tData 0.7515373229980469 (1.2193743871856522)\t\n",
      "  batch 9150 loss: 6.0527742481231686\n",
      "Epoch: [1][9150/17600]\tTime 1.05446457862854 (1.2272772287149898)\tData 1.041238784790039 (1.218516888800866)\t\n",
      "  batch 9200 loss: 6.099401836395264\n",
      "Epoch: [1][9200/17600]\tTime 0.87422776222229 (1.2267774769534237)\tData 0.8608510494232178 (1.2179972108550694)\t\n",
      "  batch 9250 loss: 5.907730660438538\n",
      "Epoch: [1][9250/17600]\tTime 0.9084720611572266 (1.2257986124915046)\tData 0.8984949588775635 (1.21699843746907)\t\n",
      "  batch 9300 loss: 6.1131188106536865\n",
      "Epoch: [1][9300/17600]\tTime 1.229832649230957 (1.225034820854023)\tData 1.2164933681488037 (1.2162130831390299)\t\n",
      "  batch 9350 loss: 6.107377405166626\n",
      "Epoch: [1][9350/17600]\tTime 0.8785696029663086 (1.2237640910480112)\tData 0.8658077716827393 (1.214924734543989)\t\n",
      "  batch 9400 loss: 6.33774510383606\n",
      "Epoch: [1][9400/17600]\tTime 1.0704658031463623 (1.2230550815196748)\tData 1.0581064224243164 (1.2141974512059637)\t\n",
      "  batch 9450 loss: 6.2220706415176394\n",
      "Epoch: [1][9450/17600]\tTime 1.0543458461761475 (1.2226035057804572)\tData 1.0416104793548584 (1.2137280299928452)\t\n",
      "  batch 9500 loss: 6.3123007488250735\n",
      "Epoch: [1][9500/17600]\tTime 0.9956331253051758 (1.2216281185903046)\tData 0.9826898574829102 (1.212734244572489)\t\n",
      "  batch 9550 loss: 5.918591480255127\n",
      "Epoch: [1][9550/17600]\tTime 1.157301664352417 (1.2206883780993716)\tData 1.1446490287780762 (1.2117756911722153)\t\n",
      "  batch 9600 loss: 6.014044075012207\n",
      "Epoch: [1][9600/17600]\tTime 1.2661640644073486 (1.2200331349174183)\tData 1.2531859874725342 (1.211103104352951)\t\n",
      "  batch 9650 loss: 6.230198564529419\n",
      "Epoch: [1][9650/17600]\tTime 1.1166284084320068 (1.2196904050500899)\tData 1.1061444282531738 (1.2107443732671788)\t\n",
      "  batch 9700 loss: 5.870611200332641\n",
      "Epoch: [1][9700/17600]\tTime 0.9913451671600342 (1.2188530171531993)\tData 0.9768128395080566 (1.2098873810424018)\t\n",
      "  batch 9750 loss: 6.110547127723694\n",
      "Epoch: [1][9750/17600]\tTime 1.3428125381469727 (1.2181019920446934)\tData 1.332925796508789 (1.209119339404962)\t\n",
      "  batch 9800 loss: 6.098131513595581\n",
      "Epoch: [1][9800/17600]\tTime 1.4824986457824707 (1.2176132939056474)\tData 1.470160961151123 (1.2086146158588176)\t\n",
      "  batch 9850 loss: 6.28785924911499\n",
      "Epoch: [1][9850/17600]\tTime 1.2762327194213867 (1.2171762778432236)\tData 1.2610032558441162 (1.208160341064337)\t\n",
      "  batch 9900 loss: 5.916853613853455\n",
      "Epoch: [1][9900/17600]\tTime 0.8907613754272461 (1.2163877274773338)\tData 0.8746688365936279 (1.2073549008369446)\t\n",
      "  batch 9950 loss: 6.13353627204895\n",
      "Epoch: [1][9950/17600]\tTime 0.7363317012786865 (1.2156958960767967)\tData 0.723595142364502 (1.206646280240773)\t\n",
      "  batch 10000 loss: 5.973842167854309\n",
      "Epoch: [1][10000/17600]\tTime 0.771496057510376 (1.2151179615259171)\tData 0.7587249279022217 (1.206053742837906)\t\n",
      "  batch 10050 loss: 6.12268301486969\n",
      "Epoch: [1][10050/17600]\tTime 1.4671075344085693 (1.2145568512684077)\tData 1.4542698860168457 (1.2054760869106844)\t\n",
      "  batch 10100 loss: 5.975301842689515\n",
      "Epoch: [1][10100/17600]\tTime 1.0671038627624512 (1.213971123412104)\tData 1.0527143478393555 (1.2048766579250298)\t\n",
      "  batch 10150 loss: 6.202592763900757\n",
      "Epoch: [1][10150/17600]\tTime 0.965660810470581 (1.2131243759540502)\tData 0.9521908760070801 (1.2040140166775934)\t\n",
      "  batch 10200 loss: 6.112333354949951\n",
      "Epoch: [1][10200/17600]\tTime 1.2287969589233398 (1.2128026475859623)\tData 1.2159149646759033 (1.203677132106295)\t\n",
      "  batch 10250 loss: 6.125692238807678\n",
      "Epoch: [1][10250/17600]\tTime 1.056335687637329 (1.2119019516502938)\tData 1.042635202407837 (1.2027601954064717)\t\n",
      "  batch 10300 loss: 5.968967242240906\n",
      "Epoch: [1][10300/17600]\tTime 1.0586607456207275 (1.211044195138135)\tData 1.0482735633850098 (1.2018859152192052)\t\n",
      "  batch 10350 loss: 6.049473848342895\n",
      "Epoch: [1][10350/17600]\tTime 0.7119991779327393 (1.2103122411488334)\tData 0.6980280876159668 (1.201138140314443)\t\n",
      "  batch 10400 loss: 6.041817026138306\n",
      "Epoch: [1][10400/17600]\tTime 1.0161194801330566 (1.2097022124666434)\tData 1.0034728050231934 (1.200513652265072)\t\n",
      "  batch 10450 loss: 5.675769777297973\n",
      "Epoch: [1][10450/17600]\tTime 1.2267167568206787 (1.2087360630765487)\tData 1.2139389514923096 (1.1995305384631363)\t\n",
      "  batch 10500 loss: 6.116944694519043\n",
      "Epoch: [1][10500/17600]\tTime 1.1552183628082275 (1.2079749696822393)\tData 1.1449122428894043 (1.1987528287796747)\t\n",
      "  batch 10550 loss: 5.965453729629517\n",
      "Epoch: [1][10550/17600]\tTime 0.8237712383270264 (1.2073525737021207)\tData 0.8140971660614014 (1.1981166096773193)\t\n",
      "  batch 10600 loss: 6.118352556228638\n",
      "Epoch: [1][10600/17600]\tTime 1.528111457824707 (1.2068736404292988)\tData 1.5183014869689941 (1.1976246422866605)\t\n",
      "  batch 10650 loss: 5.854298214912415\n",
      "Epoch: [1][10650/17600]\tTime 0.6922755241394043 (1.2059369458167206)\tData 0.6779303550720215 (1.1966750028771413)\t\n",
      "  batch 10700 loss: 5.668733687400818\n",
      "Epoch: [1][10700/17600]\tTime 0.8275976181030273 (1.2049972388677508)\tData 0.8155460357666016 (1.1957211807286627)\t\n",
      "  batch 10750 loss: 5.881544942855835\n",
      "Epoch: [1][10750/17600]\tTime 1.033010482788086 (1.2045494340630465)\tData 1.0226550102233887 (1.1952590140187462)\t\n",
      "  batch 10800 loss: 5.9788763189315794\n",
      "Epoch: [1][10800/17600]\tTime 1.2351603507995605 (1.2040069575662966)\tData 1.2221794128417969 (1.1947041922586936)\t\n",
      "  batch 10850 loss: 5.9491573381423954\n",
      "Epoch: [1][10850/17600]\tTime 0.6742076873779297 (1.2032008910069267)\tData 0.6636993885040283 (1.1938839674874935)\t\n",
      "  batch 10900 loss: 5.786803107261658\n",
      "Epoch: [1][10900/17600]\tTime 1.4905545711517334 (1.2024615739901132)\tData 1.480494499206543 (1.1931317872301155)\t\n",
      "  batch 10950 loss: 5.849407052993774\n",
      "Epoch: [1][10950/17600]\tTime 1.1258695125579834 (1.2019278331434347)\tData 1.1132838726043701 (1.1925845181234351)\t\n",
      "  batch 11000 loss: 5.971784615516663\n",
      "Epoch: [1][11000/17600]\tTime 0.720789909362793 (1.201306428454139)\tData 0.710965633392334 (1.1919501207741825)\t\n",
      "  batch 11050 loss: 5.931163563728332\n",
      "Epoch: [1][11050/17600]\tTime 1.0859894752502441 (1.2004457010079292)\tData 1.0738904476165771 (1.1910783191827627)\t\n",
      "  batch 11100 loss: 5.987428750991821\n",
      "Epoch: [1][11100/17600]\tTime 1.1685898303985596 (1.1993140281428087)\tData 1.1587116718292236 (1.1899344521385056)\t\n",
      "  batch 11150 loss: 5.869401006698609\n",
      "Epoch: [1][11150/17600]\tTime 0.9530029296875 (1.1986855626640833)\tData 0.9434926509857178 (1.1892932593341365)\t\n",
      "  batch 11200 loss: 5.74780415058136\n",
      "Epoch: [1][11200/17600]\tTime 1.296492576599121 (1.197522087671927)\tData 1.286029577255249 (1.1881165636011533)\t\n",
      "  batch 11250 loss: 5.907177720069885\n",
      "Epoch: [1][11250/17600]\tTime 0.8238511085510254 (1.1965025338914659)\tData 0.8134241104125977 (1.1870852757983739)\t\n",
      "  batch 11300 loss: 5.7203602647781375\n",
      "Epoch: [1][11300/17600]\tTime 1.3935317993164062 (1.1958773713829243)\tData 1.3798143863677979 (1.186444736624186)\t\n",
      "  batch 11350 loss: 5.940523228645325\n",
      "Epoch: [1][11350/17600]\tTime 1.0892066955566406 (1.1951760009732015)\tData 1.074967622756958 (1.1857287847208031)\t\n",
      "  batch 11400 loss: 5.638602313995361\n",
      "Epoch: [1][11400/17600]\tTime 0.6587967872619629 (1.1945137004684985)\tData 0.6461777687072754 (1.1850550602820882)\t\n",
      "  batch 11450 loss: 5.729383058547974\n",
      "Epoch: [1][11450/17600]\tTime 1.1029975414276123 (1.193731756668424)\tData 1.0928666591644287 (1.1842617228978587)\t\n",
      "  batch 11500 loss: 5.90337188243866\n",
      "Epoch: [1][11500/17600]\tTime 0.934668779373169 (1.192983486154805)\tData 0.9246916770935059 (1.1835020291494287)\t\n",
      "  batch 11550 loss: 5.724404830932617\n",
      "Epoch: [1][11550/17600]\tTime 1.2649295330047607 (1.1925337744791271)\tData 1.2521319389343262 (1.1830396380981842)\t\n",
      "  batch 11600 loss: 5.9089416408538815\n",
      "Epoch: [1][11600/17600]\tTime 1.2981445789337158 (1.1919280406729929)\tData 1.2852709293365479 (1.1824204132474703)\t\n",
      "  batch 11650 loss: 5.667418003082275\n",
      "Epoch: [1][11650/17600]\tTime 0.8731968402862549 (1.1914187855167961)\tData 0.8587050437927246 (1.1818971085241423)\t\n",
      "  batch 11700 loss: 5.681875123977661\n",
      "Epoch: [1][11700/17600]\tTime 0.9180219173431396 (1.1906415324944717)\tData 0.907956600189209 (1.181108990082374)\t\n",
      "  batch 11750 loss: 5.867655563354492\n",
      "Epoch: [1][11750/17600]\tTime 0.7762227058410645 (1.1900156418617736)\tData 0.7670023441314697 (1.180471122437335)\t\n",
      "  batch 11800 loss: 5.531072902679443\n",
      "Epoch: [1][11800/17600]\tTime 1.0270779132843018 (1.1891232521655195)\tData 1.015246868133545 (1.1795673118405423)\t\n",
      "  batch 11850 loss: 5.848126645088196\n",
      "Epoch: [1][11850/17600]\tTime 0.8775227069854736 (1.1885016181398544)\tData 0.8643350601196289 (1.1789338010474097)\t\n",
      "  batch 11900 loss: 5.622627258300781\n",
      "Epoch: [1][11900/17600]\tTime 1.4961187839508057 (1.1881626877063463)\tData 1.4814152717590332 (1.178584137924579)\t\n",
      "  batch 11950 loss: 5.776692514419556\n",
      "Epoch: [1][11950/17600]\tTime 1.1794939041137695 (1.1873883629044728)\tData 1.1651782989501953 (1.1777993094472208)\t\n",
      "  batch 12000 loss: 5.908918147087097\n",
      "Epoch: [1][12000/17600]\tTime 1.2718613147735596 (1.1869950231909752)\tData 1.2596194744110107 (1.177394256969293)\t\n",
      "  batch 12050 loss: 5.6552763223648075\n",
      "Epoch: [1][12050/17600]\tTime 1.037891149520874 (1.1861831121721702)\tData 1.0274770259857178 (1.1765732941291145)\t\n",
      "  batch 12100 loss: 6.222951283454895\n",
      "Epoch: [1][12100/17600]\tTime 0.7497415542602539 (1.18535496250657)\tData 0.7357463836669922 (1.1757349000686457)\t\n",
      "  batch 12150 loss: 5.755412769317627\n",
      "Epoch: [1][12150/17600]\tTime 1.002671718597412 (1.184758106376899)\tData 0.9880967140197754 (1.1751292924723997)\t\n",
      "  batch 12200 loss: 5.427923808097839\n",
      "Epoch: [1][12200/17600]\tTime 1.0928163528442383 (1.1840491501034283)\tData 1.0832996368408203 (1.17440955674062)\t\n",
      "  batch 12250 loss: 5.632755389213562\n",
      "Epoch: [1][12250/17600]\tTime 1.0519213676452637 (1.1835640052484007)\tData 1.039255142211914 (1.1739150008376764)\t\n",
      "  batch 12300 loss: 5.692473621368408\n",
      "Epoch: [1][12300/17600]\tTime 1.1480951309204102 (1.1831744614461572)\tData 1.137986660003662 (1.173515998503057)\t\n",
      "  batch 12350 loss: 5.928344416618347\n",
      "Epoch: [1][12350/17600]\tTime 0.987619161605835 (1.182606754360894)\tData 0.9749314785003662 (1.1729367090719431)\t\n",
      "  batch 12400 loss: 5.682840123176574\n",
      "Epoch: [1][12400/17600]\tTime 1.0777168273925781 (1.1823188905562123)\tData 1.0672364234924316 (1.1726385083890731)\t\n",
      "  batch 12450 loss: 5.618923816680908\n",
      "Epoch: [1][12450/17600]\tTime 1.273392915725708 (1.181794624271163)\tData 1.2550504207611084 (1.1721044252962471)\t\n",
      "  batch 12500 loss: 5.831949048042297\n",
      "Epoch: [1][12500/17600]\tTime 1.1383421421051025 (1.1813472320556642)\tData 1.1252384185791016 (1.1716479357528686)\t\n",
      "  batch 12550 loss: 5.697008247375488\n",
      "Epoch: [1][12550/17600]\tTime 1.1226000785827637 (1.180865270759005)\tData 1.1080107688903809 (1.171156023925994)\t\n",
      "  batch 12600 loss: 6.169602370262146\n",
      "Epoch: [1][12600/17600]\tTime 0.6582052707672119 (1.1804844195502144)\tData 0.6439735889434814 (1.1707637488085125)\t\n",
      "  batch 12650 loss: 5.68042341709137\n",
      "Epoch: [1][12650/17600]\tTime 1.2274751663208008 (1.179971418003791)\tData 1.2155687808990479 (1.1702392689135706)\t\n",
      "  batch 12700 loss: 5.887076950073242\n",
      "Epoch: [1][12700/17600]\tTime 0.9977643489837646 (1.1795370564686032)\tData 0.9847579002380371 (1.1697940534681786)\t\n",
      "  batch 12750 loss: 5.785806245803833\n",
      "Epoch: [1][12750/17600]\tTime 1.5315353870391846 (1.1793896761314542)\tData 1.521235466003418 (1.1696368778453154)\t\n",
      "  batch 12800 loss: 5.767594094276428\n",
      "Epoch: [1][12800/17600]\tTime 0.9494431018829346 (1.1790324857831)\tData 0.9390177726745605 (1.1692700928077102)\t\n",
      "  batch 12850 loss: 5.64316321849823\n",
      "Epoch: [1][12850/17600]\tTime 1.936635971069336 (1.1782878268831898)\tData 1.9261443614959717 (1.168515717769875)\t\n",
      "  batch 12900 loss: 5.62245005607605\n",
      "Epoch: [1][12900/17600]\tTime 1.3213608264923096 (1.1781082099537517)\tData 1.3086683750152588 (1.168326852340107)\t\n",
      "  batch 12950 loss: 5.6225616121292115\n",
      "Epoch: [1][12950/17600]\tTime 1.8952577114105225 (1.1780032574348007)\tData 1.884897232055664 (1.1682132367830018)\t\n",
      "  batch 13000 loss: 5.557524881362915\n",
      "Epoch: [1][13000/17600]\tTime 0.7971642017364502 (1.1774828852873582)\tData 0.782984733581543 (1.1676827100240268)\t\n",
      "  batch 13050 loss: 5.760510401725769\n",
      "Epoch: [1][13050/17600]\tTime 1.1817522048950195 (1.1771187507329772)\tData 1.1675477027893066 (1.1673079199626528)\t\n",
      "  batch 13100 loss: 5.654266877174377\n",
      "Epoch: [1][13100/17600]\tTime 1.334190845489502 (1.1765630418653708)\tData 1.3242533206939697 (1.1667433567447516)\t\n",
      "  batch 13150 loss: 5.7712223339080815\n",
      "Epoch: [1][13150/17600]\tTime 0.8190145492553711 (1.1760095773269015)\tData 0.8070008754730225 (1.1661816124680378)\t\n",
      "  batch 13200 loss: 5.51489866733551\n",
      "Epoch: [1][13200/17600]\tTime 1.399174451828003 (1.1754965903903498)\tData 1.3892204761505127 (1.1656594010013523)\t\n",
      "  batch 13250 loss: 5.504642171859741\n",
      "Epoch: [1][13250/17600]\tTime 0.8803777694702148 (1.1749902736195978)\tData 0.8694291114807129 (1.1651429804136169)\t\n",
      "  batch 13300 loss: 5.637454824447632\n",
      "Epoch: [1][13300/17600]\tTime 1.1821811199188232 (1.174507811266677)\tData 1.168381690979004 (1.164651564278997)\t\n",
      "  batch 13350 loss: 5.948753995895386\n",
      "Epoch: [1][13350/17600]\tTime 1.155045509338379 (1.1741910279913341)\tData 1.14101243019104 (1.1643247777960273)\t\n",
      "  batch 13400 loss: 5.706983141899109\n",
      "Epoch: [1][13400/17600]\tTime 0.9089136123657227 (1.1737625905648985)\tData 0.8978514671325684 (1.1638881066663942)\t\n",
      "  batch 13450 loss: 5.584637432098389\n",
      "Epoch: [1][13450/17600]\tTime 1.8122541904449463 (1.1735198529502273)\tData 1.7996082305908203 (1.1636363151968634)\t\n",
      "  batch 13500 loss: 5.860932865142822\n",
      "Epoch: [1][13500/17600]\tTime 1.128483533859253 (1.1736140384497467)\tData 1.115525245666504 (1.1637196791966755)\t\n",
      "  batch 13550 loss: 5.578942203521729\n",
      "Epoch: [1][13550/17600]\tTime 1.3318793773651123 (1.1732400818328577)\tData 1.3205740451812744 (1.16333619501318)\t\n",
      "  batch 13600 loss: 5.658819150924683\n",
      "Epoch: [1][13600/17600]\tTime 1.182784080505371 (1.1728454657863168)\tData 1.1724894046783447 (1.1629334233438267)\t\n",
      "  batch 13650 loss: 5.6196140909194945\n",
      "Epoch: [1][13650/17600]\tTime 0.8415870666503906 (1.1724996297962063)\tData 0.8295869827270508 (1.1625772203717912)\t\n",
      "  batch 13700 loss: 5.519271068572998\n",
      "Epoch: [1][13700/17600]\tTime 1.542978048324585 (1.1719626310271938)\tData 1.5280296802520752 (1.1620340878946067)\t\n",
      "  batch 13750 loss: 5.351600952148438\n",
      "Epoch: [1][13750/17600]\tTime 1.251310110092163 (1.171407935298573)\tData 1.2383267879486084 (1.1614722976164384)\t\n",
      "  batch 13800 loss: 5.620250816345215\n",
      "Epoch: [1][13800/17600]\tTime 1.0513103008270264 (1.171076558223669)\tData 1.0363636016845703 (1.1611331680719403)\t\n",
      "  batch 13850 loss: 5.505185432434082\n",
      "Epoch: [1][13850/17600]\tTime 0.9245543479919434 (1.1705555613376604)\tData 0.9110054969787598 (1.160604556476166)\t\n",
      "  batch 13900 loss: 5.680928273200989\n",
      "Epoch: [1][13900/17600]\tTime 0.6991522312164307 (1.1703076842191409)\tData 0.6866228580474854 (1.160349145638857)\t\n",
      "  batch 13950 loss: 5.910527749061584\n",
      "Epoch: [1][13950/17600]\tTime 0.6723217964172363 (1.1699677913248752)\tData 0.659043550491333 (1.16000198969277)\t\n",
      "  batch 14000 loss: 5.436696853637695\n",
      "Epoch: [1][14000/17600]\tTime 1.0959675312042236 (1.1696661823647363)\tData 1.0829746723175049 (1.1596885281630924)\t\n",
      "  batch 14050 loss: 5.54188681602478\n",
      "Epoch: [1][14050/17600]\tTime 1.7242577075958252 (1.169574086504899)\tData 1.7143499851226807 (1.1595893485520659)\t\n",
      "  batch 14100 loss: 5.253943529129028\n",
      "Epoch: [1][14100/17600]\tTime 1.0307798385620117 (1.169003975814116)\tData 1.0210294723510742 (1.1590113695124362)\t\n",
      "  batch 14150 loss: 5.634432826042175\n",
      "Epoch: [1][14150/17600]\tTime 1.38169527053833 (1.1685798987567215)\tData 1.3691298961639404 (1.1585810149095084)\t\n",
      "  batch 14200 loss: 5.4690665102005\n",
      "Epoch: [1][14200/17600]\tTime 1.1501023769378662 (1.1684787277772393)\tData 1.1399123668670654 (1.1584716001530768)\t\n",
      "  batch 14250 loss: 5.371032619476319\n",
      "Epoch: [1][14250/17600]\tTime 0.8335988521575928 (1.1685236654448927)\tData 0.8212540149688721 (1.15850889804907)\t\n",
      "  batch 14300 loss: 5.572818231582642\n",
      "Epoch: [1][14300/17600]\tTime 0.7875106334686279 (1.1680787052808108)\tData 0.7766869068145752 (1.1580560207200217)\t\n",
      "  batch 14350 loss: 5.371298899650574\n",
      "Epoch: [1][14350/17600]\tTime 0.9444835186004639 (1.1676851092149156)\tData 0.9308228492736816 (1.1576544586374369)\t\n",
      "  batch 14400 loss: 5.6126629781723025\n",
      "Epoch: [1][14400/17600]\tTime 1.19185209274292 (1.1673969296283193)\tData 1.181835412979126 (1.1573591624200343)\t\n",
      "  batch 14450 loss: 5.580569934844971\n",
      "Epoch: [1][14450/17600]\tTime 1.5384392738342285 (1.1670099251163046)\tData 1.523127555847168 (1.1569651981538556)\t\n",
      "  batch 14500 loss: 5.282815742492676\n",
      "Epoch: [1][14500/17600]\tTime 1.4771003723144531 (1.1666466697331133)\tData 1.465782642364502 (1.1565937840856355)\t\n",
      "  batch 14550 loss: 5.934162044525147\n",
      "Epoch: [1][14550/17600]\tTime 0.9427716732025146 (1.1663944339424475)\tData 0.9327883720397949 (1.1563345179115374)\t\n",
      "  batch 14600 loss: 5.660184717178344\n",
      "Epoch: [1][14600/17600]\tTime 0.8415176868438721 (1.1658704150212955)\tData 0.8293662071228027 (1.1558022902436453)\t\n",
      "  batch 14650 loss: 5.833715906143189\n",
      "Epoch: [1][14650/17600]\tTime 1.381866693496704 (1.1657071813381572)\tData 1.3720355033874512 (1.155631206890015)\t\n",
      "  batch 14700 loss: 5.577705736160278\n",
      "Epoch: [1][14700/17600]\tTime 0.7925934791564941 (1.1652565223830087)\tData 0.7803068161010742 (1.155172525246938)\t\n",
      "  batch 14750 loss: 5.500762209892273\n",
      "Epoch: [1][14750/17600]\tTime 1.9552340507507324 (1.1648612788087231)\tData 1.9456923007965088 (1.1547703058598404)\t\n",
      "  batch 14800 loss: 5.366655025482178\n",
      "Epoch: [1][14800/17600]\tTime 1.0043299198150635 (1.1648998068635528)\tData 0.9918203353881836 (1.154803840566326)\t\n",
      "  batch 14850 loss: 5.290141844749451\n",
      "Epoch: [1][14850/17600]\tTime 0.7742290496826172 (1.164701071652499)\tData 0.7611565589904785 (1.154600062193694)\t\n",
      "  batch 14900 loss: 5.392122220993042\n",
      "Epoch: [1][14900/17600]\tTime 1.4496033191680908 (1.1645849014288627)\tData 1.4368438720703125 (1.1544762104149633)\t\n",
      "  batch 14950 loss: 5.313679347038269\n",
      "Epoch: [1][14950/17600]\tTime 1.2765638828277588 (1.1641560665500603)\tData 1.2665846347808838 (1.1540405349029745)\t\n",
      "  batch 15000 loss: 5.595495615005493\n",
      "Epoch: [1][15000/17600]\tTime 0.9071497917175293 (1.1639929667154947)\tData 0.8943777084350586 (1.1538707608540852)\t\n",
      "  batch 15050 loss: 5.444694676399231\n",
      "Epoch: [1][15050/17600]\tTime 1.1949830055236816 (1.1634756812859215)\tData 1.1851911544799805 (1.1533463768943204)\t\n",
      "  batch 15100 loss: 5.776210985183716\n",
      "Epoch: [1][15100/17600]\tTime 1.330411434173584 (1.1629855246575462)\tData 1.3210041522979736 (1.152848098751725)\t\n",
      "  batch 15150 loss: 5.228213548660278\n",
      "Epoch: [1][15150/17600]\tTime 0.7334511280059814 (1.1626154668732445)\tData 0.7233767509460449 (1.1524718532625204)\t\n",
      "  batch 15200 loss: 5.226061463356018\n",
      "Epoch: [1][15200/17600]\tTime 0.7936182022094727 (1.1622235830990892)\tData 0.7832026481628418 (1.1520722183428314)\t\n",
      "  batch 15250 loss: 5.594365215301513\n",
      "Epoch: [1][15250/17600]\tTime 2.138417959213257 (1.1620617787408047)\tData 2.126941442489624 (1.151902974003651)\t\n",
      "  batch 15300 loss: 5.51456618309021\n",
      "Epoch: [1][15300/17600]\tTime 0.9748032093048096 (1.1619793787501216)\tData 0.9621517658233643 (1.1518131734966452)\t\n",
      "  batch 15350 loss: 5.579842743873596\n",
      "Epoch: [1][15350/17600]\tTime 1.134885311126709 (1.1615177582141243)\tData 1.1210746765136719 (1.1513434037168173)\t\n",
      "  batch 15400 loss: 5.534570960998535\n",
      "Epoch: [1][15400/17600]\tTime 0.8613924980163574 (1.1611379966488131)\tData 0.8483912944793701 (1.1509549231498273)\t\n",
      "  batch 15450 loss: 5.646491227149963\n",
      "Epoch: [1][15450/17600]\tTime 0.7597453594207764 (1.1607846576110445)\tData 0.7477700710296631 (1.150596469752611)\t\n",
      "  batch 15500 loss: 5.543782858848572\n",
      "Epoch: [1][15500/17600]\tTime 1.3334283828735352 (1.1605733104521228)\tData 1.323244333267212 (1.1503790327810473)\t\n",
      "  batch 15550 loss: 5.316158185005188\n",
      "Epoch: [1][15550/17600]\tTime 0.907686710357666 (1.1603241544674447)\tData 0.8948369026184082 (1.1501246342704994)\t\n",
      "  batch 15600 loss: 5.586897628307343\n",
      "Epoch: [1][15600/17600]\tTime 1.4117014408111572 (1.159893228442241)\tData 1.4015662670135498 (1.1496851541292974)\t\n",
      "  batch 15650 loss: 5.333315033912658\n",
      "Epoch: [1][15650/17600]\tTime 0.7842361927032471 (1.1594494252768568)\tData 0.7703649997711182 (1.149234409911183)\t\n",
      "  batch 15700 loss: 5.21556930065155\n",
      "Epoch: [1][15700/17600]\tTime 1.4279382228851318 (1.159232146982934)\tData 1.4157328605651855 (1.1490115085680774)\t\n",
      "  batch 15750 loss: 5.3551842308044435\n",
      "Epoch: [1][15750/17600]\tTime 1.0146048069000244 (1.1588611852100916)\tData 1.0004043579101562 (1.1486328553850689)\t\n",
      "  batch 15800 loss: 5.42744767665863\n",
      "Epoch: [1][15800/17600]\tTime 0.8167037963867188 (1.1582176491429534)\tData 0.8065166473388672 (1.1479826445066477)\t\n",
      "  batch 15850 loss: 5.540040664672851\n",
      "Epoch: [1][15850/17600]\tTime 0.9690358638763428 (1.15778379953246)\tData 0.9592094421386719 (1.147543252620035)\t\n",
      "  batch 15900 loss: 5.793957204818725\n",
      "Epoch: [1][15900/17600]\tTime 1.0068070888519287 (1.1575037024306052)\tData 0.9938788414001465 (1.1472574881187776)\t\n",
      "  batch 15950 loss: 5.485065445899964\n",
      "Epoch: [1][15950/17600]\tTime 1.1357152462005615 (1.1573055919659174)\tData 1.1228554248809814 (1.1470534189068786)\t\n",
      "  batch 16000 loss: 5.5782110357284544\n",
      "Epoch: [1][16000/17600]\tTime 0.8709213733673096 (1.1570194340199231)\tData 0.8607208728790283 (1.14676285494864)\t\n",
      "  batch 16050 loss: 5.348601717948913\n",
      "Epoch: [1][16050/17600]\tTime 1.2493855953216553 (1.1566748394773014)\tData 1.2398886680603027 (1.1464135217518079)\t\n",
      "  batch 16100 loss: 5.446277542114258\n",
      "Epoch: [1][16100/17600]\tTime 1.4242911338806152 (1.1565047484895457)\tData 1.4094700813293457 (1.1462371003405647)\t\n",
      "  batch 16150 loss: 5.264273943901062\n",
      "Epoch: [1][16150/17600]\tTime 1.0307631492614746 (1.1563220428313263)\tData 1.0173652172088623 (1.1460483278947717)\t\n",
      "  batch 16200 loss: 5.190483903884887\n",
      "Epoch: [1][16200/17600]\tTime 1.299119234085083 (1.1559170556215592)\tData 1.288994312286377 (1.1456354056905818)\t\n",
      "  batch 16250 loss: 5.596114783287049\n",
      "Epoch: [1][16250/17600]\tTime 1.0946753025054932 (1.1554194004352276)\tData 1.0809121131896973 (1.1451317175498374)\t\n",
      "  batch 16300 loss: 5.275107359886169\n",
      "Epoch: [1][16300/17600]\tTime 0.7635674476623535 (1.1549793840771072)\tData 0.7517580986022949 (1.1446865168817204)\t\n",
      "  batch 16350 loss: 5.164889726638794\n",
      "Epoch: [1][16350/17600]\tTime 1.0992016792297363 (1.154625075701909)\tData 1.0862281322479248 (1.1443266939169041)\t\n",
      "  batch 16400 loss: 5.605480489730835\n",
      "Epoch: [1][16400/17600]\tTime 1.0790998935699463 (1.1546607099945951)\tData 1.0687236785888672 (1.1443566403447127)\t\n",
      "  batch 16450 loss: 5.390578742027283\n",
      "Epoch: [1][16450/17600]\tTime 1.1367781162261963 (1.1544248779638921)\tData 1.1237635612487793 (1.1441144563796672)\t\n",
      "  batch 16500 loss: 5.179987978935242\n",
      "Epoch: [1][16500/17600]\tTime 1.1288745403289795 (1.1539810983628938)\tData 1.118323802947998 (1.1436659896590493)\t\n",
      "  batch 16550 loss: 5.408818774223327\n",
      "Epoch: [1][16550/17600]\tTime 0.9529561996459961 (1.153732783527893)\tData 0.9387650489807129 (1.1434125083018645)\t\n",
      "  batch 16600 loss: 5.5534881973266605\n",
      "Epoch: [1][16600/17600]\tTime 1.0381314754486084 (1.1535341600481286)\tData 1.025914192199707 (1.1432092229285873)\t\n",
      "  batch 16650 loss: 5.347286992073059\n",
      "Epoch: [1][16650/17600]\tTime 0.8471436500549316 (1.153388249165303)\tData 0.8374426364898682 (1.1430586069410629)\t\n",
      "  batch 16700 loss: 5.584919290542603\n",
      "Epoch: [1][16700/17600]\tTime 0.9458277225494385 (1.1530876244185213)\tData 0.9328718185424805 (1.1427529333594317)\t\n",
      "  batch 16750 loss: 5.330775279998779\n",
      "Epoch: [1][16750/17600]\tTime 1.527534008026123 (1.152786352897758)\tData 1.514603614807129 (1.1424458604926493)\t\n",
      "  batch 16800 loss: 5.107171649932861\n",
      "Epoch: [1][16800/17600]\tTime 0.9734818935394287 (1.1524446867051579)\tData 0.9620809555053711 (1.14210041982787)\t\n",
      "  batch 16850 loss: 5.576888847351074\n",
      "Epoch: [1][16850/17600]\tTime 1.0158262252807617 (1.1522119167226004)\tData 1.000697374343872 (1.1418644188419647)\t\n",
      "  batch 16900 loss: 5.429446177482605\n",
      "Epoch: [1][16900/17600]\tTime 1.315478801727295 (1.1521443484661846)\tData 1.3020806312561035 (1.141790469257084)\t\n",
      "  batch 16950 loss: 5.135120697021485\n",
      "Epoch: [1][16950/17600]\tTime 0.7490074634552002 (1.1518335546926763)\tData 0.7382287979125977 (1.1414760086318385)\t\n",
      "  batch 17000 loss: 5.482817325592041\n",
      "Epoch: [1][17000/17600]\tTime 1.1130499839782715 (1.1515380102746626)\tData 1.1031241416931152 (1.14117449408419)\t\n",
      "  batch 17050 loss: 5.808578715324402\n",
      "Epoch: [1][17050/17600]\tTime 0.8863019943237305 (1.15141675021991)\tData 0.8738090991973877 (1.1410497534519766)\t\n",
      "  batch 17100 loss: 4.99758819103241\n",
      "Epoch: [1][17100/17600]\tTime 1.0988905429840088 (1.1511657042670669)\tData 1.0861833095550537 (1.1407930011358876)\t\n",
      "  batch 17150 loss: 5.280430483818054\n",
      "Epoch: [1][17150/17600]\tTime 1.2726948261260986 (1.1511876428092533)\tData 1.2589740753173828 (1.1408101456227873)\t\n",
      "  batch 17200 loss: 5.369323348999023\n",
      "Epoch: [1][17200/17600]\tTime 1.1447951793670654 (1.1508672617341196)\tData 1.13230299949646 (1.1404857331514358)\t\n",
      "  batch 17250 loss: 5.565705862045288\n",
      "Epoch: [1][17250/17600]\tTime 0.9722003936767578 (1.1506691425986912)\tData 0.9617445468902588 (1.1402822677778162)\t\n",
      "  batch 17300 loss: 5.30470796585083\n",
      "Epoch: [1][17300/17600]\tTime 1.1725115776062012 (1.1503968964697997)\tData 1.162466049194336 (1.1400052282851556)\t\n",
      "  batch 17350 loss: 5.404197063446045\n",
      "Epoch: [1][17350/17600]\tTime 0.6959364414215088 (1.1504797045573034)\tData 0.6850602626800537 (1.1400827076799245)\t\n",
      "  batch 17400 loss: 5.358836283683777\n",
      "Epoch: [1][17400/17600]\tTime 1.0343079566955566 (1.1501962999502817)\tData 1.0209150314331055 (1.1397954539320936)\t\n",
      "  batch 17450 loss: 5.433777661323547\n",
      "Epoch: [1][17450/17600]\tTime 1.0331807136535645 (1.1498113639580145)\tData 1.0201432704925537 (1.1394043338879474)\t\n",
      "  batch 17500 loss: 5.114288878440857\n",
      "Epoch: [1][17500/17600]\tTime 0.9009044170379639 (1.1497033598354884)\tData 0.8883411884307861 (1.1392927441460745)\t\n",
      "  batch 17550 loss: 5.353708000183105\n",
      "Epoch: [1][17550/17600]\tTime 1.0225396156311035 (1.149375748457732)\tData 1.0099143981933594 (1.138960617383321)\t\n",
      "  batch 17600 loss: 5.632038033008575\n",
      "Epoch: [1][17600/17600]\tTime 1.0066840648651123 (1.1491814702207392)\tData 0.9914770126342773 (1.1387600622529332)\t\n",
      "Finished training epoch 1\n",
      "Epoch Loss: 10.687194923036163\n",
      "Starting training epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79c8aec92b646f68e767319188a78c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 50 loss: 5.2627639484405515\n",
      "Epoch: [2][50/17600]\tTime 0.9513545036315918 (1.102919192314148)\tData 0.9378535747528076 (1.0902174758911132)\t\n",
      "  batch 100 loss: 5.452137999534607\n",
      "Epoch: [2][100/17600]\tTime 0.7375247478485107 (1.0669990181922913)\tData 0.7230088710784912 (1.054327130317688)\t\n",
      "  batch 150 loss: 5.1708753490448\n",
      "Epoch: [2][150/17600]\tTime 1.2102572917938232 (1.0751028378804526)\tData 1.1963965892791748 (1.0625444253285725)\t\n",
      "  batch 200 loss: 5.248636932373047\n",
      "Epoch: [2][200/17600]\tTime 1.085035800933838 (1.093427301645279)\tData 1.071558952331543 (1.081041761636734)\t\n",
      "  batch 250 loss: 5.340456528663635\n",
      "Epoch: [2][250/17600]\tTime 0.989823579788208 (1.068752371788025)\tData 0.9771020412445068 (1.056390139579773)\t\n",
      "  batch 300 loss: 5.45594244480133\n",
      "Epoch: [2][300/17600]\tTime 0.8946633338928223 (1.062893912792206)\tData 0.8823950290679932 (1.0506064152717591)\t\n",
      "  batch 350 loss: 5.651820096969605\n",
      "Epoch: [2][350/17600]\tTime 1.041299819946289 (1.062803705760411)\tData 1.0287234783172607 (1.05052850655147)\t\n",
      "  batch 400 loss: 5.093485798835754\n",
      "Epoch: [2][400/17600]\tTime 0.8895230293273926 (1.0558900958299637)\tData 0.879481315612793 (1.0436295080184936)\t\n",
      "  batch 450 loss: 5.116192717552185\n",
      "Epoch: [2][450/17600]\tTime 0.9112515449523926 (1.0564398924509684)\tData 0.8969931602478027 (1.0442239136166043)\t\n",
      "  batch 500 loss: 5.541254005432129\n",
      "Epoch: [2][500/17600]\tTime 1.495223045349121 (1.0615933809280396)\tData 1.4845538139343262 (1.0493375225067139)\t\n",
      "  batch 550 loss: 5.350968155860901\n",
      "Epoch: [2][550/17600]\tTime 0.910811185836792 (1.0621092896028)\tData 0.9013099670410156 (1.0498332184011285)\t\n",
      "  batch 600 loss: 5.382801938056946\n",
      "Epoch: [2][600/17600]\tTime 1.390974521636963 (1.0631365629037222)\tData 1.3780620098114014 (1.0508511392275492)\t\n",
      "  batch 650 loss: 5.341440415382385\n",
      "Epoch: [2][650/17600]\tTime 1.362778902053833 (1.0558446796123797)\tData 1.3501861095428467 (1.0435562518926766)\t\n",
      "  batch 700 loss: 5.395612826347351\n",
      "Epoch: [2][700/17600]\tTime 1.0800371170043945 (1.0590544741494314)\tData 1.0672402381896973 (1.0468109287534442)\t\n",
      "  batch 750 loss: 5.347255969047547\n",
      "Epoch: [2][750/17600]\tTime 0.9063735008239746 (1.0555258153279623)\tData 0.8939168453216553 (1.0432592420578002)\t\n",
      "  batch 800 loss: 5.7220867109298705\n",
      "Epoch: [2][800/17600]\tTime 1.231459379196167 (1.0564619186520576)\tData 1.2183001041412354 (1.0442098486423492)\t\n",
      "  batch 850 loss: 5.639958028793335\n",
      "Epoch: [2][850/17600]\tTime 0.6125235557556152 (1.0523389140297386)\tData 0.6026508808135986 (1.040075431431041)\t\n",
      "  batch 900 loss: 4.9447078609466555\n",
      "Epoch: [2][900/17600]\tTime 1.1500773429870605 (1.0533691011534796)\tData 1.1401605606079102 (1.0411220762464735)\t\n",
      "  batch 950 loss: 5.375040326118469\n",
      "Epoch: [2][950/17600]\tTime 0.9373204708099365 (1.0544343074999358)\tData 0.9278359413146973 (1.0422110489795082)\t\n",
      "  batch 1000 loss: 5.208001899719238\n",
      "Epoch: [2][1000/17600]\tTime 0.9506654739379883 (1.0552470343112945)\tData 0.9405741691589355 (1.0430171422958374)\t\n",
      "  batch 1050 loss: 5.34124174118042\n",
      "Epoch: [2][1050/17600]\tTime 1.2976069450378418 (1.0656752152669997)\tData 1.2869172096252441 (1.0534512996673584)\t\n",
      "  batch 1100 loss: 4.9893829870224\n",
      "Epoch: [2][1100/17600]\tTime 0.8751461505889893 (1.0634881500764326)\tData 0.8625249862670898 (1.0512756785479458)\t\n",
      "  batch 1150 loss: 5.151891431808472\n",
      "Epoch: [2][1150/17600]\tTime 0.835108757019043 (1.0628684914630393)\tData 0.8253507614135742 (1.0506483252152152)\t\n",
      "  batch 1200 loss: 5.3878482151031495\n",
      "Epoch: [2][1200/17600]\tTime 1.7685654163360596 (1.060395955046018)\tData 1.7537899017333984 (1.0481890519460042)\t\n",
      "  batch 1250 loss: 5.315054364204407\n",
      "Epoch: [2][1250/17600]\tTime 0.9386706352233887 (1.0583954069137573)\tData 0.9276049137115479 (1.0462041601181031)\t\n",
      "  batch 1300 loss: 5.078237662315368\n",
      "Epoch: [2][1300/17600]\tTime 0.7125656604766846 (1.0556488572634184)\tData 0.7032253742218018 (1.0434917930456309)\t\n",
      "  batch 1350 loss: 5.408258810043335\n",
      "Epoch: [2][1350/17600]\tTime 0.8534371852874756 (1.0523680248966925)\tData 0.8397862911224365 (1.0401969266820836)\t\n",
      "  batch 1400 loss: 5.173865151405335\n",
      "Epoch: [2][1400/17600]\tTime 1.3998451232910156 (1.0518890779359)\tData 1.3895602226257324 (1.0397093883582524)\t\n",
      "  batch 1450 loss: 5.258637142181397\n",
      "Epoch: [2][1450/17600]\tTime 0.8715000152587891 (1.050522656769588)\tData 0.8608901500701904 (1.0383276469131997)\t\n",
      "  batch 1500 loss: 5.225123252868652\n",
      "Epoch: [2][1500/17600]\tTime 1.2068111896514893 (1.051200809955597)\tData 1.1936578750610352 (1.0390212450027465)\t\n",
      "  batch 1550 loss: 5.301112627983093\n",
      "Epoch: [2][1550/17600]\tTime 0.6821997165679932 (1.0506359995565107)\tData 0.6670308113098145 (1.0384705638885499)\t\n",
      "  batch 1600 loss: 5.373831377029419\n",
      "Epoch: [2][1600/17600]\tTime 1.0808417797088623 (1.0499259392917155)\tData 1.0658013820648193 (1.0377642564475535)\t\n",
      "  batch 1650 loss: 5.542886819839477\n",
      "Epoch: [2][1650/17600]\tTime 1.4142241477966309 (1.049573835026134)\tData 1.4042518138885498 (1.037422001434095)\t\n",
      "  batch 1700 loss: 5.372141246795654\n",
      "Epoch: [2][1700/17600]\tTime 0.8061776161193848 (1.049334468981799)\tData 0.7955715656280518 (1.0371895394605748)\t\n",
      "  batch 1750 loss: 5.08643470287323\n",
      "Epoch: [2][1750/17600]\tTime 0.9420497417449951 (1.050506363596235)\tData 0.9283370971679688 (1.0383613674981254)\t\n",
      "  batch 1800 loss: 5.2690017127990725\n",
      "Epoch: [2][1800/17600]\tTime 1.374605655670166 (1.0508977439668443)\tData 1.3640048503875732 (1.038751199112998)\t\n",
      "  batch 1850 loss: 5.382017102241516\n",
      "Epoch: [2][1850/17600]\tTime 0.7463498115539551 (1.049179679123131)\tData 0.7335484027862549 (1.0370338974772273)\t\n",
      "  batch 1900 loss: 5.48575355052948\n",
      "Epoch: [2][1900/17600]\tTime 1.180469036102295 (1.0485751259954352)\tData 1.1660597324371338 (1.0364328644150183)\t\n",
      "  batch 1950 loss: 5.428557181358338\n",
      "Epoch: [2][1950/17600]\tTime 0.9993288516998291 (1.0494073976614537)\tData 0.9865138530731201 (1.0372779704362918)\t\n",
      "  batch 2000 loss: 5.409117269515991\n",
      "Epoch: [2][2000/17600]\tTime 1.134223461151123 (1.0478182374238967)\tData 1.1240417957305908 (1.0356940068006515)\t\n",
      "  batch 2050 loss: 5.364218688011169\n",
      "Epoch: [2][2050/17600]\tTime 1.0200412273406982 (1.0487183181250967)\tData 1.0087671279907227 (1.0366006233634018)\t\n",
      "  batch 2100 loss: 4.771992282867432\n",
      "Epoch: [2][2100/17600]\tTime 0.9359214305877686 (1.048809894493648)\tData 0.9261612892150879 (1.036686962786175)\t\n",
      "  batch 2150 loss: 5.2175162982940675\n",
      "Epoch: [2][2150/17600]\tTime 0.9729337692260742 (1.0482462725528452)\tData 0.9629201889038086 (1.036132808507875)\t\n",
      "  batch 2200 loss: 5.4855980920791625\n",
      "Epoch: [2][2200/17600]\tTime 1.6207892894744873 (1.0496969842910766)\tData 1.6080803871154785 (1.0375935011560267)\t\n",
      "  batch 2250 loss: 4.931055240631103\n",
      "Epoch: [2][2250/17600]\tTime 0.9398863315582275 (1.0503078261481391)\tData 0.9291095733642578 (1.0382004075580173)\t\n",
      "  batch 2300 loss: 5.319936571121215\n",
      "Epoch: [2][2300/17600]\tTime 1.2838056087493896 (1.0508830483063407)\tData 1.272249460220337 (1.0387647409024445)\t\n",
      "  batch 2350 loss: 5.151075258255005\n",
      "Epoch: [2][2350/17600]\tTime 0.9382035732269287 (1.0515329443140233)\tData 0.9256088733673096 (1.0394147006501542)\t\n",
      "  batch 2400 loss: 5.4461352205276485\n",
      "Epoch: [2][2400/17600]\tTime 1.0298945903778076 (1.051899548669656)\tData 1.015655517578125 (1.039791098833084)\t\n",
      "  batch 2450 loss: 5.621312675476074\n",
      "Epoch: [2][2450/17600]\tTime 1.2003674507141113 (1.0523168494750041)\tData 1.1884701251983643 (1.0401996534697864)\t\n",
      "  batch 2500 loss: 5.279382095336914\n",
      "Epoch: [2][2500/17600]\tTime 0.7919826507568359 (1.0520311752319336)\tData 0.7809445858001709 (1.039921007156372)\t\n",
      "  batch 2550 loss: 5.109844961166382\n",
      "Epoch: [2][2550/17600]\tTime 1.7585277557373047 (1.0517393289827832)\tData 1.7450895309448242 (1.039630910836014)\t\n",
      "  batch 2600 loss: 5.312632484436035\n",
      "Epoch: [2][2600/17600]\tTime 1.125873327255249 (1.051898152919916)\tData 1.1131596565246582 (1.0397900422719808)\t\n",
      "  batch 2650 loss: 5.519855823516846\n",
      "Epoch: [2][2650/17600]\tTime 1.0766384601593018 (1.0523346921632875)\tData 1.064549207687378 (1.0402312182480433)\t\n",
      "  batch 2700 loss: 5.083351650238037\n",
      "Epoch: [2][2700/17600]\tTime 1.2209787368774414 (1.0534477509392632)\tData 1.2088565826416016 (1.041339682208167)\t\n",
      "  batch 2750 loss: 5.1431131219863895\n",
      "Epoch: [2][2750/17600]\tTime 1.089827299118042 (1.0534184568578546)\tData 1.075549602508545 (1.041307131247087)\t\n",
      "  batch 2800 loss: 5.192029104232788\n",
      "Epoch: [2][2800/17600]\tTime 1.4195501804351807 (1.055463468176978)\tData 1.4093470573425293 (1.04335555434227)\t\n",
      "  batch 2850 loss: 5.258210706710815\n",
      "Epoch: [2][2850/17600]\tTime 0.9137449264526367 (1.0560997189136974)\tData 0.9013087749481201 (1.0439887198230677)\t\n",
      "  batch 2900 loss: 4.999444975852966\n",
      "Epoch: [2][2900/17600]\tTime 1.3132870197296143 (1.0552499638754747)\tData 1.3002169132232666 (1.0431386793892958)\t\n",
      "  batch 2950 loss: 4.973551650047302\n",
      "Epoch: [2][2950/17600]\tTime 0.9477462768554688 (1.0537865637116512)\tData 0.9338870048522949 (1.0416779573893142)\t\n",
      "  batch 3000 loss: 5.304862279891967\n",
      "Epoch: [2][3000/17600]\tTime 1.1079697608947754 (1.0523891140619914)\tData 1.0933990478515625 (1.0402853129704794)\t\n",
      "  batch 3050 loss: 5.483826117515564\n",
      "Epoch: [2][3050/17600]\tTime 0.8018171787261963 (1.05333616647564)\tData 0.7907238006591797 (1.04122835886283)\t\n",
      "  batch 3100 loss: 5.181479802131653\n",
      "Epoch: [2][3100/17600]\tTime 0.8981616497039795 (1.0529920304975202)\tData 0.8850677013397217 (1.040881658677132)\t\n",
      "  batch 3150 loss: 4.960156321525574\n",
      "Epoch: [2][3150/17600]\tTime 1.041179895401001 (1.0527778937324646)\tData 1.0262548923492432 (1.0406600590357704)\t\n",
      "  batch 3200 loss: 5.4722279977798465\n",
      "Epoch: [2][3200/17600]\tTime 1.1205861568450928 (1.052660739570856)\tData 1.1065788269042969 (1.0405409269779922)\t\n",
      "  batch 3250 loss: 5.388127183914184\n",
      "Epoch: [2][3250/17600]\tTime 1.326582670211792 (1.052611233491164)\tData 1.3164567947387695 (1.040494940684392)\t\n",
      "  batch 3300 loss: 5.173494443893433\n",
      "Epoch: [2][3300/17600]\tTime 1.1318480968475342 (1.0527290546532833)\tData 1.1188557147979736 (1.0406141105565159)\t\n",
      "  batch 3350 loss: 4.951135673522949\n",
      "Epoch: [2][3350/17600]\tTime 0.8637866973876953 (1.053120717575301)\tData 0.8512759208679199 (1.0410075545666824)\t\n",
      "  batch 3400 loss: 5.089692916870117\n",
      "Epoch: [2][3400/17600]\tTime 0.8985438346862793 (1.0543887411846835)\tData 0.8851926326751709 (1.0422783387408536)\t\n",
      "  batch 3450 loss: 4.954882254600525\n",
      "Epoch: [2][3450/17600]\tTime 1.1411938667297363 (1.0542612453820048)\tData 1.1277694702148438 (1.042147934264031)\t\n",
      "  batch 3500 loss: 5.123653235435486\n",
      "Epoch: [2][3500/17600]\tTime 0.8874197006225586 (1.0536210386412483)\tData 0.8740088939666748 (1.0414961560794285)\t\n",
      "  batch 3550 loss: 5.1328214836120605\n",
      "Epoch: [2][3550/17600]\tTime 1.350294828414917 (1.0546304366957973)\tData 1.3378193378448486 (1.0425073001754117)\t\n",
      "  batch 3600 loss: 5.3130183506011965\n",
      "Epoch: [2][3600/17600]\tTime 1.0590565204620361 (1.054023310409652)\tData 1.0490505695343018 (1.0419029343128203)\t\n",
      "  batch 3650 loss: 5.610747513771057\n",
      "Epoch: [2][3650/17600]\tTime 0.9609072208404541 (1.0543003246228988)\tData 0.9509541988372803 (1.0421866610278823)\t\n",
      "  batch 3700 loss: 5.25796902179718\n",
      "Epoch: [2][3700/17600]\tTime 1.7252476215362549 (1.054176195763253)\tData 1.7125511169433594 (1.0420565203718237)\t\n",
      "  batch 3750 loss: 5.090017518997192\n",
      "Epoch: [2][3750/17600]\tTime 0.8484804630279541 (1.053530241839091)\tData 0.8344271183013916 (1.041414774131775)\t\n",
      "  batch 3800 loss: 5.140632743835449\n",
      "Epoch: [2][3800/17600]\tTime 0.7485134601593018 (1.053096145893398)\tData 0.7354443073272705 (1.0409793127210516)\t\n",
      "  batch 3850 loss: 5.444084620475769\n",
      "Epoch: [2][3850/17600]\tTime 0.769212007522583 (1.053005856972236)\tData 0.759340763092041 (1.040886592988844)\t\n",
      "  batch 3900 loss: 5.078672347068786\n",
      "Epoch: [2][3900/17600]\tTime 0.8982770442962646 (1.0525567548702925)\tData 0.8852701187133789 (1.040438991509951)\t\n",
      "  batch 3950 loss: 5.132519488334656\n",
      "Epoch: [2][3950/17600]\tTime 1.2606987953186035 (1.0529407294792466)\tData 1.249373435974121 (1.0408260344855393)\t\n",
      "  batch 4000 loss: 4.9339717721939085\n",
      "Epoch: [2][4000/17600]\tTime 0.8394191265106201 (1.053233704507351)\tData 0.8266632556915283 (1.0411255546212197)\t\n",
      "  batch 4050 loss: 5.259832530021668\n",
      "Epoch: [2][4050/17600]\tTime 0.938981294631958 (1.0524745643874744)\tData 0.9247615337371826 (1.0403633442631475)\t\n",
      "  batch 4100 loss: 4.972267851829529\n",
      "Epoch: [2][4100/17600]\tTime 1.0845706462860107 (1.0531145176654908)\tData 1.0699739456176758 (1.0409976954576445)\t\n",
      "  batch 4150 loss: 5.389009127616882\n",
      "Epoch: [2][4150/17600]\tTime 0.9826738834381104 (1.0534841302504023)\tData 0.9716312885284424 (1.0413702184033682)\t\n",
      "  batch 4200 loss: 5.157402057647705\n",
      "Epoch: [2][4200/17600]\tTime 0.9402990341186523 (1.0538697304612115)\tData 0.927849531173706 (1.0417572639102028)\t\n",
      "  batch 4250 loss: 5.072449238300323\n",
      "Epoch: [2][4250/17600]\tTime 0.7713911533355713 (1.0542031653348138)\tData 0.7577834129333496 (1.0420907491235172)\t\n",
      "  batch 4300 loss: 5.086880888938904\n",
      "Epoch: [2][4300/17600]\tTime 1.3893375396728516 (1.0537610630656398)\tData 1.374708652496338 (1.041645598688791)\t\n",
      "  batch 4350 loss: 5.176212344169617\n",
      "Epoch: [2][4350/17600]\tTime 1.7512643337249756 (1.0542612623346264)\tData 1.740051031112671 (1.042140472236721)\t\n",
      "  batch 4400 loss: 5.292040839195251\n",
      "Epoch: [2][4400/17600]\tTime 1.2627694606781006 (1.0544245998425916)\tData 1.2503859996795654 (1.0423008891669188)\t\n",
      "  batch 4450 loss: 4.7640384840965275\n",
      "Epoch: [2][4450/17600]\tTime 1.425793170928955 (1.0548778246761707)\tData 1.4153494834899902 (1.0427522914329272)\t\n",
      "  batch 4500 loss: 5.196065020561218\n",
      "Epoch: [2][4500/17600]\tTime 1.50252366065979 (1.0564177837901645)\tData 1.4924018383026123 (1.0442948481241863)\t\n",
      "  batch 4550 loss: 5.143196454048157\n",
      "Epoch: [2][4550/17600]\tTime 1.3794374465942383 (1.0560285521601582)\tData 1.3664376735687256 (1.043904332800226)\t\n",
      "  batch 4600 loss: 5.149404468536377\n",
      "Epoch: [2][4600/17600]\tTime 0.8627567291259766 (1.0563936420627262)\tData 0.8524801731109619 (1.0442670370703158)\t\n",
      "  batch 4650 loss: 5.166734642982483\n",
      "Epoch: [2][4650/17600]\tTime 0.6258459091186523 (1.056956603142523)\tData 0.6156785488128662 (1.044834048466016)\t\n",
      "  batch 4700 loss: 5.296024913787842\n",
      "Epoch: [2][4700/17600]\tTime 0.9203026294708252 (1.0567990643420118)\tData 0.907843828201294 (1.0446700601882124)\t\n",
      "  batch 4750 loss: 5.424527044296265\n",
      "Epoch: [2][4750/17600]\tTime 1.2089574337005615 (1.0573070308283756)\tData 1.1939153671264648 (1.045179931640625)\t\n",
      "  batch 4800 loss: 4.973975133895874\n",
      "Epoch: [2][4800/17600]\tTime 1.0618798732757568 (1.0578377505640189)\tData 1.0480163097381592 (1.0457104538877806)\t\n",
      "  batch 4850 loss: 5.429745907783508\n",
      "Epoch: [2][4850/17600]\tTime 0.8369264602661133 (1.0584130553609317)\tData 0.8243181705474854 (1.0462864993773784)\t\n",
      "  batch 4900 loss: 4.8545009756088255\n",
      "Epoch: [2][4900/17600]\tTime 0.8246524333953857 (1.058085498323246)\tData 0.8120448589324951 (1.0459566717245141)\t\n",
      "  batch 4950 loss: 5.2456484270095824\n",
      "Epoch: [2][4950/17600]\tTime 0.9573676586151123 (1.0580699962558169)\tData 0.9444093704223633 (1.0459347926245794)\t\n",
      "  batch 5000 loss: 4.964362578392029\n",
      "Epoch: [2][5000/17600]\tTime 1.1418898105621338 (1.0582320209026337)\tData 1.1268439292907715 (1.0460968905448913)\t\n",
      "  batch 5050 loss: 5.209357757568359\n",
      "Epoch: [2][5050/17600]\tTime 0.8372466564178467 (1.058748094681466)\tData 0.8270940780639648 (1.0466121824661103)\t\n",
      "  batch 5100 loss: 5.349534730911255\n",
      "Epoch: [2][5100/17600]\tTime 1.2369201183319092 (1.0594347224516028)\tData 1.2268097400665283 (1.0472947037921232)\t\n",
      "  batch 5150 loss: 5.620611925125122\n",
      "Epoch: [2][5150/17600]\tTime 0.6635129451751709 (1.0593027613000963)\tData 0.651287317276001 (1.0471609911409396)\t\n",
      "  batch 5200 loss: 5.085120148658753\n",
      "Epoch: [2][5200/17600]\tTime 0.9300789833068848 (1.058750436581098)\tData 0.917529821395874 (1.0466072012827947)\t\n",
      "  batch 5250 loss: 5.041052885055542\n",
      "Epoch: [2][5250/17600]\tTime 1.1488368511199951 (1.059137342589242)\tData 1.1360466480255127 (1.0469949054263887)\t\n",
      "  batch 5300 loss: 5.123028435707092\n",
      "Epoch: [2][5300/17600]\tTime 0.7515482902526855 (1.0585898340423152)\tData 0.736569881439209 (1.0464495828466596)\t\n",
      "  batch 5350 loss: 5.07260112285614\n",
      "Epoch: [2][5350/17600]\tTime 0.9895267486572266 (1.0593572738237471)\tData 0.9765360355377197 (1.0472175221131226)\t\n",
      "  batch 5400 loss: 4.6861471891403195\n",
      "Epoch: [2][5400/17600]\tTime 0.8986012935638428 (1.0595714295351948)\tData 0.8855111598968506 (1.0474313565095266)\t\n",
      "  batch 5450 loss: 5.276455616950988\n",
      "Epoch: [2][5450/17600]\tTime 1.0746958255767822 (1.0603501317697928)\tData 1.0626230239868164 (1.048209995261026)\t\n",
      "  batch 5500 loss: 5.204011034965515\n",
      "Epoch: [2][5500/17600]\tTime 1.0775277614593506 (1.0604254394444552)\tData 1.0649960041046143 (1.0482821266867899)\t\n",
      "  batch 5550 loss: 4.7345286464691165\n",
      "Epoch: [2][5550/17600]\tTime 0.9033958911895752 (1.0607897636911892)\tData 0.8928365707397461 (1.0486449123502852)\t\n",
      "  batch 5600 loss: 5.023717398643494\n",
      "Epoch: [2][5600/17600]\tTime 1.010016918182373 (1.06022073920284)\tData 1.0005292892456055 (1.0480793901000705)\t\n",
      "  batch 5650 loss: 5.320185127258301\n",
      "Epoch: [2][5650/17600]\tTime 1.17997407913208 (1.061672369062373)\tData 1.1696209907531738 (1.0495340340960342)\t\n",
      "  batch 5700 loss: 5.25895655632019\n",
      "Epoch: [2][5700/17600]\tTime 0.9123353958129883 (1.0618045074061344)\tData 0.9028651714324951 (1.0496632952857436)\t\n",
      "  batch 5750 loss: 5.143940424919128\n",
      "Epoch: [2][5750/17600]\tTime 1.090468406677246 (1.0613471517562867)\tData 1.0782687664031982 (1.0492058476572452)\t\n",
      "  batch 5800 loss: 5.157580089569092\n",
      "Epoch: [2][5800/17600]\tTime 0.8406078815460205 (1.0615218837096774)\tData 0.8302359580993652 (1.049382867854217)\t\n",
      "  batch 5850 loss: 5.18508828163147\n",
      "Epoch: [2][5850/17600]\tTime 2.1472647190093994 (1.0615077338666998)\tData 2.1346616744995117 (1.049369204513028)\t\n",
      "  batch 5900 loss: 5.393381834030151\n",
      "Epoch: [2][5900/17600]\tTime 1.276681661605835 (1.0620953930434534)\tData 1.2667784690856934 (1.049959625551256)\t\n",
      "  batch 5950 loss: 5.1476582384109495\n",
      "Epoch: [2][5950/17600]\tTime 1.396299123764038 (1.0622714542741536)\tData 1.3837289810180664 (1.0501351460689257)\t\n",
      "  batch 6000 loss: 5.471575422286987\n",
      "Epoch: [2][6000/17600]\tTime 0.6326594352722168 (1.0621732071638108)\tData 0.6197447776794434 (1.0500365670919418)\t\n",
      "  batch 6050 loss: 5.442829513549805\n",
      "Epoch: [2][6050/17600]\tTime 0.9329004287719727 (1.0621417386472718)\tData 0.9207117557525635 (1.050002618387711)\t\n",
      "  batch 6100 loss: 5.1181499910354615\n",
      "Epoch: [2][6100/17600]\tTime 1.0900323390960693 (1.0619209123830327)\tData 1.0797526836395264 (1.049779960210206)\t\n",
      "  batch 6150 loss: 5.389074745178223\n",
      "Epoch: [2][6150/17600]\tTime 1.083488941192627 (1.061926492481697)\tData 1.068955421447754 (1.0497871167485306)\t\n",
      "  batch 6200 loss: 5.209254121780395\n",
      "Epoch: [2][6200/17600]\tTime 0.6041395664215088 (1.0615210994597404)\tData 0.5940971374511719 (1.0493812689089006)\t\n",
      "  batch 6250 loss: 5.244491753578186\n",
      "Epoch: [2][6250/17600]\tTime 1.7607948780059814 (1.0615273918151855)\tData 1.7479557991027832 (1.0493857301330567)\t\n",
      "  batch 6300 loss: 5.099981818199158\n",
      "Epoch: [2][6300/17600]\tTime 1.083244800567627 (1.0612564653063576)\tData 1.06980299949646 (1.049112274987357)\t\n",
      "  batch 6350 loss: 4.711932997703553\n",
      "Epoch: [2][6350/17600]\tTime 0.9903318881988525 (1.0608276125765221)\tData 0.9802243709564209 (1.0486857300480519)\t\n",
      "  batch 6400 loss: 5.016506228446961\n",
      "Epoch: [2][6400/17600]\tTime 0.9600608348846436 (1.0611135268583893)\tData 0.946923017501831 (1.0489700369536876)\t\n",
      "  batch 6450 loss: 5.074208478927613\n",
      "Epoch: [2][6450/17600]\tTime 0.979327917098999 (1.0611063096319981)\tData 0.9635684490203857 (1.048959233557531)\t\n",
      "  batch 6500 loss: 4.989652934074402\n",
      "Epoch: [2][6500/17600]\tTime 0.951063871383667 (1.061029480090508)\tData 0.940988302230835 (1.0488866205582252)\t\n",
      "  batch 6550 loss: 5.08350378036499\n",
      "Epoch: [2][6550/17600]\tTime 1.339538812637329 (1.0615464517724422)\tData 1.3270680904388428 (1.049402797276737)\t\n",
      "  batch 6600 loss: 5.064166870117187\n",
      "Epoch: [2][6600/17600]\tTime 1.064089298248291 (1.0614582203735006)\tData 1.0505287647247314 (1.0493155760114843)\t\n",
      "  batch 6650 loss: 5.490285410881042\n",
      "Epoch: [2][6650/17600]\tTime 1.3708875179290771 (1.0612239681329942)\tData 1.3574681282043457 (1.0490793848396245)\t\n",
      "  batch 6700 loss: 5.058491077423096\n",
      "Epoch: [2][6700/17600]\tTime 1.5918700695037842 (1.0610511775159124)\tData 1.5816638469696045 (1.0489048673501655)\t\n",
      "  batch 6750 loss: 5.019080481529236\n",
      "Epoch: [2][6750/17600]\tTime 0.8416669368743896 (1.060936834829825)\tData 0.8314759731292725 (1.0487921539589211)\t\n",
      "  batch 6800 loss: 4.951675992012024\n",
      "Epoch: [2][6800/17600]\tTime 1.0763778686523438 (1.061164519997204)\tData 1.0655863285064697 (1.0490178628178204)\t\n",
      "  batch 6850 loss: 5.124812216758728\n",
      "Epoch: [2][6850/17600]\tTime 1.3281118869781494 (1.06108474989007)\tData 1.3161547183990479 (1.0489388064572411)\t\n",
      "  batch 6900 loss: 5.197321372032166\n",
      "Epoch: [2][6900/17600]\tTime 0.8634803295135498 (1.0607117605900418)\tData 0.8518919944763184 (1.0485670113563537)\t\n",
      "  batch 6950 loss: 5.276681942939758\n",
      "Epoch: [2][6950/17600]\tTime 0.8330302238464355 (1.0611747416489417)\tData 0.8189888000488281 (1.0490316246224822)\t\n",
      "  batch 7000 loss: 5.185895285606384\n",
      "Epoch: [2][7000/17600]\tTime 1.1873953342437744 (1.0616262850080218)\tData 1.175779104232788 (1.0494846739087786)\t\n",
      "  batch 7050 loss: 5.284669432640076\n",
      "Epoch: [2][7050/17600]\tTime 0.6844725608825684 (1.0615568820128205)\tData 0.6740479469299316 (1.0494178259288165)\t\n",
      "  batch 7100 loss: 4.9571222448349\n",
      "Epoch: [2][7100/17600]\tTime 0.6638977527618408 (1.0616597107094778)\tData 0.6535589694976807 (1.049524451913968)\t\n",
      "  batch 7150 loss: 5.05822389125824\n",
      "Epoch: [2][7150/17600]\tTime 1.0122954845428467 (1.061339726848202)\tData 1.0017998218536377 (1.0492033284527438)\t\n",
      "  batch 7200 loss: 4.756136584281921\n",
      "Epoch: [2][7200/17600]\tTime 1.586411714553833 (1.0614620991216765)\tData 1.575676441192627 (1.0493270792232618)\t\n",
      "  batch 7250 loss: 4.971661767959595\n",
      "Epoch: [2][7250/17600]\tTime 1.0336222648620605 (1.0617807589234978)\tData 1.0237882137298584 (1.0496492964645912)\t\n",
      "  batch 7300 loss: 5.247217688560486\n",
      "Epoch: [2][7300/17600]\tTime 1.1548163890838623 (1.061250198442642)\tData 1.1423211097717285 (1.0491171863634292)\t\n",
      "  batch 7350 loss: 4.869853439331055\n",
      "Epoch: [2][7350/17600]\tTime 0.9650046825408936 (1.061147709249639)\tData 0.953899621963501 (1.0490153213747504)\t\n",
      "  batch 7400 loss: 5.016205763816833\n",
      "Epoch: [2][7400/17600]\tTime 1.0163681507110596 (1.0613029856939573)\tData 1.0028579235076904 (1.0491710290071126)\t\n",
      "  batch 7450 loss: 4.922177305221558\n",
      "Epoch: [2][7450/17600]\tTime 1.0272698402404785 (1.0605060636597192)\tData 1.016885757446289 (1.0483743988267527)\t\n",
      "  batch 7500 loss: 5.411649339199066\n",
      "Epoch: [2][7500/17600]\tTime 1.2306034564971924 (1.060566652393341)\tData 1.2177114486694336 (1.048436742401123)\t\n",
      "  batch 7550 loss: 5.147966151237488\n",
      "Epoch: [2][7550/17600]\tTime 1.2609829902648926 (1.0611715166142446)\tData 1.2428832054138184 (1.0490418600246607)\t\n",
      "  batch 7600 loss: 4.886492323875427\n",
      "Epoch: [2][7600/17600]\tTime 0.9630250930786133 (1.0606393793068434)\tData 0.9500579833984375 (1.048508984101446)\t\n",
      "  batch 7650 loss: 5.229266881942749\n",
      "Epoch: [2][7650/17600]\tTime 1.0275647640228271 (1.0601400461695554)\tData 1.0171358585357666 (1.048006664382087)\t\n",
      "  batch 7700 loss: 4.87281756401062\n",
      "Epoch: [2][7700/17600]\tTime 0.8781771659851074 (1.0598106644679974)\tData 0.865079402923584 (1.0476779383498354)\t\n",
      "  batch 7750 loss: 5.17673773765564\n",
      "Epoch: [2][7750/17600]\tTime 0.9456181526184082 (1.0602951627854378)\tData 0.9326872825622559 (1.0481646879565332)\t\n",
      "  batch 7800 loss: 5.01644965171814\n",
      "Epoch: [2][7800/17600]\tTime 1.6160454750061035 (1.0602984453164614)\tData 1.6056146621704102 (1.0481705844707978)\t\n",
      "  batch 7850 loss: 5.341431479454041\n",
      "Epoch: [2][7850/17600]\tTime 1.0704915523529053 (1.0611674650155816)\tData 1.0603489875793457 (1.049042000011274)\t\n",
      "  batch 7900 loss: 5.062968015670776\n",
      "Epoch: [2][7900/17600]\tTime 1.167855978012085 (1.0612863065924825)\tData 1.153742790222168 (1.0491623644889156)\t\n",
      "  batch 7950 loss: 5.08931875705719\n",
      "Epoch: [2][7950/17600]\tTime 1.2338554859161377 (1.060963680159371)\tData 1.2206130027770996 (1.0488377395365973)\t\n",
      "  batch 8000 loss: 4.784961566925049\n",
      "Epoch: [2][8000/17600]\tTime 0.9287991523742676 (1.0614684525430202)\tData 0.9141087532043457 (1.0493422401547432)\t\n",
      "  batch 8050 loss: 4.949333791732788\n",
      "Epoch: [2][8050/17600]\tTime 1.173978328704834 (1.0614528231295)\tData 1.1630160808563232 (1.0493279383641592)\t\n",
      "  batch 8100 loss: 4.95046145439148\n",
      "Epoch: [2][8100/17600]\tTime 1.225620985031128 (1.0622548287297473)\tData 1.2127408981323242 (1.050131773919235)\t\n",
      "  batch 8150 loss: 4.839573860168457\n",
      "Epoch: [2][8150/17600]\tTime 1.4656713008880615 (1.0621440101986281)\tData 1.4530994892120361 (1.0500201258045032)\t\n",
      "  batch 8200 loss: 5.024463167190552\n",
      "Epoch: [2][8200/17600]\tTime 1.0148029327392578 (1.0619385877469691)\tData 1.0047168731689453 (1.0498141994127412)\t\n",
      "  batch 8250 loss: 5.041234240531922\n",
      "Epoch: [2][8250/17600]\tTime 0.8345980644226074 (1.0615619354537038)\tData 0.8244962692260742 (1.0494386694937041)\t\n",
      "  batch 8300 loss: 4.786199350357055\n",
      "Epoch: [2][8300/17600]\tTime 0.9756884574890137 (1.0616180264518922)\tData 0.9632425308227539 (1.0494941150711243)\t\n",
      "  batch 8350 loss: 5.14188591003418\n",
      "Epoch: [2][8350/17600]\tTime 0.6558988094329834 (1.0616354392388623)\tData 0.6451573371887207 (1.04951061876948)\t\n",
      "  batch 8400 loss: 5.033114104270935\n",
      "Epoch: [2][8400/17600]\tTime 1.107297420501709 (1.0618223864407765)\tData 1.0930397510528564 (1.0496966158776055)\t\n",
      "  batch 8450 loss: 4.9342263889312745\n",
      "Epoch: [2][8450/17600]\tTime 0.9351437091827393 (1.0616553539072973)\tData 0.9246993064880371 (1.049530706828868)\t\n",
      "  batch 8500 loss: 5.01375645160675\n",
      "Epoch: [2][8500/17600]\tTime 1.0989203453063965 (1.061711113649256)\tData 1.0859761238098145 (1.0495880312919617)\t\n",
      "  batch 8550 loss: 5.362593626976013\n",
      "Epoch: [2][8550/17600]\tTime 1.1098268032073975 (1.061820489007827)\tData 1.099449872970581 (1.0496951367004572)\t\n",
      "  batch 8600 loss: 4.839730768203736\n",
      "Epoch: [2][8600/17600]\tTime 0.8684351444244385 (1.0616778930675153)\tData 0.8547513484954834 (1.0495504156101583)\t\n",
      "  batch 8650 loss: 4.955072450637817\n",
      "Epoch: [2][8650/17600]\tTime 0.8209617137908936 (1.0614685068792002)\tData 0.8077688217163086 (1.0493393826071238)\t\n",
      "  batch 8700 loss: 4.827979874610901\n",
      "Epoch: [2][8700/17600]\tTime 0.7101278305053711 (1.0612856542927096)\tData 0.6998875141143799 (1.049155188456349)\t\n",
      "  batch 8750 loss: 4.869631681442261\n",
      "Epoch: [2][8750/17600]\tTime 1.201613187789917 (1.0612556645257132)\tData 1.1900444030761719 (1.0491232120241438)\t\n",
      "  batch 8800 loss: 4.914516143798828\n",
      "Epoch: [2][8800/17600]\tTime 0.880601167678833 (1.0611086196249182)\tData 0.8677105903625488 (1.0489740044149485)\t\n",
      "  batch 8850 loss: 4.851972393989563\n",
      "Epoch: [2][8850/17600]\tTime 0.9531245231628418 (1.0607259283227435)\tData 0.9419512748718262 (1.048589851600302)\t\n",
      "  batch 8900 loss: 5.086927168369293\n",
      "Epoch: [2][8900/17600]\tTime 1.1006250381469727 (1.0607368949825844)\tData 1.0861485004425049 (1.0486016797483637)\t\n",
      "  batch 8950 loss: 5.064983139038086\n",
      "Epoch: [2][8950/17600]\tTime 0.885143518447876 (1.0605746151215538)\tData 0.8720746040344238 (1.0484401163175785)\t\n",
      "  batch 9000 loss: 4.706564888954163\n",
      "Epoch: [2][9000/17600]\tTime 1.230088472366333 (1.0603902271058825)\tData 1.2159335613250732 (1.0482549135420058)\t\n",
      "  batch 9050 loss: 5.121831889152527\n",
      "Epoch: [2][9050/17600]\tTime 0.9231228828430176 (1.0606315186273987)\tData 0.9101195335388184 (1.0484972990678818)\t\n",
      "  batch 9100 loss: 4.945647315979004\n",
      "Epoch: [2][9100/17600]\tTime 0.7600162029266357 (1.0606432483484456)\tData 0.7474260330200195 (1.0485069868328807)\t\n",
      "  batch 9150 loss: 5.153839492797852\n",
      "Epoch: [2][9150/17600]\tTime 1.0416419506072998 (1.0606369905263349)\tData 1.026750087738037 (1.0484997824892972)\t\n",
      "  batch 9200 loss: 5.140443229675293\n",
      "Epoch: [2][9200/17600]\tTime 0.8818056583404541 (1.0608529376983642)\tData 0.866985559463501 (1.048715962327045)\t\n",
      "  batch 9250 loss: 4.817534873485565\n",
      "Epoch: [2][9250/17600]\tTime 0.8846986293792725 (1.0607362656206698)\tData 0.8747189044952393 (1.0485983966363444)\t\n",
      "  batch 9300 loss: 4.881501874923706\n",
      "Epoch: [2][9300/17600]\tTime 0.925447940826416 (1.0608641489603186)\tData 0.9101753234863281 (1.0487260058618362)\t\n",
      "  batch 9350 loss: 5.037119376659393\n",
      "Epoch: [2][9350/17600]\tTime 0.9100613594055176 (1.0604327762828154)\tData 0.8965520858764648 (1.048296010430484)\t\n",
      "  batch 9400 loss: 5.000519380569458\n",
      "Epoch: [2][9400/17600]\tTime 1.0564725399017334 (1.0605162668481787)\tData 1.0461010932922363 (1.0483778282175673)\t\n",
      "  batch 9450 loss: 4.785989327430725\n",
      "Epoch: [2][9450/17600]\tTime 1.0552971363067627 (1.0608932039977381)\tData 1.0451011657714844 (1.0487568376682423)\t\n",
      "  batch 9500 loss: 5.344531936645508\n",
      "Epoch: [2][9500/17600]\tTime 1.0227530002593994 (1.060715867494282)\tData 1.0122644901275635 (1.048580988080878)\t\n",
      "  batch 9550 loss: 5.082603764533997\n",
      "Epoch: [2][9550/17600]\tTime 1.166553258895874 (1.0605703732355727)\tData 1.1551828384399414 (1.0484354364684738)\t\n",
      "  batch 9600 loss: 5.018055243492126\n",
      "Epoch: [2][9600/17600]\tTime 1.225506067276001 (1.0607153347631295)\tData 1.2155554294586182 (1.0485813409090041)\t\n",
      "  batch 9650 loss: 5.31149715423584\n",
      "Epoch: [2][9650/17600]\tTime 1.0505144596099854 (1.0610318094955207)\tData 1.0361390113830566 (1.0488963733435912)\t\n",
      "  batch 9700 loss: 4.841045215129852\n",
      "Epoch: [2][9700/17600]\tTime 0.9612929821014404 (1.0609688441532175)\tData 0.951045036315918 (1.0488341537701715)\t\n",
      "  batch 9750 loss: 5.083387770652771\n",
      "Epoch: [2][9750/17600]\tTime 1.2489769458770752 (1.060982148781801)\tData 1.2386648654937744 (1.048845544081468)\t\n",
      "  batch 9800 loss: 4.8943807935714725\n",
      "Epoch: [2][9800/17600]\tTime 1.36326003074646 (1.0612226686672288)\tData 1.3506450653076172 (1.0490875853810993)\t\n",
      "  batch 9850 loss: 4.968770823478699\n",
      "Epoch: [2][9850/17600]\tTime 1.080070972442627 (1.0612634214410928)\tData 1.068237066268921 (1.0491296730428783)\t\n",
      "  batch 9900 loss: 4.910641071796417\n",
      "Epoch: [2][9900/17600]\tTime 0.8622944355010986 (1.0611789506131952)\tData 0.8490474224090576 (1.049041596253713)\t\n",
      "  batch 9950 loss: 5.230982227325439\n",
      "Epoch: [2][9950/17600]\tTime 0.7285850048065186 (1.0612146424767959)\tData 0.7183144092559814 (1.0490793765609587)\t\n",
      "  batch 10000 loss: 4.870315074920654\n",
      "Epoch: [2][10000/17600]\tTime 0.7782566547393799 (1.061321700334549)\tData 0.7660531997680664 (1.0491836568832398)\t\n",
      "  batch 10050 loss: 5.0406721544265745\n",
      "Epoch: [2][10050/17600]\tTime 1.4615082740783691 (1.0614503214964226)\tData 1.4485597610473633 (1.0493128916517418)\t\n",
      "  batch 10100 loss: 5.126703944206238\n",
      "Epoch: [2][10100/17600]\tTime 1.0419268608093262 (1.0616867147341813)\tData 1.0284554958343506 (1.0495499390658767)\t\n",
      "  batch 10150 loss: 5.111655187606812\n",
      "Epoch: [2][10150/17600]\tTime 0.958202600479126 (1.0616156410583721)\tData 0.945563793182373 (1.0494803341738697)\t\n",
      "  batch 10200 loss: 4.996694719791412\n",
      "Epoch: [2][10200/17600]\tTime 1.238286018371582 (1.0620123825119991)\tData 1.225503921508789 (1.0498777032365987)\t\n",
      "  batch 10250 loss: 5.128215522766113\n",
      "Epoch: [2][10250/17600]\tTime 1.042680263519287 (1.0617851859069452)\tData 1.032991886138916 (1.0496532448559273)\t\n",
      "  batch 10300 loss: 4.807033491134644\n",
      "Epoch: [2][10300/17600]\tTime 1.0773577690124512 (1.061608661980305)\tData 1.067331314086914 (1.0494747209317477)\t\n",
      "  batch 10350 loss: 4.858400559425354\n",
      "Epoch: [2][10350/17600]\tTime 0.7066960334777832 (1.0615981911230779)\tData 0.6941747665405273 (1.049464921122012)\t\n",
      "  batch 10400 loss: 5.112241630554199\n",
      "Epoch: [2][10400/17600]\tTime 0.9510312080383301 (1.0616644210540331)\tData 0.9412107467651367 (1.0495304820400018)\t\n",
      "  batch 10450 loss: 4.991552495956421\n",
      "Epoch: [2][10450/17600]\tTime 1.2479307651519775 (1.0613813795199234)\tData 1.2345795631408691 (1.0492444125773233)\t\n",
      "  batch 10500 loss: 4.754502129554749\n",
      "Epoch: [2][10500/17600]\tTime 1.1424858570098877 (1.0612931563740684)\tData 1.1326520442962646 (1.0491555562473478)\t\n",
      "  batch 10550 loss: 5.082321810722351\n",
      "Epoch: [2][10550/17600]\tTime 0.8555426597595215 (1.0612965130918963)\tData 0.8416838645935059 (1.0491584552520825)\t\n",
      "  batch 10600 loss: 5.24156813621521\n",
      "Epoch: [2][10600/17600]\tTime 1.5406646728515625 (1.0615114512758435)\tData 1.52651047706604 (1.0493738250687437)\t\n",
      "  batch 10650 loss: 4.937702975273132\n",
      "Epoch: [2][10650/17600]\tTime 0.7357730865478516 (1.061169588084512)\tData 0.72306227684021 (1.0490312862172373)\t\n",
      "  batch 10700 loss: 4.725239963531494\n",
      "Epoch: [2][10700/17600]\tTime 0.8200669288635254 (1.0609213689108876)\tData 0.806929349899292 (1.0487832306701446)\t\n",
      "  batch 10750 loss: 4.962569432258606\n",
      "Epoch: [2][10750/17600]\tTime 1.1079301834106445 (1.0611069610728774)\tData 1.08567476272583 (1.0489664215487102)\t\n",
      "  batch 10800 loss: 5.073637542724609\n",
      "Epoch: [2][10800/17600]\tTime 1.2311835289001465 (1.0611394714426112)\tData 1.2168259620666504 (1.0489986948834524)\t\n",
      "  batch 10850 loss: 5.04110848903656\n",
      "Epoch: [2][10850/17600]\tTime 0.6701257228851318 (1.0609960710507933)\tData 0.6584446430206299 (1.0488543692162509)\t\n",
      "  batch 10900 loss: 4.762632169723511\n",
      "Epoch: [2][10900/17600]\tTime 1.5019991397857666 (1.0609587941475964)\tData 1.491633653640747 (1.0488148970560196)\t\n",
      "  batch 10950 loss: 5.157005581855774\n",
      "Epoch: [2][10950/17600]\tTime 1.1270637512207031 (1.061123872216978)\tData 1.1122677326202393 (1.0489806217472304)\t\n",
      "  batch 11000 loss: 5.047126250267029\n",
      "Epoch: [2][11000/17600]\tTime 0.7466464042663574 (1.0611347139965404)\tData 0.7337408065795898 (1.048992816513235)\t\n",
      "  batch 11050 loss: 4.47686851978302\n",
      "Epoch: [2][11050/17600]\tTime 1.1261897087097168 (1.0609534776264726)\tData 1.1122519969940186 (1.04881250739637)\t\n",
      "  batch 11100 loss: 4.970320224761963\n",
      "Epoch: [2][11100/17600]\tTime 1.1593105792999268 (1.0604223440144513)\tData 1.1492810249328613 (1.0482778266528705)\t\n",
      "  batch 11150 loss: 4.779386510848999\n",
      "Epoch: [2][11150/17600]\tTime 0.9753005504608154 (1.0604819565289758)\tData 0.9615888595581055 (1.0483384167025442)\t\n",
      "  batch 11200 loss: 4.859178838729858\n",
      "Epoch: [2][11200/17600]\tTime 1.2684168815612793 (1.0599529233574867)\tData 1.2580549716949463 (1.047809709906578)\t\n",
      "  batch 11250 loss: 4.889063224792481\n",
      "Epoch: [2][11250/17600]\tTime 0.8372800350189209 (1.0601881824069552)\tData 0.8273248672485352 (1.0480445032755534)\t\n",
      "  batch 11300 loss: 4.622781157493591\n",
      "Epoch: [2][11300/17600]\tTime 1.2588133811950684 (1.0603566408157348)\tData 1.2465109825134277 (1.048212965294323)\t\n",
      "  batch 11350 loss: 4.907444734573364\n",
      "Epoch: [2][11350/17600]\tTime 1.0901315212249756 (1.0602879177631261)\tData 1.0781476497650146 (1.0481462259754735)\t\n",
      "  batch 11400 loss: 4.7550527024269105\n",
      "Epoch: [2][11400/17600]\tTime 0.6840927600860596 (1.0603371003636142)\tData 0.6701552867889404 (1.048195469860445)\t\n",
      "  batch 11450 loss: 4.726535892486572\n",
      "Epoch: [2][11450/17600]\tTime 1.1001040935516357 (1.0601782979507113)\tData 1.0895648002624512 (1.048038197646495)\t\n",
      "  batch 11500 loss: 4.931381282806396\n",
      "Epoch: [2][11500/17600]\tTime 0.9428181648254395 (1.0601193966036258)\tData 0.930408239364624 (1.0479798320480016)\t\n",
      "  batch 11550 loss: 4.668934049606324\n",
      "Epoch: [2][11550/17600]\tTime 1.2570295333862305 (1.0602412717579763)\tData 1.2437944412231445 (1.0481031910991256)\t\n",
      "  batch 11600 loss: 5.1153283786773684\n",
      "Epoch: [2][11600/17600]\tTime 1.2388572692871094 (1.0601462405303428)\tData 1.225992202758789 (1.0480091550226869)\t\n",
      "  batch 11650 loss: 4.91070996761322\n",
      "Epoch: [2][11650/17600]\tTime 0.890399694442749 (1.0601694421399817)\tData 0.8801884651184082 (1.04803195836718)\t\n",
      "  batch 11700 loss: 4.862020258903503\n",
      "Epoch: [2][11700/17600]\tTime 0.9163198471069336 (1.0599354185813512)\tData 0.9062981605529785 (1.0477971978065295)\t\n",
      "  batch 11750 loss: 4.753403673171997\n",
      "Epoch: [2][11750/17600]\tTime 0.7250857353210449 (1.0598544798911886)\tData 0.7150328159332275 (1.0477154373209527)\t\n",
      "  batch 11800 loss: 4.975370016098022\n",
      "Epoch: [2][11800/17600]\tTime 1.0448698997497559 (1.0595610693551727)\tData 1.0331189632415771 (1.0474223713551538)\t\n",
      "  batch 11850 loss: 4.993915657997132\n",
      "Epoch: [2][11850/17600]\tTime 0.8614678382873535 (1.059453664087545)\tData 0.8462629318237305 (1.0473149667208708)\t\n",
      "  batch 11900 loss: 4.636802816390992\n",
      "Epoch: [2][11900/17600]\tTime 1.4765679836273193 (1.0595802593631904)\tData 1.464005947113037 (1.0474417669632856)\t\n",
      "  batch 11950 loss: 4.934414701461792\n",
      "Epoch: [2][11950/17600]\tTime 1.1706461906433105 (1.0593397339417845)\tData 1.15671706199646 (1.0471999373894856)\t\n",
      "  batch 12000 loss: 5.36758584022522\n",
      "Epoch: [2][12000/17600]\tTime 1.2482123374938965 (1.0595876532594364)\tData 1.2381365299224854 (1.0474473719994226)\t\n",
      "  batch 12050 loss: 5.230964398384094\n",
      "Epoch: [2][12050/17600]\tTime 1.0347626209259033 (1.0593548260882681)\tData 1.0219366550445557 (1.047213357929372)\t\n",
      "  batch 12100 loss: 5.202679538726807\n",
      "Epoch: [2][12100/17600]\tTime 0.7252428531646729 (1.058984477421469)\tData 0.7156119346618652 (1.0468460035915217)\t\n",
      "  batch 12150 loss: 5.015813417434693\n",
      "Epoch: [2][12150/17600]\tTime 1.0048322677612305 (1.058913218886764)\tData 0.9909625053405762 (1.0467739152515867)\t\n",
      "  batch 12200 loss: 4.525938348770142\n",
      "Epoch: [2][12200/17600]\tTime 1.0475101470947266 (1.0587671798760774)\tData 1.0371184349060059 (1.0466283491791273)\t\n",
      "  batch 12250 loss: 4.799219827651978\n",
      "Epoch: [2][12250/17600]\tTime 1.0502440929412842 (1.0588612114458669)\tData 1.0392811298370361 (1.04672383942896)\t\n",
      "  batch 12300 loss: 4.866024353504181\n",
      "Epoch: [2][12300/17600]\tTime 1.1294217109680176 (1.0589556184435278)\tData 1.1186792850494385 (1.0468181279035118)\t\n",
      "  batch 12350 loss: 4.822813773155213\n",
      "Epoch: [2][12350/17600]\tTime 0.9573304653167725 (1.0588834011796033)\tData 0.9431073665618896 (1.0467463834469135)\t\n",
      "  batch 12400 loss: 5.337640252113342\n",
      "Epoch: [2][12400/17600]\tTime 1.1229264736175537 (1.0590989150347248)\tData 1.1130428314208984 (1.0469603686755704)\t\n",
      "  batch 12450 loss: 4.795603733062745\n",
      "Epoch: [2][12450/17600]\tTime 1.2667996883392334 (1.0590807848283086)\tData 1.2562363147735596 (1.0469432792318873)\t\n",
      "  batch 12500 loss: 5.144773726463318\n",
      "Epoch: [2][12500/17600]\tTime 1.1296391487121582 (1.0590777326011658)\tData 1.1189658641815186 (1.0469396307945251)\t\n",
      "  batch 12550 loss: 5.095991015434265\n",
      "Epoch: [2][12550/17600]\tTime 1.1530237197875977 (1.059092851653992)\tData 1.1428651809692383 (1.0469545112663057)\t\n",
      "  batch 12600 loss: 5.2484211921691895\n",
      "Epoch: [2][12600/17600]\tTime 0.6532063484191895 (1.059002867426191)\tData 0.640338659286499 (1.046864007635722)\t\n",
      "  batch 12650 loss: 5.231645638942719\n",
      "Epoch: [2][12650/17600]\tTime 1.2325613498687744 (1.058933698518474)\tData 1.219956874847412 (1.046795145701985)\t\n",
      "  batch 12700 loss: 5.221776556968689\n",
      "Epoch: [2][12700/17600]\tTime 0.9852898120880127 (1.0589360597377686)\tData 0.9670050144195557 (1.0467964950321227)\t\n",
      "  batch 12750 loss: 5.038978371620178\n",
      "Epoch: [2][12750/17600]\tTime 1.5336759090423584 (1.059170903598561)\tData 1.5224802494049072 (1.0470300891352635)\t\n",
      "  batch 12800 loss: 4.851261258125305\n",
      "Epoch: [2][12800/17600]\tTime 0.912877082824707 (1.0592842260934412)\tData 0.8982632160186768 (1.0471433424018324)\t\n",
      "  batch 12850 loss: 4.94301873922348\n",
      "Epoch: [2][12850/17600]\tTime 1.8859784603118896 (1.058979881487004)\tData 1.871044635772705 (1.0468382497705837)\t\n",
      "  batch 12900 loss: 4.78832633972168\n",
      "Epoch: [2][12900/17600]\tTime 1.295149326324463 (1.0594820088933605)\tData 1.284466028213501 (1.0473403965779977)\t\n",
      "  batch 12950 loss: 4.928063554763794\n",
      "Epoch: [2][12950/17600]\tTime 2.3203749656677246 (1.0600110066903603)\tData 2.3080215454101562 (1.0478691104204039)\t\n",
      "  batch 13000 loss: 4.846486797332764\n",
      "Epoch: [2][13000/17600]\tTime 0.7834315299987793 (1.060148921269637)\tData 0.7706336975097656 (1.0480076906497662)\t\n",
      "  batch 13050 loss: 4.942964568138122\n",
      "Epoch: [2][13050/17600]\tTime 1.1780972480773926 (1.0602327419697553)\tData 1.1638903617858887 (1.048091318908779)\t\n",
      "  batch 13100 loss: 4.882244734764099\n",
      "Epoch: [2][13100/17600]\tTime 1.2559969425201416 (1.060160011298784)\tData 1.2463171482086182 (1.0480181755910394)\t\n",
      "  batch 13150 loss: 4.94014319896698\n",
      "Epoch: [2][13150/17600]\tTime 0.8510122299194336 (1.060084494239024)\tData 0.8384184837341309 (1.0479425535093243)\t\n",
      "  batch 13200 loss: 4.756141090393067\n",
      "Epoch: [2][13200/17600]\tTime 1.418802261352539 (1.0599949946548)\tData 1.404114007949829 (1.0478518058314468)\t\n",
      "  batch 13250 loss: 4.637436513900757\n",
      "Epoch: [2][13250/17600]\tTime 0.8803131580352783 (1.0599347421538154)\tData 0.8681097030639648 (1.0477926996159104)\t\n",
      "  batch 13300 loss: 4.7121772909164426\n",
      "Epoch: [2][13300/17600]\tTime 1.1552352905273438 (1.0599234192532705)\tData 1.1451218128204346 (1.047780608073213)\t\n",
      "  batch 13350 loss: 4.971478934288025\n",
      "Epoch: [2][13350/17600]\tTime 1.1593506336212158 (1.0600351875819516)\tData 1.1491780281066895 (1.0478914477316181)\t\n",
      "  batch 13400 loss: 4.769322094917297\n",
      "Epoch: [2][13400/17600]\tTime 0.9040093421936035 (1.0599511433359403)\tData 0.8915822505950928 (1.0478077155618526)\t\n",
      "  batch 13450 loss: 5.133982520103455\n",
      "Epoch: [2][13450/17600]\tTime 1.7980329990386963 (1.0600290849394958)\tData 1.7850403785705566 (1.0478867058062642)\t\n",
      "  batch 13500 loss: 5.01942994594574\n",
      "Epoch: [2][13500/17600]\tTime 1.1115691661834717 (1.0602509439962882)\tData 1.098356008529663 (1.048109617356901)\t\n",
      "  batch 13550 loss: 4.837115650177002\n",
      "Epoch: [2][13550/17600]\tTime 1.532628059387207 (1.0602984085646063)\tData 1.519763708114624 (1.04815489865757)\t\n",
      "  batch 13600 loss: 5.06941071510315\n",
      "Epoch: [2][13600/17600]\tTime 1.1798102855682373 (1.060316695009961)\tData 1.1695332527160645 (1.0481709823012353)\t\n",
      "  batch 13650 loss: 4.644620141983032\n",
      "Epoch: [2][13650/17600]\tTime 0.8520016670227051 (1.0603318415805971)\tData 0.8380272388458252 (1.0481860572165185)\t\n",
      "  batch 13700 loss: 4.878834133148193\n",
      "Epoch: [2][13700/17600]\tTime 1.528879165649414 (1.060208207394955)\tData 1.5186455249786377 (1.048063670335895)\t\n",
      "  batch 13750 loss: 5.124880666732788\n",
      "Epoch: [2][13750/17600]\tTime 1.2467539310455322 (1.0602307828036222)\tData 1.2341907024383545 (1.0480877524462613)\t\n",
      "  batch 13800 loss: 4.777270917892456\n",
      "Epoch: [2][13800/17600]\tTime 1.0593531131744385 (1.0602971867029218)\tData 1.0475280284881592 (1.048154631593953)\t\n",
      "  batch 13850 loss: 5.063710932731628\n",
      "Epoch: [2][13850/17600]\tTime 0.9115853309631348 (1.0601968330768903)\tData 0.8992702960968018 (1.048055090250091)\t\n",
      "  batch 13900 loss: 4.797830443382264\n",
      "Epoch: [2][13900/17600]\tTime 0.6938591003417969 (1.0603130224454318)\tData 0.6807997226715088 (1.0481728267155106)\t\n",
      "  batch 13950 loss: 4.87036102771759\n",
      "Epoch: [2][13950/17600]\tTime 0.678015947341919 (1.0602786366144816)\tData 0.6635866165161133 (1.0481381618164773)\t\n",
      "  batch 14000 loss: 4.585494480133057\n",
      "Epoch: [2][14000/17600]\tTime 1.0789556503295898 (1.0603862679515565)\tData 1.0670108795166016 (1.0482454802479062)\t\n",
      "  batch 14050 loss: 4.69065417766571\n",
      "Epoch: [2][14050/17600]\tTime 1.7813084125518799 (1.06038847991156)\tData 1.770991325378418 (1.0482491765582265)\t\n",
      "  batch 14100 loss: 4.623138136863709\n",
      "Epoch: [2][14100/17600]\tTime 1.0276274681091309 (1.0601981772091371)\tData 1.0143885612487793 (1.04805839082028)\t\n",
      "  batch 14150 loss: 4.90696834564209\n",
      "Epoch: [2][14150/17600]\tTime 1.386486291885376 (1.0601306312581253)\tData 1.373237133026123 (1.0479897089644792)\t\n",
      "  batch 14200 loss: 5.018245501518249\n",
      "Epoch: [2][14200/17600]\tTime 1.093956708908081 (1.0601990327700763)\tData 1.083547830581665 (1.048058338064543)\t\n",
      "  batch 14250 loss: 4.8811780548095705\n",
      "Epoch: [2][14250/17600]\tTime 0.8289227485656738 (1.0603774751027426)\tData 0.8140363693237305 (1.0482367680198268)\t\n",
      "  batch 14300 loss: 4.783637866973877\n",
      "Epoch: [2][14300/17600]\tTime 0.8302435874938965 (1.0602887820530604)\tData 0.8172576427459717 (1.0481486375181825)\t\n",
      "  batch 14350 loss: 4.633193874359131\n",
      "Epoch: [2][14350/17600]\tTime 0.9067220687866211 (1.0601637138805322)\tData 0.8950350284576416 (1.048023214589428)\t\n",
      "  batch 14400 loss: 4.80967794418335\n",
      "Epoch: [2][14400/17600]\tTime 1.1862432956695557 (1.0601393504275216)\tData 1.1740672588348389 (1.0479982491168711)\t\n",
      "  batch 14450 loss: 4.99238874912262\n",
      "Epoch: [2][14450/17600]\tTime 1.4571466445922852 (1.060211651646967)\tData 1.4440178871154785 (1.04807084979483)\t\n",
      "  batch 14500 loss: 4.808679480552673\n",
      "Epoch: [2][14500/17600]\tTime 1.3825795650482178 (1.0602091109012735)\tData 1.370112657546997 (1.0480701083643682)\t\n",
      "  batch 14550 loss: 5.037205357551574\n",
      "Epoch: [2][14550/17600]\tTime 1.0018532276153564 (1.0602930520080618)\tData 0.9889583587646484 (1.0481539870783225)\t\n",
      "  batch 14600 loss: 5.016807112693787\n",
      "Epoch: [2][14600/17600]\tTime 2.035149335861206 (1.0602700417825621)\tData 2.02530837059021 (1.0481309437588469)\t\n",
      "  batch 14650 loss: 5.179639911651611\n",
      "Epoch: [2][14650/17600]\tTime 1.4261870384216309 (1.06182517245361)\tData 1.412400245666504 (1.0496876058969073)\t\n",
      "  batch 14700 loss: 4.9577934098243714\n",
      "Epoch: [2][14700/17600]\tTime 0.7963929176330566 (1.0617236889138513)\tData 0.7864413261413574 (1.049587483033031)\t\n",
      "  batch 14750 loss: 4.764908180236817\n",
      "Epoch: [2][14750/17600]\tTime 1.1122164726257324 (1.0615966375156984)\tData 1.0996334552764893 (1.0494608333070399)\t\n",
      "  batch 14800 loss: 4.7833233833312985\n",
      "Epoch: [2][14800/17600]\tTime 1.0181694030761719 (1.061534055423092)\tData 1.0038588047027588 (1.0493985885381698)\t\n",
      "  batch 14850 loss: 4.946570019721985\n",
      "Epoch: [2][14850/17600]\tTime 0.7825143337249756 (1.0617059363098658)\tData 0.7696967124938965 (1.049570623262964)\t\n",
      "  batch 14900 loss: 4.780805010795593\n",
      "Epoch: [2][14900/17600]\tTime 1.4370439052581787 (1.0619051855522514)\tData 1.4272427558898926 (1.0497694066226881)\t\n",
      "  batch 14950 loss: 4.737562699317932\n",
      "Epoch: [2][14950/17600]\tTime 1.3099770545959473 (1.0618392693637606)\tData 1.299048662185669 (1.0497042619902952)\t\n",
      "  batch 15000 loss: 4.832609901428222\n",
      "Epoch: [2][15000/17600]\tTime 1.090484619140625 (1.0619864333629607)\tData 1.077923059463501 (1.0498527237256368)\t\n",
      "  batch 15050 loss: 4.758327531814575\n",
      "Epoch: [2][15050/17600]\tTime 1.2161247730255127 (1.0617968599978476)\tData 1.203592300415039 (1.0496620690703788)\t\n",
      "  batch 15100 loss: 4.844748826026916\n",
      "Epoch: [2][15100/17600]\tTime 1.349156141281128 (1.0616261162663139)\tData 1.3338868618011475 (1.0494924386921307)\t\n",
      "  batch 15150 loss: 4.593458962440491\n",
      "Epoch: [2][15150/17600]\tTime 0.7229568958282471 (1.0616192337231274)\tData 0.7094554901123047 (1.0494847577633244)\t\n",
      "  batch 15200 loss: 4.695550603866577\n",
      "Epoch: [2][15200/17600]\tTime 0.9111120700836182 (1.0615935421774263)\tData 0.8994405269622803 (1.0494598274638778)\t\n",
      "  batch 15250 loss: 4.883189299106598\n",
      "Epoch: [2][15250/17600]\tTime 2.1090056896209717 (1.0616925527385024)\tData 2.095571756362915 (1.0495585618097274)\t\n",
      "  batch 15300 loss: 4.756485319137573\n",
      "Epoch: [2][15300/17600]\tTime 1.0241987705230713 (1.0616880178451538)\tData 1.013922929763794 (1.0495547098271987)\t\n",
      "  batch 15350 loss: 4.949040670394897\n",
      "Epoch: [2][15350/17600]\tTime 1.1545121669769287 (1.0615081226087937)\tData 1.1417384147644043 (1.0493740914931904)\t\n",
      "  batch 15400 loss: 4.997524881362915\n",
      "Epoch: [2][15400/17600]\tTime 0.8300526142120361 (1.0614407711524467)\tData 0.8172433376312256 (1.0493073716875794)\t\n",
      "  batch 15450 loss: 4.890947003364563\n",
      "Epoch: [2][15450/17600]\tTime 0.6859679222106934 (1.061363281802452)\tData 0.6738905906677246 (1.049232440534919)\t\n",
      "  batch 15500 loss: 4.929131889343262\n",
      "Epoch: [2][15500/17600]\tTime 1.3181052207946777 (1.061832802864813)\tData 1.3058128356933594 (1.0497032397639368)\t\n",
      "  batch 15550 loss: 4.799174809455872\n",
      "Epoch: [2][15550/17600]\tTime 0.914421796798706 (1.061856299029286)\tData 0.9033920764923096 (1.0497275354931208)\t\n",
      "  batch 15600 loss: 4.674681694507599\n",
      "Epoch: [2][15600/17600]\tTime 1.4090189933776855 (1.0617283216195228)\tData 1.3957359790802002 (1.0495996709358997)\t\n",
      "  batch 15650 loss: 4.711644387245178\n",
      "Epoch: [2][15650/17600]\tTime 0.7726879119873047 (1.061582472758552)\tData 0.7628388404846191 (1.0494559380040762)\t\n",
      "  batch 15700 loss: 4.7168294000625615\n",
      "Epoch: [2][15700/17600]\tTime 1.4674983024597168 (1.0616638091567216)\tData 1.4096155166625977 (1.0495348105157256)\t\n",
      "  batch 15750 loss: 4.734237251281738\n",
      "Epoch: [2][15750/17600]\tTime 1.009242296218872 (1.0615846598034813)\tData 0.9968209266662598 (1.0494573261624291)\t\n",
      "  batch 15800 loss: 4.69010158777237\n",
      "Epoch: [2][15800/17600]\tTime 0.7997956275939941 (1.0612347007401381)\tData 0.7869086265563965 (1.0491067680226096)\t\n",
      "  batch 15850 loss: 4.640966875553131\n",
      "Epoch: [2][15850/17600]\tTime 0.9592530727386475 (1.0610657416081954)\tData 0.9500529766082764 (1.0489381517897645)\t\n",
      "  batch 15900 loss: 5.235656011104584\n",
      "Epoch: [2][15900/17600]\tTime 0.9175748825073242 (1.0610630527682274)\tData 0.9039044380187988 (1.0489342981914305)\t\n",
      "  batch 15950 loss: 4.992218799591065\n",
      "Epoch: [2][15950/17600]\tTime 1.1121153831481934 (1.0609889982486593)\tData 1.0997562408447266 (1.0488624467520877)\t\n",
      "  batch 16000 loss: 4.875940265655518\n",
      "Epoch: [2][16000/17600]\tTime 0.8601377010345459 (1.0609998540133239)\tData 0.8476212024688721 (1.0488749129772186)\t\n",
      "  batch 16050 loss: 4.983052630424499\n",
      "Epoch: [2][16050/17600]\tTime 1.317600965499878 (1.0608097094687345)\tData 1.3040039539337158 (1.0486850603792897)\t\n",
      "  batch 16100 loss: 4.878662514686584\n",
      "Epoch: [2][16100/17600]\tTime 1.455430269241333 (1.061009781405052)\tData 1.4447453022003174 (1.0488856453480928)\t\n",
      "  batch 16150 loss: 4.676532468795776\n",
      "Epoch: [2][16150/17600]\tTime 1.0467703342437744 (1.0610190317579098)\tData 1.0331964492797852 (1.0488958959608994)\t\n",
      "  batch 16200 loss: 4.705085620880127\n",
      "Epoch: [2][16200/17600]\tTime 1.2774145603179932 (1.0608850473533442)\tData 1.2655537128448486 (1.048761967111517)\t\n",
      "  batch 16250 loss: 4.8612518930435185\n",
      "Epoch: [2][16250/17600]\tTime 1.0480051040649414 (1.0606781450271607)\tData 1.0381646156311035 (1.0485556742594793)\t\n",
      "  batch 16300 loss: 4.740391011238098\n",
      "Epoch: [2][16300/17600]\tTime 1.6033737659454346 (1.0631890943299043)\tData 1.5939013957977295 (1.0510687944932948)\t\n",
      "  batch 16350 loss: 4.631211762428284\n",
      "Epoch: [2][16350/17600]\tTime 1.171384572982788 (1.0687718520179073)\tData 1.1565611362457275 (1.0566545242198746)\t\n",
      "  batch 16400 loss: 4.50705771446228\n",
      "Epoch: [2][16400/17600]\tTime 1.0483546257019043 (1.0690577637567753)\tData 1.0359818935394287 (1.0569418382208522)\t\n",
      "  batch 16450 loss: 4.973697772026062\n",
      "Epoch: [2][16450/17600]\tTime 1.201754093170166 (1.069093002388905)\tData 1.189218282699585 (1.056979475992429)\t\n",
      "  batch 16500 loss: 4.530998146533966\n",
      "Epoch: [2][16500/17600]\tTime 1.1660065650939941 (1.068917068235802)\tData 1.1557798385620117 (1.0568046316522541)\t\n",
      "  batch 16550 loss: 4.876287002563476\n",
      "Epoch: [2][16550/17600]\tTime 0.9310176372528076 (1.0691294961969657)\tData 0.9185492992401123 (1.0570178629912639)\t\n",
      "  batch 16600 loss: 4.879222240447998\n",
      "Epoch: [2][16600/17600]\tTime 1.0523276329040527 (1.0692829834122255)\tData 1.0395822525024414 (1.057172982908157)\t\n",
      "  batch 16650 loss: 5.119036922454834\n",
      "Epoch: [2][16650/17600]\tTime 0.892474889755249 (1.0694265678766612)\tData 0.8812546730041504 (1.0573163487889745)\t\n",
      "  batch 16700 loss: 4.805544285774231\n",
      "Epoch: [2][16700/17600]\tTime 0.947486162185669 (1.069435566485285)\tData 0.935530424118042 (1.0573267976109852)\t\n",
      "  batch 16750 loss: 5.126910843849182\n",
      "Epoch: [2][16750/17600]\tTime 1.4810936450958252 (1.069355772431217)\tData 1.4710609912872314 (1.057247753798072)\t\n",
      "  batch 16800 loss: 4.592845003604889\n",
      "Epoch: [2][16800/17600]\tTime 0.983879566192627 (1.0692346824634642)\tData 0.9721715450286865 (1.0571286418040593)\t\n",
      "  batch 16850 loss: 4.7722002172470095\n",
      "Epoch: [2][16850/17600]\tTime 1.0093672275543213 (1.0692105185879444)\tData 0.9969625473022461 (1.0571052711017055)\t\n",
      "  batch 16900 loss: 4.791229305267334\n",
      "Epoch: [2][16900/17600]\tTime 1.2717909812927246 (1.0691970699355446)\tData 1.2590246200561523 (1.0570929436429717)\t\n",
      "  batch 16950 loss: 4.705803611278534\n",
      "Epoch: [2][16950/17600]\tTime 0.7604324817657471 (1.0690738420570847)\tData 0.7470207214355469 (1.0569717832722847)\t\n",
      "  batch 17000 loss: 4.820291380882264\n",
      "Epoch: [2][17000/17600]\tTime 1.101722002029419 (1.0691531865456525)\tData 1.0916972160339355 (1.057052169000401)\t\n",
      "  batch 17050 loss: 4.911188049316406\n",
      "Epoch: [2][17050/17600]\tTime 0.8599305152893066 (1.0692952155507556)\tData 0.8495876789093018 (1.0571941871307462)\t\n",
      "  batch 17100 loss: 4.4086255884170535\n",
      "Epoch: [2][17100/17600]\tTime 1.0903887748718262 (1.0695282356641447)\tData 1.0797710418701172 (1.0574286866606328)\t\n",
      "  batch 17150 loss: 4.619412941932678\n",
      "Epoch: [2][17150/17600]\tTime 1.2473831176757812 (1.0696901959928062)\tData 1.237955093383789 (1.0575924922147923)\t\n",
      "  batch 17200 loss: 4.822344269752502\n",
      "Epoch: [2][17200/17600]\tTime 1.1462020874023438 (1.0695313605458237)\tData 1.13385009765625 (1.0574347287693688)\t\n",
      "  batch 17250 loss: 4.505212054252625\n",
      "Epoch: [2][17250/17600]\tTime 0.9967575073242188 (1.069582417861275)\tData 0.9862253665924072 (1.057487674644028)\t\n",
      "  batch 17300 loss: 4.847181115150452\n",
      "Epoch: [2][17300/17600]\tTime 1.2034552097320557 (1.069654845791745)\tData 1.191145658493042 (1.0575605797078569)\t\n",
      "  batch 17350 loss: 5.042629714012146\n",
      "Epoch: [2][17350/17600]\tTime 0.6968274116516113 (1.0696394611435596)\tData 0.6840581893920898 (1.0575457037697609)\t\n",
      "  batch 17400 loss: 4.757774143218994\n",
      "Epoch: [2][17400/17600]\tTime 1.0596582889556885 (1.0695873558247226)\tData 1.0468268394470215 (1.0574953840244776)\t\n",
      "  batch 17450 loss: 4.58090678691864\n",
      "Epoch: [2][17450/17600]\tTime 0.9574079513549805 (1.0694020987786672)\tData 0.9445405006408691 (1.0573108731709784)\t\n",
      "  batch 17500 loss: 4.546195130348206\n",
      "Epoch: [2][17500/17600]\tTime 0.8804185390472412 (1.0695552262169974)\tData 0.8700554370880127 (1.0574652514321463)\t\n",
      "  batch 17550 loss: 4.731151027679443\n",
      "Epoch: [2][17550/17600]\tTime 1.0338258743286133 (1.069436065777075)\tData 1.0194487571716309 (1.0573479837026352)\t\n",
      "  batch 17600 loss: 4.864663603305817\n",
      "Epoch: [2][17600/17600]\tTime 0.9909727573394775 (1.0694249187138947)\tData 0.9773151874542236 (1.0573372146622702)\t\n",
      "Finished training epoch 2\n",
      "Epoch Loss: 8.024046886198732\n",
      "Starting training epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5df73a39c664b05811aff33a6512702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 50 loss: 4.8082512092590335\n",
      "Epoch: [3][50/17600]\tTime 0.9691228866577148 (1.1020145511627197)\tData 0.958892822265625 (1.0904083156585693)\t\n",
      "  batch 100 loss: 4.767690508365631\n",
      "Epoch: [3][100/17600]\tTime 0.7561020851135254 (1.0651993584632873)\tData 0.746279239654541 (1.0534481167793275)\t\n",
      "  batch 150 loss: 4.779217371940613\n",
      "Epoch: [3][150/17600]\tTime 1.2258760929107666 (1.0717190281550089)\tData 1.2141444683074951 (1.0599225362141926)\t\n",
      "  batch 200 loss: 4.639702723026276\n",
      "Epoch: [3][200/17600]\tTime 1.0775225162506104 (1.0539909017086029)\tData 1.0653488636016846 (1.0422128760814666)\t\n",
      "  batch 250 loss: 4.766773447990418\n",
      "Epoch: [3][250/17600]\tTime 2.874955892562866 (1.049760768890381)\tData 2.865328550338745 (1.0379829416275024)\t\n",
      "  batch 300 loss: 4.839803433418274\n",
      "Epoch: [3][300/17600]\tTime 0.8955326080322266 (1.4067522064844766)\tData 0.8829221725463867 (1.3952077571551005)\t\n",
      "  batch 350 loss: 4.975383443832397\n",
      "Epoch: [3][350/17600]\tTime 3.424175977706909 (1.6415507629939488)\tData 3.4107463359832764 (1.6300732278823853)\t\n",
      "  batch 400 loss: 4.699526085853576\n",
      "Epoch: [3][400/17600]\tTime 2.577014923095703 (1.7882997554540634)\tData 2.566559314727783 (1.7768675482273102)\t\n",
      "  batch 450 loss: 4.890458769798279\n",
      "Epoch: [3][450/17600]\tTime 0.9046030044555664 (1.943869186507331)\tData 0.8903076648712158 (1.932483154932658)\t\n",
      "  batch 500 loss: 4.9958627319335935\n",
      "Epoch: [3][500/17600]\tTime 7.049442291259766 (2.127562105178833)\tData 7.039384365081787 (2.1162310600280763)\t\n",
      "  batch 550 loss: 4.641302897930145\n",
      "Epoch: [3][550/17600]\tTime 1.0827200412750244 (2.246734054738825)\tData 1.068892240524292 (2.2354150390625)\t\n",
      "  batch 600 loss: 4.6265668869018555\n",
      "Epoch: [3][600/17600]\tTime 2.280574083328247 (2.3628676390647887)\tData 2.271132469177246 (2.3515728163719176)\t\n",
      "  batch 650 loss: 4.70138756275177\n",
      "Epoch: [3][650/17600]\tTime 2.6033754348754883 (2.401307222659771)\tData 2.593336343765259 (2.39005615234375)\t\n",
      "  batch 700 loss: 4.905199627876282\n",
      "Epoch: [3][700/17600]\tTime 1.1018164157867432 (2.4384970102991375)\tData 1.0918903350830078 (2.427275709765298)\t\n",
      "  batch 750 loss: 4.840523476600647\n",
      "Epoch: [3][750/17600]\tTime 0.9251749515533447 (2.45202516523997)\tData 0.9155235290527344 (2.440801523844401)\t\n",
      "  batch 800 loss: 4.878241438865661\n",
      "Epoch: [3][800/17600]\tTime 8.68710994720459 (2.501010759174824)\tData 8.67736291885376 (2.4898227474093435)\t\n",
      "  batch 850 loss: 5.043092041015625\n",
      "Epoch: [3][850/17600]\tTime 7.4496870040893555 (2.675645721098956)\tData 7.4400551319122314 (2.6644761520273543)\t\n",
      "  batch 900 loss: 4.626079564094543\n",
      "Epoch: [3][900/17600]\tTime 3.592663526535034 (2.930235424041748)\tData 3.580286741256714 (2.919112960497538)\t\n",
      "  batch 950 loss: 4.804073343276977\n",
      "Epoch: [3][950/17600]\tTime 5.547485589981079 (2.941002806362353)\tData 5.534847736358643 (2.929888922791732)\t\n",
      "  batch 1000 loss: 4.799382772445679\n",
      "Epoch: [3][1000/17600]\tTime 1.0658035278320312 (2.9334316027164458)\tData 1.0556206703186035 (2.922346884727478)\t\n",
      "  batch 1050 loss: 4.573495593070984\n",
      "Epoch: [3][1050/17600]\tTime 2.881246566772461 (2.9508168047950383)\tData 2.8640291690826416 (2.939760128429958)\t\n",
      "  batch 1100 loss: 4.591458120346069\n",
      "Epoch: [3][1100/17600]\tTime 2.6487629413604736 (2.9634236043149773)\tData 2.6349451541900635 (2.9523663915287366)\t\n",
      "  batch 1150 loss: 4.410928657054901\n",
      "Epoch: [3][1150/17600]\tTime 1.096522331237793 (2.9838687162813935)\tData 1.0862760543823242 (2.9728211527285366)\t\n",
      "  batch 1200 loss: 4.804369313716888\n",
      "Epoch: [3][1200/17600]\tTime 1.6106550693511963 (2.9881026564041773)\tData 1.6011466979980469 (2.977070445815722)\t\n",
      "  batch 1250 loss: 4.813796849250793\n",
      "Epoch: [3][1250/17600]\tTime 3.032970428466797 (2.9900132110595705)\tData 3.023669481277466 (2.978952850341797)\t\n",
      "  batch 1300 loss: 4.8036440253257755\n",
      "Epoch: [3][1300/17600]\tTime 3.7939987182617188 (2.995724179377923)\tData 3.78016996383667 (2.984670361188742)\t\n",
      "  batch 1350 loss: 4.819296641349792\n",
      "Epoch: [3][1350/17600]\tTime 0.8138618469238281 (2.997466391104239)\tData 0.8044023513793945 (2.9864220811702586)\t\n",
      "  batch 1400 loss: 4.779921469688415\n",
      "Epoch: [3][1400/17600]\tTime 6.427271842956543 (3.0077426210471563)\tData 6.416990280151367 (2.9967045596667696)\t\n",
      "  batch 1450 loss: 4.637276377677917\n",
      "Epoch: [3][1450/17600]\tTime 2.383448362350464 (3.0185720895898753)\tData 2.373006582260132 (3.0075316682355155)\t\n",
      "  batch 1500 loss: 4.67051332950592\n",
      "Epoch: [3][1500/17600]\tTime 4.2988121509552 (3.0369012090365093)\tData 4.28680682182312 (3.025862794717153)\t\n",
      "  batch 1550 loss: 4.508032937049865\n",
      "Epoch: [3][1550/17600]\tTime 0.6575074195861816 (3.017145989479557)\tData 0.6383192539215088 (3.006101020536115)\t\n",
      "  batch 1600 loss: 4.954399061203003\n",
      "Epoch: [3][1600/17600]\tTime 2.561033010482788 (3.0168069671094417)\tData 2.5514228343963623 (3.0057640638947487)\t\n",
      "  batch 1650 loss: 5.0019636154174805\n",
      "Epoch: [3][1650/17600]\tTime 1.5781207084655762 (3.009331347581112)\tData 1.564767599105835 (2.998284463448958)\t\n",
      "  batch 1700 loss: 4.944694199562073\n",
      "Epoch: [3][1700/17600]\tTime 0.6764261722564697 (3.0013509807867162)\tData 0.6670141220092773 (2.990313742581536)\t\n",
      "  batch 1750 loss: 4.774529280662537\n",
      "Epoch: [3][1750/17600]\tTime 0.9565048217773438 (3.0171760907854352)\tData 0.9467658996582031 (3.0061479928152903)\t\n",
      "  batch 1800 loss: 4.773026194572449\n",
      "Epoch: [3][1800/17600]\tTime 2.770524740219116 (3.017013236814075)\tData 2.760944128036499 (3.0059756819407144)\t\n",
      "  batch 1850 loss: 4.691203103065491\n",
      "Epoch: [3][1850/17600]\tTime 4.126672267913818 (3.0316199325870823)\tData 4.117433786392212 (3.0205979070147952)\t\n",
      "  batch 1900 loss: 4.838213548660279\n",
      "Epoch: [3][1900/17600]\tTime 9.416265487670898 (3.0798381939687225)\tData 9.406720161437988 (3.068838560581207)\t\n",
      "  batch 1950 loss: 4.743189058303833\n",
      "Epoch: [3][1950/17600]\tTime 2.9898273944854736 (3.104093782962897)\tData 2.9796242713928223 (3.0931068166097004)\t\n",
      "  batch 2000 loss: 4.8186116123199465\n",
      "Epoch: [3][2000/17600]\tTime 1.3899517059326172 (3.0597740689516066)\tData 1.379363775253296 (3.0487996903657915)\t\n",
      "  batch 2050 loss: 4.8141483879089355\n",
      "Epoch: [3][2050/17600]\tTime 1.1322104930877686 (3.0154831388520034)\tData 1.122406005859375 (3.004510474553922)\t\n",
      "  batch 2100 loss: 4.846611800193787\n",
      "Epoch: [3][2100/17600]\tTime 1.059873104095459 (2.973140347912198)\tData 1.0477116107940674 (2.9621713555426825)\t\n",
      "  batch 2150 loss: 4.81753246307373\n",
      "Epoch: [3][2150/17600]\tTime 0.9605131149291992 (2.9292261629326397)\tData 0.9406704902648926 (2.9182418507198955)\t\n",
      "  batch 2200 loss: 4.9128612661361695\n",
      "Epoch: [3][2200/17600]\tTime 1.5314412117004395 (2.8884404784982856)\tData 1.5212969779968262 (2.8774437417767267)\t\n",
      "  batch 2250 loss: 4.486561307907104\n",
      "Epoch: [3][2250/17600]\tTime 0.922173261642456 (2.84813362481859)\tData 0.9094676971435547 (2.8371214137607152)\t\n",
      "  batch 2300 loss: 4.865839562416077\n",
      "Epoch: [3][2300/17600]\tTime 1.2637274265289307 (2.809583226908808)\tData 1.2533278465270996 (2.798567860852117)\t\n",
      "  batch 2350 loss: 4.5167291498184206\n",
      "Epoch: [3][2350/17600]\tTime 0.9400084018707275 (2.7726900411159434)\tData 0.9274630546569824 (2.761656873987076)\t\n",
      "  batch 2400 loss: 5.040664434432983\n",
      "Epoch: [3][2400/17600]\tTime 1.0119438171386719 (2.7370307793219886)\tData 1.0010972023010254 (2.7259866698582966)\t\n",
      "  batch 2450 loss: 5.061092958450318\n",
      "Epoch: [3][2450/17600]\tTime 1.1997714042663574 (2.7029858727357827)\tData 1.1861672401428223 (2.6919269191975497)\t\n",
      "  batch 2500 loss: 4.946648726463318\n",
      "Epoch: [3][2500/17600]\tTime 0.791334867477417 (2.669531167507172)\tData 0.781059980392456 (2.6584702877044677)\t\n",
      "  batch 2550 loss: 4.738530583381653\n",
      "Epoch: [3][2550/17600]\tTime 1.8524632453918457 (2.6375736626456767)\tData 1.8423705101013184 (2.626491520919052)\t\n",
      "  batch 2600 loss: 4.84572817325592\n",
      "Epoch: [3][2600/17600]\tTime 1.1876139640808105 (2.6070391366114984)\tData 1.1778993606567383 (2.595948352538622)\t\n",
      "  batch 2650 loss: 5.033611583709717\n",
      "Epoch: [3][2650/17600]\tTime 1.0690858364105225 (2.577861050209909)\tData 1.0565767288208008 (2.5667639253724297)\t\n",
      "  batch 2700 loss: 4.743097248077393\n",
      "Epoch: [3][2700/17600]\tTime 1.1848125457763672 (2.5492297271445947)\tData 1.1724247932434082 (2.5381233412248116)\t\n",
      "  batch 2750 loss: 4.720639500617981\n",
      "Epoch: [3][2750/17600]\tTime 1.0940625667572021 (2.52107796348225)\tData 1.0841944217681885 (2.5099653111371127)\t\n",
      "  batch 2800 loss: 4.849320540428161\n",
      "Epoch: [3][2800/17600]\tTime 1.38389253616333 (2.49478746346065)\tData 1.3717713356018066 (2.4836619007587433)\t\n",
      "  batch 2850 loss: 4.704597597122192\n",
      "Epoch: [3][2850/17600]\tTime 0.8780379295349121 (2.4700084917168867)\tData 0.8680171966552734 (2.4588766690304404)\t\n",
      "  batch 2900 loss: 4.714593815803528\n",
      "Epoch: [3][2900/17600]\tTime 1.2833349704742432 (2.444570600575414)\tData 1.270716667175293 (2.433430216805688)\t\n",
      "  batch 2950 loss: 4.405540857315064\n",
      "Epoch: [3][2950/17600]\tTime 0.9364161491394043 (2.4195651535260474)\tData 0.9263498783111572 (2.408422110606048)\t\n",
      "  batch 3000 loss: 4.839477787017822\n",
      "Epoch: [3][3000/17600]\tTime 1.107877254486084 (2.395263650337855)\tData 1.0955283641815186 (2.384111281553904)\t\n",
      "  batch 3050 loss: 4.832579526901245\n",
      "Epoch: [3][3050/17600]\tTime 0.8423395156860352 (2.374239136117404)\tData 0.8299148082733154 (2.3630703150639767)\t\n",
      "  batch 3100 loss: 4.538513355255127\n",
      "Epoch: [3][3100/17600]\tTime 0.869091272354126 (2.3526046905979032)\tData 0.8589773178100586 (2.3414255402934168)\t\n",
      "  batch 3150 loss: 4.121588606834411\n",
      "Epoch: [3][3150/17600]\tTime 1.0842528343200684 (2.331721617910597)\tData 1.074326992034912 (2.320533629977514)\t\n",
      "  batch 3200 loss: 4.805949749946595\n",
      "Epoch: [3][3200/17600]\tTime 1.1528842449188232 (2.3113264183700086)\tData 1.143073320388794 (2.3001271952688693)\t\n",
      "  batch 3250 loss: 4.6101981019973755\n",
      "Epoch: [3][3250/17600]\tTime 1.2991931438446045 (2.2914125646444465)\tData 1.286980152130127 (2.2801993562258205)\t\n",
      "  batch 3300 loss: 4.630217173099518\n",
      "Epoch: [3][3300/17600]\tTime 1.1082425117492676 (2.272873292547284)\tData 1.0985784530639648 (2.2616473523775737)\t\n",
      "  batch 3350 loss: 4.274637308120727\n",
      "Epoch: [3][3350/17600]\tTime 0.8687503337860107 (2.254968869365863)\tData 0.85577392578125 (2.2437221071613367)\t\n",
      "  batch 3400 loss: 4.6123205137252805\n",
      "Epoch: [3][3400/17600]\tTime 0.8352169990539551 (2.237967066484339)\tData 0.8224306106567383 (2.226717948913574)\t\n",
      "  batch 3450 loss: 4.396386251449585\n",
      "Epoch: [3][3450/17600]\tTime 1.085341215133667 (2.2205717603711115)\tData 1.0729873180389404 (2.2093129168386043)\t\n",
      "  batch 3500 loss: 4.558479471206665\n",
      "Epoch: [3][3500/17600]\tTime 0.8525915145874023 (2.203182334627424)\tData 0.8400542736053467 (2.1919160401480537)\t\n",
      "  batch 3550 loss: 4.894440402984619\n",
      "Epoch: [3][3550/17600]\tTime 1.3642160892486572 (2.187265531513053)\tData 1.3539624214172363 (2.1759969380204107)\t\n",
      "  batch 3600 loss: 4.797784190177918\n",
      "Epoch: [3][3600/17600]\tTime 1.3758549690246582 (2.1708851657973396)\tData 1.3631267547607422 (2.1596033796336918)\t\n",
      "  batch 3650 loss: 4.689206547737122\n",
      "Epoch: [3][3650/17600]\tTime 1.0282495021820068 (2.1559883522660765)\tData 1.015568494796753 (2.144696860574696)\t\n",
      "  batch 3700 loss: 4.758485994338989\n",
      "Epoch: [3][3700/17600]\tTime 1.9350464344024658 (2.1407769624606985)\tData 1.9218242168426514 (2.1294847328598436)\t\n",
      "  batch 3750 loss: 4.672641940116883\n",
      "Epoch: [3][3750/17600]\tTime 0.8256747722625732 (2.125567139307658)\tData 0.8149688243865967 (2.1142739820480347)\t\n",
      "  batch 3800 loss: 4.679097352027893\n",
      "Epoch: [3][3800/17600]\tTime 0.7559692859649658 (2.1110903811454773)\tData 0.7445673942565918 (2.0997949988591045)\t\n",
      "  batch 3850 loss: 4.920319333076477\n",
      "Epoch: [3][3850/17600]\tTime 0.7535977363586426 (2.0969795323037483)\tData 0.740382194519043 (2.0856704702005757)\t\n",
      "  batch 3900 loss: 4.7577454662323\n",
      "Epoch: [3][3900/17600]\tTime 0.8929691314697266 (2.083018049337925)\tData 0.8833625316619873 (2.0717081538224833)\t\n",
      "  batch 3950 loss: 4.4627121591567995\n",
      "Epoch: [3][3950/17600]\tTime 1.2692852020263672 (2.0701840173141868)\tData 1.256540298461914 (2.0588709356211408)\t\n",
      "  batch 4000 loss: 4.490659399032593\n",
      "Epoch: [3][4000/17600]\tTime 0.8688714504241943 (2.057598479986191)\tData 0.8564174175262451 (2.046284188747406)\t\n",
      "  batch 4050 loss: 4.824412264823914\n",
      "Epoch: [3][4050/17600]\tTime 0.9322810173034668 (2.044351559980416)\tData 0.9133241176605225 (2.033033247052887)\t\n",
      "  batch 4100 loss: 4.89025532245636\n",
      "Epoch: [3][4100/17600]\tTime 1.0897605419158936 (2.0328635034328553)\tData 1.0797288417816162 (2.021543486467222)\t\n",
      "  batch 4150 loss: 4.622890334129334\n",
      "Epoch: [3][4150/17600]\tTime 0.9572048187255859 (2.021250787815416)\tData 0.9459409713745117 (2.0099219104468102)\t\n",
      "  batch 4200 loss: 4.629447708129883\n",
      "Epoch: [3][4200/17600]\tTime 0.9442403316497803 (2.009994126274472)\tData 0.9320039749145508 (1.9986624140966507)\t\n",
      "  batch 4250 loss: 4.531778764724732\n",
      "Epoch: [3][4250/17600]\tTime 0.7560670375823975 (1.9992320874158074)\tData 0.7416384220123291 (1.9878962442173678)\t\n",
      "  batch 4300 loss: 4.421163067817688\n",
      "Epoch: [3][4300/17600]\tTime 1.3378338813781738 (1.9878386073888734)\tData 1.3277883529663086 (1.9765002317761267)\t\n",
      "  batch 4350 loss: 4.670968747138977\n",
      "Epoch: [3][4350/17600]\tTime 1.657801628112793 (1.9769002229317851)\tData 1.6477510929107666 (1.965552867856519)\t\n",
      "  batch 4400 loss: 4.853762850761414\n",
      "Epoch: [3][4400/17600]\tTime 1.2571747303009033 (1.966310601288622)\tData 1.246701717376709 (1.9549596212668852)\t\n",
      "  batch 4450 loss: 4.676532583236694\n",
      "Epoch: [3][4450/17600]\tTime 1.4037721157073975 (1.9559449097279753)\tData 1.3915746212005615 (1.9445921737692329)\t\n",
      "  batch 4500 loss: 4.489687294960022\n",
      "Epoch: [3][4500/17600]\tTime 1.4707355499267578 (1.9468577069706388)\tData 1.4587464332580566 (1.9355009134080674)\t\n",
      "  batch 4550 loss: 4.4945406293869015\n",
      "Epoch: [3][4550/17600]\tTime 1.364272117614746 (1.9364695197409325)\tData 1.3514831066131592 (1.925108078128689)\t\n",
      "  batch 4600 loss: 4.565694117546082\n",
      "Epoch: [3][4600/17600]\tTime 0.854994535446167 (1.9270561603359555)\tData 0.8450345993041992 (1.9156906554491624)\t\n",
      "  batch 4650 loss: 4.679711451530457\n",
      "Epoch: [3][4650/17600]\tTime 0.5891594886779785 (1.9177973282721734)\tData 0.5785648822784424 (1.9064246597597676)\t\n",
      "  batch 4700 loss: 4.853455519676208\n",
      "Epoch: [3][4700/17600]\tTime 0.920403003692627 (1.9082870603622275)\tData 0.9079806804656982 (1.8969117716525463)\t\n",
      "  batch 4750 loss: 4.888487000465393\n",
      "Epoch: [3][4750/17600]\tTime 1.1987628936767578 (1.8997550563310321)\tData 1.1863489151000977 (1.8883779905720761)\t\n",
      "  batch 4800 loss: 4.698225975036621\n",
      "Epoch: [3][4800/17600]\tTime 1.0011231899261475 (1.8912306398153305)\tData 0.9913818836212158 (1.8798505441844464)\t\n",
      "  batch 4850 loss: 4.902872972488403\n",
      "Epoch: [3][4850/17600]\tTime 0.8320133686065674 (1.882912104203529)\tData 0.8190557956695557 (1.871532555462159)\t\n",
      "  batch 4900 loss: 4.652778797149658\n",
      "Epoch: [3][4900/17600]\tTime 0.8230388164520264 (1.8739441538830193)\tData 0.8104653358459473 (1.862560668721491)\t\n",
      "  batch 4950 loss: 4.753681349754333\n",
      "Epoch: [3][4950/17600]\tTime 1.003741979598999 (1.8656434487333202)\tData 0.9926044940948486 (1.8542564715279473)\t\n",
      "  batch 5000 loss: 4.509861962795258\n",
      "Epoch: [3][5000/17600]\tTime 1.128830909729004 (1.857484419631958)\tData 1.1163182258605957 (1.846096753168106)\t\n",
      "  batch 5050 loss: 4.897192544937134\n",
      "Epoch: [3][5050/17600]\tTime 0.8431382179260254 (1.849958738997431)\tData 0.8303508758544922 (1.8385638826672392)\t\n",
      "  batch 5100 loss: 4.84352961063385\n",
      "Epoch: [3][5100/17600]\tTime 1.2132935523986816 (1.8428327408491396)\tData 1.2035253047943115 (1.8314364167288237)\t\n",
      "  batch 5150 loss: 4.882307529449463\n",
      "Epoch: [3][5150/17600]\tTime 0.6486918926239014 (1.834930958701569)\tData 0.6391434669494629 (1.8235313846532581)\t\n",
      "  batch 5200 loss: 4.582613306045532\n",
      "Epoch: [3][5200/17600]\tTime 0.9310932159423828 (1.8268570835315263)\tData 0.9218204021453857 (1.8154575891219653)\t\n",
      "  batch 5250 loss: 4.417704153060913\n",
      "Epoch: [3][5250/17600]\tTime 1.145381212234497 (1.819846942674546)\tData 1.1321794986724854 (1.8084403483527047)\t\n",
      "  batch 5300 loss: 4.591329262256623\n",
      "Epoch: [3][5300/17600]\tTime 0.7571461200714111 (1.812042289949813)\tData 0.7470371723175049 (1.8006363404022072)\t\n",
      "  batch 5350 loss: 4.644292960166931\n",
      "Epoch: [3][5350/17600]\tTime 1.0088458061218262 (1.8058623788067114)\tData 0.9961645603179932 (1.7944506827024655)\t\n",
      "  batch 5400 loss: 4.462403299808503\n",
      "Epoch: [3][5400/17600]\tTime 0.8647112846374512 (1.7990368528277785)\tData 0.8523902893066406 (1.7876214854805559)\t\n",
      "  batch 5450 loss: 4.6856032919883726\n",
      "Epoch: [3][5450/17600]\tTime 1.055509090423584 (1.7928100564064235)\tData 1.0429110527038574 (1.7813870306627466)\t\n",
      "  batch 5500 loss: 4.944849896430969\n",
      "Epoch: [3][5500/17600]\tTime 1.0582716464996338 (1.7859851658561012)\tData 1.0439589023590088 (1.7745566557103938)\t\n",
      "  batch 5550 loss: 4.487549438476562\n",
      "Epoch: [3][5550/17600]\tTime 0.868640661239624 (1.7793654182794931)\tData 0.8589808940887451 (1.7679342634183866)\t\n",
      "  batch 5600 loss: 4.570969493389129\n",
      "Epoch: [3][5600/17600]\tTime 1.00777268409729 (1.7721930219020163)\tData 0.9976513385772705 (1.760761831487928)\t\n",
      "  batch 5650 loss: 4.766731283664703\n",
      "Epoch: [3][5650/17600]\tTime 1.1692280769348145 (1.7665539394648728)\tData 1.1583871841430664 (1.7551194564431114)\t\n",
      "  batch 5700 loss: 4.739017672538758\n",
      "Epoch: [3][5700/17600]\tTime 0.893883228302002 (1.7603734501202901)\tData 0.8835299015045166 (1.7489393055648135)\t\n",
      "  batch 5750 loss: 4.76543089389801\n",
      "Epoch: [3][5750/17600]\tTime 1.0874109268188477 (1.7538620350879173)\tData 1.0773415565490723 (1.7424232108903968)\t\n",
      "  batch 5800 loss: 4.5996962881088255\n",
      "Epoch: [3][5800/17600]\tTime 0.8396666049957275 (1.747880500719465)\tData 0.8266112804412842 (1.7364385331910233)\t\n",
      "  batch 5850 loss: 4.673562197685242\n",
      "Epoch: [3][5850/17600]\tTime 2.016314744949341 (1.7418802820107875)\tData 2.006152868270874 (1.7304399826995327)\t\n",
      "  batch 5900 loss: 4.8667927789688115\n",
      "Epoch: [3][5900/17600]\tTime 1.2384834289550781 (1.7371718367883715)\tData 1.225728988647461 (1.725731947179568)\t\n",
      "  batch 5950 loss: 4.900678806304931\n",
      "Epoch: [3][5950/17600]\tTime 1.3891716003417969 (1.7314789022718158)\tData 1.3791782855987549 (1.7200346182174042)\t\n",
      "  batch 6000 loss: 4.971945972442627\n",
      "Epoch: [3][6000/17600]\tTime 0.6444270610809326 (1.725680061062177)\tData 0.6346750259399414 (1.714235760052999)\t\n",
      "  batch 6050 loss: 4.580334918498993\n",
      "Epoch: [3][6050/17600]\tTime 0.9459304809570312 (1.7201234142051256)\tData 0.935941219329834 (1.708674558726224)\t\n",
      "  batch 6100 loss: 4.78672420501709\n",
      "Epoch: [3][6100/17600]\tTime 0.7515292167663574 (1.7144260979871282)\tData 0.7395713329315186 (1.7029756489347239)\t\n",
      "  batch 6150 loss: 4.768579316139221\n",
      "Epoch: [3][6150/17600]\tTime 1.0695850849151611 (1.7091305563314174)\tData 1.0571961402893066 (1.6976782879402967)\t\n",
      "  batch 6200 loss: 4.622113833427429\n",
      "Epoch: [3][6200/17600]\tTime 0.6032376289367676 (1.7034171867755152)\tData 0.5903835296630859 (1.6919632788242833)\t\n",
      "  batch 6250 loss: 4.691795015335083\n",
      "Epoch: [3][6250/17600]\tTime 1.7905073165893555 (1.698503140220642)\tData 1.7778189182281494 (1.6870454441452027)\t\n",
      "  batch 6300 loss: 4.836894955635071\n",
      "Epoch: [3][6300/17600]\tTime 1.0907723903656006 (1.6931533760873099)\tData 1.0787434577941895 (1.68168822878883)\t\n",
      "  batch 6350 loss: 4.754418544769287\n",
      "Epoch: [3][6350/17600]\tTime 1.006920576095581 (1.6877746380407979)\tData 0.9952280521392822 (1.6763091115876445)\t\n",
      "  batch 6400 loss: 4.977852566242218\n",
      "Epoch: [3][6400/17600]\tTime 0.9360270500183105 (1.683109993301332)\tData 0.9265680313110352 (1.6716437787935137)\t\n",
      "  batch 6450 loss: 4.528052606582642\n",
      "Epoch: [3][6450/17600]\tTime 0.966942310333252 (1.6783850890906282)\tData 0.9540085792541504 (1.6669160699474719)\t\n",
      "  batch 6500 loss: 4.652565274238587\n",
      "Epoch: [3][6500/17600]\tTime 0.9354777336120605 (1.6736587723585274)\tData 0.9206347465515137 (1.6621879756267255)\t\n",
      "  batch 6550 loss: 4.607793316841126\n",
      "Epoch: [3][6550/17600]\tTime 1.4796900749206543 (1.669382342345842)\tData 1.4672818183898926 (1.657909012896414)\t\n",
      "  batch 6600 loss: 4.8261696720123295\n",
      "Epoch: [3][6600/17600]\tTime 1.0278146266937256 (1.6646387895670804)\tData 1.014082670211792 (1.6531642903342392)\t\n",
      "  batch 6650 loss: 4.960809907913208\n",
      "Epoch: [3][6650/17600]\tTime 1.3008182048797607 (1.660045195522165)\tData 1.288393259048462 (1.648570791187143)\t\n",
      "  batch 6700 loss: 4.3457948064804075\n",
      "Epoch: [3][6700/17600]\tTime 1.6756010055541992 (1.6554222009786919)\tData 1.6658611297607422 (1.6439481096837059)\t\n",
      "  batch 6750 loss: 4.57354284286499\n",
      "Epoch: [3][6750/17600]\tTime 0.8567023277282715 (1.6509488221627695)\tData 0.8446996212005615 (1.6394715179514001)\t\n",
      "  batch 6800 loss: 4.77167462348938\n",
      "Epoch: [3][6800/17600]\tTime 1.2466130256652832 (1.6466625501829035)\tData 1.2366642951965332 (1.6351829755306244)\t\n",
      "  batch 6850 loss: 4.513998341560364\n",
      "Epoch: [3][6850/17600]\tTime 1.2823843955993652 (1.6422012857799113)\tData 1.2705621719360352 (1.6307180220541293)\t\n",
      "  batch 6900 loss: 4.810261836051941\n",
      "Epoch: [3][6900/17600]\tTime 0.8675656318664551 (1.6376068702642468)\tData 0.8552186489105225 (1.6261234624835028)\t\n",
      "  batch 6950 loss: 4.662395887374878\n",
      "Epoch: [3][6950/17600]\tTime 0.6980206966400146 (1.6335172578756758)\tData 0.6879904270172119 (1.6220385660542)\t\n",
      "  batch 7000 loss: 4.786250839233398\n",
      "Epoch: [3][7000/17600]\tTime 1.3192765712738037 (1.6295189330237252)\tData 1.3074069023132324 (1.6180403648444583)\t\n",
      "  batch 7050 loss: 4.504036784172058\n",
      "Epoch: [3][7050/17600]\tTime 0.7189939022064209 (1.6252376316963357)\tData 0.7065606117248535 (1.6137571407209896)\t\n",
      "  batch 7100 loss: 4.5874445271492\n",
      "Epoch: [3][7100/17600]\tTime 0.6617851257324219 (1.6213286193323806)\tData 0.6494021415710449 (1.6098464593417208)\t\n",
      "  batch 7150 loss: 4.722040886878967\n",
      "Epoch: [3][7150/17600]\tTime 0.9957375526428223 (1.6171073639142763)\tData 0.9859955310821533 (1.6056259870862628)\t\n",
      "  batch 7200 loss: 4.528218812942505\n",
      "Epoch: [3][7200/17600]\tTime 1.621781826019287 (1.6135061209400494)\tData 1.6119554042816162 (1.6020233344038328)\t\n",
      "  batch 7250 loss: 4.707500238418579\n",
      "Epoch: [3][7250/17600]\tTime 1.0254244804382324 (1.610087105060446)\tData 1.0128004550933838 (1.5986053045207056)\t\n",
      "  batch 7300 loss: 4.552781045436859\n",
      "Epoch: [3][7300/17600]\tTime 1.3530051708221436 (1.6066893683720942)\tData 1.3431506156921387 (1.5952005982072386)\t\n",
      "  batch 7350 loss: 4.576974682807922\n",
      "Epoch: [3][7350/17600]\tTime 0.961174726486206 (1.6029973243531728)\tData 0.9503717422485352 (1.5915064695903234)\t\n",
      "  batch 7400 loss: 4.695404486656189\n",
      "Epoch: [3][7400/17600]\tTime 1.019212007522583 (1.5995174351576211)\tData 1.0070981979370117 (1.5880228055167842)\t\n",
      "  batch 7450 loss: 4.360597095489502\n",
      "Epoch: [3][7450/17600]\tTime 1.0148417949676514 (1.59518691021324)\tData 1.0043056011199951 (1.5836871922576188)\t\n",
      "  batch 7500 loss: 4.707653822898865\n",
      "Epoch: [3][7500/17600]\tTime 1.1984081268310547 (1.591676212755839)\tData 1.188856601715088 (1.5801761187871297)\t\n",
      "  batch 7550 loss: 4.802082223892212\n",
      "Epoch: [3][7550/17600]\tTime 1.2617831230163574 (1.5888548392807411)\tData 1.2513947486877441 (1.5773546584236702)\t\n",
      "  batch 7600 loss: 4.717605805397033\n",
      "Epoch: [3][7600/17600]\tTime 0.9665651321411133 (1.5851354063184637)\tData 0.9540221691131592 (1.5736334436190755)\t\n",
      "  batch 7650 loss: 4.657905812263489\n",
      "Epoch: [3][7650/17600]\tTime 1.1167705059051514 (1.5811609380073797)\tData 1.1063039302825928 (1.5696518632789063)\t\n",
      "  batch 7700 loss: 4.570166430473328\n",
      "Epoch: [3][7700/17600]\tTime 0.8800528049468994 (1.5774573862397825)\tData 0.8702306747436523 (1.5659480532423242)\t\n",
      "  batch 7750 loss: 4.638259391784668\n",
      "Epoch: [3][7750/17600]\tTime 0.9105167388916016 (1.574454503766952)\tData 0.8980960845947266 (1.56294337731023)\t\n",
      "  batch 7800 loss: 4.882448291778564\n",
      "Epoch: [3][7800/17600]\tTime 1.5846872329711914 (1.571098792675214)\tData 1.5724775791168213 (1.5595870085557302)\t\n",
      "  batch 7850 loss: 4.463287839889526\n",
      "Epoch: [3][7850/17600]\tTime 1.0383598804473877 (1.5680894302866262)\tData 1.025583028793335 (1.5565771125987837)\t\n",
      "  batch 7900 loss: 5.09877613067627\n",
      "Epoch: [3][7900/17600]\tTime 1.1701459884643555 (1.564998030903973)\tData 1.1598944664001465 (1.5534848980963984)\t\n",
      "  batch 7950 loss: 4.54875816822052\n",
      "Epoch: [3][7950/17600]\tTime 1.223653793334961 (1.5615404996032236)\tData 1.2129197120666504 (1.5500293340922902)\t\n",
      "  batch 8000 loss: 4.506886591911316\n",
      "Epoch: [3][8000/17600]\tTime 0.790003776550293 (1.5585163240730762)\tData 0.7756190299987793 (1.5470019806325435)\t\n",
      "  batch 8050 loss: 4.6325571155548095\n",
      "Epoch: [3][8050/17600]\tTime 1.068260669708252 (1.5549971053318947)\tData 1.05857515335083 (1.5434839399705023)\t\n",
      "  batch 8100 loss: 4.526793069839478\n",
      "Epoch: [3][8100/17600]\tTime 1.0891408920288086 (1.5521453392652818)\tData 1.0769221782684326 (1.540630491397999)\t\n",
      "  batch 8150 loss: 4.518447167873383\n",
      "Epoch: [3][8150/17600]\tTime 1.4383776187896729 (1.5489400964573117)\tData 1.4255425930023193 (1.5374221109905126)\t\n",
      "  batch 8200 loss: 4.509718856811523\n",
      "Epoch: [3][8200/17600]\tTime 1.0016803741455078 (1.54573183266128)\tData 0.9909427165985107 (1.53421167024752)\t\n",
      "  batch 8250 loss: 4.6029770565032955\n",
      "Epoch: [3][8250/17600]\tTime 0.8199007511138916 (1.542353707631429)\tData 0.8074405193328857 (1.530832285938841)\t\n",
      "  batch 8300 loss: 4.493922686576843\n",
      "Epoch: [3][8300/17600]\tTime 0.9709422588348389 (1.5394764135831809)\tData 0.9614131450653076 (1.5279559326171874)\t\n",
      "  batch 8350 loss: 4.511383714675904\n",
      "Epoch: [3][8350/17600]\tTime 0.6460621356964111 (1.5365995699774004)\tData 0.6335978507995605 (1.5250784688652632)\t\n",
      "  batch 8400 loss: 4.511865105628967\n",
      "Epoch: [3][8400/17600]\tTime 1.0674033164978027 (1.5338635899339403)\tData 1.0551581382751465 (1.5223444317919868)\t\n",
      "  batch 8450 loss: 4.58151018857956\n",
      "Epoch: [3][8450/17600]\tTime 0.9263525009155273 (1.5309169761669001)\tData 0.9146246910095215 (1.5193958155220078)\t\n",
      "  batch 8500 loss: 4.586721792221069\n",
      "Epoch: [3][8500/17600]\tTime 1.0202655792236328 (1.528278881185195)\tData 1.0082473754882812 (1.5167583288865931)\t\n",
      "  batch 8550 loss: 4.708821024894714\n",
      "Epoch: [3][8550/17600]\tTime 1.1044681072235107 (1.5256007374378673)\tData 1.0917253494262695 (1.5140791364301716)\t\n",
      "  batch 8600 loss: 4.479897651672363\n",
      "Epoch: [3][8600/17600]\tTime 0.8311235904693604 (1.5227711606302927)\tData 0.8210716247558594 (1.5112435046462125)\t\n",
      "  batch 8650 loss: 4.604864993095398\n",
      "Epoch: [3][8650/17600]\tTime 0.8170840740203857 (1.5198977882738058)\tData 0.8041410446166992 (1.508369758363404)\t\n",
      "  batch 8700 loss: 4.589749078750611\n",
      "Epoch: [3][8700/17600]\tTime 0.7124819755554199 (1.5170352167096632)\tData 0.7014939785003662 (1.505508448748753)\t\n",
      "  batch 8750 loss: 4.866782746315002\n",
      "Epoch: [3][8750/17600]\tTime 1.2346670627593994 (1.5143795381546021)\tData 1.2249031066894531 (1.5028542481831142)\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a6118f44d5ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     save_dict = {\n",
      "\u001b[0;32m<ipython-input-19-a0e1224e120e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, img_model, text_model, transformer, criterion, optimizer_image, optimizer_text, optimizer_transformer, epoch)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mtotal_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    train(train_loader, img_model, text_model, transformer, criterion, optimizer_image, optimizer_text, optimizer_transformer, epoch)\n",
    "    \n",
    "    save_dict = {\n",
    "        \"image_vit_encoder\": img_model.state_dict(),\n",
    "        \"text_encoder\": text_model.state_dict(),\n",
    "        \"cm_transformer\": transformer.state_dict()\n",
    "    }\n",
    "    \n",
    "    torch.save(save_dict, f'/common/users/kcm161/step3_models_instructions_with_triplet_sgd_e{epoch}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {\n",
    "    \"image_vit_encoder\": img_model.state_dict(),\n",
    "    \"text_encoder\": text_model.state_dict(),\n",
    "    \"cm_transformer\": transformer.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(save_dict, f'/common/users/kcm161/step3_models_with_triplet_e1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_weights = torch.load(\"/common/users/kcm161/step3_models_with_triplet_e1.pt\", map_location = torch.device(\"cuda:1\"))\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "img_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "for param in text_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in img_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "transformer = CrossModalAttention()\n",
    "\n",
    "optimizer_image = torch.optim.SGD(img_model.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "optimizer_text = torch.optim.SGD(text_model.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "optimizer_transformer = torch.optim.SGD(transformer.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "text_model = nn.DataParallel(text_model, device_ids=[1])\n",
    "text_model.load_state_dict(model_weights[\"text_encoder\"])\n",
    "text_model.to((f'cuda:{text_model.device_ids[0]}'));\n",
    "text_model.train();\n",
    "\n",
    "img_model = nn.DataParallel(img_model, device_ids=[1])\n",
    "img_model.load_state_dict(model_weights[\"image_vit_encoder\"])\n",
    "img_model.to((f'cuda:{img_model.device_ids[0]}'));\n",
    "img_model.train();\n",
    "\n",
    "transformer = nn.DataParallel(transformer, device_ids=[1])\n",
    "# transformer.load_state_dict(model_weights_1[\"cm_transformer\"])\n",
    "transformer.to((f'cuda:{transformer.device_ids[0]}'));\n",
    "transformer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60740"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate validation and test embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "img_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "transformer = CrossModalAttention()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model_weights = torch.load(\"/common/users/kcm161/step3_models_with_triplet_sgd_e1.pt\", map_location=\"cuda:1\")\n",
    "\n",
    "text_model = nn.DataParallel(text_model, device_ids=[1])\n",
    "text_model.load_state_dict(model_weights[\"text_encoder\"])\n",
    "text_model.to((f'cuda:{text_model.device_ids[0]}'));\n",
    "text_model.eval();\n",
    "\n",
    "img_model = nn.DataParallel(img_model, device_ids=[1])\n",
    "img_model.load_state_dict(model_weights[\"image_vit_encoder\"])\n",
    "img_model.to((f'cuda:{img_model.device_ids[0]}'));\n",
    "img_model.eval();\n",
    "\n",
    "transformer = nn.DataParallel(transformer, device_ids=[1])\n",
    "transformer.load_state_dict(model_weights[\"cm_transformer\"])\n",
    "transformer.to((f'cuda:{transformer.device_ids[0]}'));\n",
    "transformer.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(loader, img_model, text_model, transformer):\n",
    "    \n",
    "    model_weights = torch.load(\"/common/users/kcm161/step3_models_instructions_with_triplet_sgd_e2.pt\", map_location=\"cuda:0\")\n",
    "\n",
    "    text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    img_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "    transformer = CrossModalAttention()\n",
    "\n",
    "    text_model = nn.DataParallel(text_model, device_ids=[0])\n",
    "    text_model.load_state_dict(model_weights[\"text_encoder\"])\n",
    "    text_model.to((f'cuda:{text_model.device_ids[0]}'));\n",
    "    text_model.eval();\n",
    "\n",
    "    img_model = nn.DataParallel(img_model, device_ids=[0])\n",
    "    img_model.load_state_dict(model_weights[\"image_vit_encoder\"])\n",
    "    img_model.to((f'cuda:{img_model.device_ids[0]}'));\n",
    "    img_model.eval();\n",
    "\n",
    "    transformer = nn.DataParallel(transformer, device_ids=[0])\n",
    "    transformer.load_state_dict(model_weights[\"cm_transformer\"])\n",
    "    transformer.to((f'cuda:{transformer.device_ids[0]}'));\n",
    "    transformer.eval();\n",
    "        \n",
    "    img_encodings = np.zeros((len(loader),), dtype = object)\n",
    "    text_encodings = np.zeros((len(loader),), dtype = object)\n",
    "    text_masks = np.zeros((len(loader),), dtype = object)\n",
    "    \n",
    "    idx = 0\n",
    "\n",
    "    print(img_encodings.shape, len(loader))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for img, text in loader:\n",
    "\n",
    "            # Run forward pass\n",
    "            image_output = img_model(img.to(f'cuda:{img_model.device_ids[0]}'))\n",
    "            encoded_ingredients = tokenizer(text, return_tensors='pt', max_length=512, truncation = True, padding = True).to(f'cuda:{text_model.device_ids[0]}')\n",
    "            output_ingredients = text_model(**encoded_ingredients)\n",
    "            input_attention_mask = encoded_ingredients.attention_mask\n",
    "            text_padding_mask = ~input_attention_mask.bool()\n",
    "\n",
    "            img_encodings[idx] = image_output[\"last_hidden_state\"].cpu().detach().numpy()\n",
    "            text_encodings[idx] = output_ingredients[\"last_hidden_state\"].cpu().detach().numpy()\n",
    "            text_masks[idx] = text_padding_mask.cpu().detach().numpy()\n",
    "        \n",
    "            idx += 1\n",
    "\n",
    "            if idx % 2000 == 0:\n",
    "                print(idx)\n",
    "                # print(img_encodings[idx-1])\n",
    "    # print(img_encodings)\n",
    "\n",
    "    return img_encodings, text_encodings, text_masks\n",
    "    \n",
    "    # ranker(img_encodings, text_encodings, text_masks, transformer, \"recipe\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking extractor embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean median 15.7\n",
      "Recall {1: 0.09549999999999999, 5: 0.28869999999999996, 10: 0.4130999999999999}\n"
     ]
    }
   ],
   "source": [
    "triplet_ranker(img_encode, text_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_ranker(im_vecs, instr_vecs, N = 1000, flag = \"image\"):\n",
    "    # Ranker\n",
    "    idxs = range(N)\n",
    "\n",
    "    glob_rank = []\n",
    "    glob_recall = {1:0.0,5:0.0,10:0.0}\n",
    "    for i in range(10):\n",
    "\n",
    "        ids = random.sample(range(0,len(im_vecs)), N)\n",
    "        \n",
    "        im_sub = im_vecs[ids]\n",
    "        instr_sub = instr_vecs[ids]\n",
    "\n",
    "        if flag == \"image\":\n",
    "            sims = np.dot(im_sub,instr_sub.reshape((N, 768, 1))) # for im2recipe\n",
    "        else:\n",
    "            sims = np.dot(instr_sub,im_sub.T) # for recipe2im\n",
    "\n",
    "        med_rank = []\n",
    "        recall = {1:0.0,5:0.0,10:0.0}\n",
    "\n",
    "        sims = sims.squeeze(1).squeeze(2)\n",
    "\n",
    "        for ii in idxs:\n",
    "\n",
    "            # name = ids_sub[ii]\n",
    "            # get a column of similarities\n",
    "            sim = sims[ii]\n",
    "\n",
    "            # sort indices in descending order\n",
    "            sorting = np.argsort(sim)[::-1].tolist()\n",
    "\n",
    "            # print(sorting)\n",
    "\n",
    "            # find where the index of the pair sample ended up in the sorting\n",
    "            pos = sorting.index(ii)\n",
    "\n",
    "            if (pos+1) == 1:\n",
    "                recall[1]+=1\n",
    "            if (pos+1) <=5:\n",
    "                recall[5]+=1\n",
    "            if (pos+1)<=10:\n",
    "                recall[10]+=1\n",
    "\n",
    "            # store the position\n",
    "            med_rank.append(pos+1)\n",
    "\n",
    "        for i in recall.keys():\n",
    "            recall[i]=recall[i]/N\n",
    "\n",
    "        med = np.median(med_rank)\n",
    "#         print (\"median\", med)\n",
    "\n",
    "        for i in recall.keys():\n",
    "            glob_recall[i]+=recall[i]\n",
    "        glob_rank.append(med)\n",
    "\n",
    "    for i in glob_recall.keys():\n",
    "        glob_recall[i] = glob_recall[i]/10\n",
    "    \n",
    "    print (\"Mean median\", np.average(glob_rank))\n",
    "    print (\"Recall\", glob_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Transformer outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredients - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60740,) 60740\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "42000\n",
      "44000\n",
      "46000\n",
      "48000\n",
      "50000\n",
      "52000\n",
      "54000\n",
      "56000\n",
      "58000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "img_encodings, text_encodings, text_masks = generate_embeddings(test_loader, img_model, text_model, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.8, 1.5362291495737217, {1: 0.072, 5: 0.286, 10: 0.487})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingredients im2recipe\n",
    "ranker(img_encodings, text_encodings, text_masks, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.1,\n",
       " 1.2206555615733703,\n",
       " {1: 0.159, 5: 0.4699999999999999, 10: 0.6340000000000001})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingredients recipe2im\n",
    "ranker(img_encodings, text_encodings, text_masks, transformer, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60740,) 60740\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "42000\n",
      "44000\n",
      "46000\n",
      "48000\n",
      "50000\n",
      "52000\n",
      "54000\n",
      "56000\n",
      "58000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "img_encodings, text_encodings, text_masks = generate_embeddings(test_loader, img_model, text_model, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.5,\n",
       " 3.0413812651491097,\n",
       " {1: 0.046000000000000006, 5: 0.15599999999999997, 10: 0.26200000000000007})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title im2recipe\n",
    "ranker(img_encodings, text_encodings, text_masks, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27.1,\n",
       " 2.981610303175115,\n",
       " {1: 0.033999999999999996, 5: 0.14200000000000002, 10: 0.24300000000000002})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title im2recipe\n",
    "ranker(img_encodings, text_encodings, text_masks, transformer, \"recipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions - testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Text - testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranker(img_encodings, text_encodings, text_masks, transformer, retrieval_type = \"recipe\", n = 100):\n",
    "    t = time.time()\n",
    "    data_size = len(img_encodings)\n",
    "    \n",
    "    glob_rank = []\n",
    "    glob_recall = {1:0.0, 5:0.0, 10:0.0}\n",
    "    \n",
    "    # with tqdm (total = n * n * 10) as pbar:\n",
    "    for i in range(10):\n",
    "        ids_sub = np.random.choice(data_size, n, replace = False)\n",
    "        # imgs_sub = img_encodings[ids_sub, :] # numpy \n",
    "        # text_sub = text_encodings[ids_sub, :] # numpy\n",
    "        # attn_sub = text_masks[ids_sub, :] # numpy\n",
    "\n",
    "        imgs_sub = img_encodings[ids_sub] # numpy \n",
    "        text_sub = text_encodings[ids_sub] # numpy\n",
    "        attn_sub = text_masks[ids_sub] # numpy\n",
    "                \n",
    "        probs = torch.zeros((n,n)).detach().cpu()\n",
    "        \n",
    "        if retrieval_type == \"recipe\":\n",
    "            for x in range(n):\n",
    "                for y in range(n):\n",
    "                    temp = transformer(torch.from_numpy(imgs_sub[x]), torch.from_numpy(text_sub[y]), torch.from_numpy(attn_sub[y]))\n",
    "                    probs[x, y] =  nn.Softmax(dim=1)(temp)[0][1].detach().cpu()\n",
    "                    # print(probs[x,y])\n",
    "                \n",
    "                # pbar.update(n)\n",
    "\n",
    "        else:\n",
    "            for x in range(n):\n",
    "                for y in range(n):\n",
    "                    temp = transformer(torch.from_numpy(imgs_sub[y]), torch.from_numpy(text_sub[x]), torch.from_numpy(attn_sub[x]))\n",
    "                    probs[x, y] =  nn.Softmax(dim=1)(temp)[0][1].detach().cpu()\n",
    "                    # print(probs[x,y])\n",
    "                \n",
    "\n",
    "        ranks, _ = compute_ranks(probs.numpy())\n",
    "        \n",
    "        recall = {1: 0.0, 5:0.0, 10:0.0}\n",
    "        for ii in recall.keys():\n",
    "            recall[ii] = (ranks <= ii).sum() / ranks.shape[0]\n",
    "        med = int(np.median(ranks))\n",
    "        # print(med, recall)\n",
    "        for ii in recall.keys():\n",
    "            glob_recall[ii] += recall[ii]\n",
    "        glob_rank.append(med)\n",
    "\n",
    "        # print(i)\n",
    "        \n",
    "    for i in glob_recall.keys():\n",
    "        glob_recall[i] /= 10\n",
    "        \n",
    "    medR = np.mean(glob_rank)\n",
    "    medR_std = np.std(glob_rank)\n",
    "            \n",
    "    return medR, medR_std, glob_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranks(sims):\n",
    "    ranks = []\n",
    "    preds = []\n",
    "\n",
    "    # print(sims, sims.shape)\n",
    "    \n",
    "    for ii in range(sims.shape[0]):\n",
    "        sim = sims[ii, :]\n",
    "        sorting = np.argsort(sim)[::-1].tolist()\n",
    "        pos = sorting.index(ii)\n",
    "        \n",
    "        ranks.append(pos + 1.0)\n",
    "        preds.append(sorting[0])\n",
    "        \n",
    "    return np.asarray(ranks), preds"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba9bc282ea7dd8acf6b93a88ab047ea17bba2d98cff2c21ca6cffa26ac4d8f39"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
