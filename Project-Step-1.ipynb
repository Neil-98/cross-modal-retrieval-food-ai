{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea3a625",
   "metadata": {},
   "source": [
    "## Image Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2ecdce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle\n",
    "\n",
    "# making sure that the whole embedding tensor is printed in output\n",
    "torch.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1ab717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure the feature extraction runs on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a6fd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, dir_path, file_path, transforms):\n",
    "#         self.dir = dir_path\n",
    "#         self.file_path = file_path\n",
    "# #         self.img_id_mapping = {}\n",
    "#         self.image_paths = []\n",
    "#         self.transforms = transforms\n",
    "\n",
    "#         test_file = open(file_path)\n",
    "#         test_data = json.load(test_file)\n",
    "#         test_file.close()\n",
    "\n",
    "#         for row in test_data:\n",
    "#             id = row[\"id\"]\n",
    "#             for image_path in row[\"images\"]:\n",
    "#                 self.image_paths.append((id, image_path))\n",
    "# #                 self.img_id_mapping[image_path] = id\n",
    "                \n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image_path = self.dir + self.image_paths[idx][1][0] + \"/\" + self.image_paths[idx][1][1] + \"/\" + self.image_paths[idx][1][2] + \"/\" + self.image_paths[idx][1][3] + \"/\" + self.image_paths[idx][1]\n",
    "#         img = Image.open(image_path)\n",
    "#         img = self.transforms(img)\n",
    "        \n",
    "#         return self.image_paths[idx][0], img, self.image_paths[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4bcb011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "last_layer = model_conv._modules.get('avgpool')\n",
    "\n",
    "# transforming each image\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.CenterCrop((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# test_dataset = MyDataset(\"D:/Projects/ML Project/test/\", \"E:/data/test/image.json\", data_transforms)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56c03ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function that hooks to the layer before the FCN in ResNet and extracts the output embedding from it\"\"\"\n",
    "\n",
    "def get_vector(img):\n",
    "    my_embedding = torch.zeros(2048)\n",
    "    \n",
    "    def copy_data(m, i, o):\n",
    "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
    "\n",
    "    h = last_layer.register_forward_hook(copy_data)\n",
    "    model_conv(img)\n",
    "    h.remove()\n",
    "\n",
    "    return my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = []\n",
    "# for i, (id, img, image_name) in enumerate(test_loader):\n",
    "#     emb = get_vector(img[i % 16].unsqueeze(0))\n",
    "#     output.append((id, image_name, emb))\n",
    "#     if len(output) % 1000 == 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b937505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(output, \"test_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file containing preprocessed image and text data\n",
    "# file path to be changed for different embeddings\n",
    "\n",
    "test_file = open('E:/data/test/image.json')\n",
    "test_data = json.load(test_file)\n",
    "test_file.close()\n",
    "output = []\n",
    "\n",
    "# feature extraction logic\n",
    "for row in test_data:\n",
    "    id = row[\"id\"]\n",
    "    for image in row[\"images\"]:\n",
    "        image_path = \"D:/Projects/ML Project/test/\" + image[0] + \"/\" + image[1] + \"/\" + image[2] + \"/\" + image[3] + \"/\" + image\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        transformed_image = data_transforms(img)\n",
    "        emb = get_vector(transformed_image.unsqueeze(0))    \n",
    "        \n",
    "        # store embedding as (id, image_file_name, embedding)\n",
    "        output.append((id, image, emb))\n",
    "        \n",
    "        if len(output) % 1000 == 0:\n",
    "            print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7444608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(output, \"E:/test_emb.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8f2d0",
   "metadata": {},
   "source": [
    "## Text Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fb4a7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE FILENAME HERE\n",
    "test_file = open('E:/data/train/text.json')\n",
    "test_data = json.load(test_file)\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "83de437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonDataset(IterableDataset):\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    def __iter__(self):\n",
    "        for row in self.file:\n",
    "            id = row[\"id\"]\n",
    "            title = row[\"title\"]\n",
    "            ingredients = row[\"ingredients\"]\n",
    "            instructions = row[\"instructions\"]\n",
    "\n",
    "            ingredient_text = \"\"\n",
    "            instructions_text = \"\"\n",
    "\n",
    "            ingredient_text = \" \".join(ingredient[\"text\"] for ingredient in ingredients)\n",
    "            instructions_text = \" \".join(instruction[\"text\"] for instruction in instructions)\n",
    "            \n",
    "            full_text = title + \" \" + ingredient_text + \" \" + instructions_text\n",
    "\n",
    "            yield id, title, ingredient_text, instructions_text, full_text\n",
    "\n",
    "    \n",
    "dataset = JsonDataset(test_data)\n",
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4e50acc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7cc9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "# in case error occurs, a range of rows to start from\n",
    "# batch_start = \n",
    "# batch_end = 100000\n",
    "\n",
    "for (id, title, ingredient_text, instructions_text, full_text) in dataloader:\n",
    "    \n",
    "#     if (counter in range(batch_start, batch_end)):\n",
    "    # encode title\n",
    "    encoded_title = tokenizer(title, return_tensors='pt', max_length=512, truncation = True)\n",
    "    output_title = model(**encoded_title)\n",
    "    output_title = torch.mean(output_title[\"last_hidden_state\"], dim = 1)\n",
    "\n",
    "    with open('E:/train_text_title_6.pkl', 'ab') as f:\n",
    "        pickle.dump((id, output_title.squeeze(0)), f)\n",
    "\n",
    "    # encode ingredients\n",
    "    encoded_ingredients = tokenizer(ingredient_text, return_tensors='pt', max_length=512, truncation = True)\n",
    "    output_ingredients = model(**encoded_ingredients)\n",
    "    output_ingredients = torch.mean(output_ingredients[\"last_hidden_state\"], dim = 1)\n",
    "\n",
    "    with open('E:/train_text_ingredients_6.pkl', 'ab') as f:\n",
    "        pickle.dump((id, output_ingredients.squeeze(0)), f)\n",
    "\n",
    "    # encode instructions\n",
    "    encoded_instructions = tokenizer(instructions_text, return_tensors='pt', max_length=512, truncation = True)\n",
    "    output_instructions = model(**encoded_instructions)\n",
    "    output_instructions = torch.mean(output_instructions[\"last_hidden_state\"], dim = 1)\n",
    "\n",
    "    with open('E:/train_text_instructions_6.pkl', 'ab') as f:\n",
    "        pickle.dump((id, output_instructions.squeeze(0)), f)\n",
    "\n",
    "    #encode everything\n",
    "    encoded_full = tokenizer(full_text, return_tensors='pt', max_length=512, truncation = True)\n",
    "    output_full = model(**encoded_full)\n",
    "    output_full = torch.mean(output_full[\"last_hidden_state\"], dim = 1)\n",
    "\n",
    "    with open('E:/train_text_full_6.pkl', 'ab') as f:\n",
    "        pickle.dump((id, output_full.squeeze(0)), f)\n",
    "\n",
    "    print(counter)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if encodings generated properly\n",
    "emb = []\n",
    "with open('E:/train_text_title_2.pkl', 'rb') as f:\n",
    "    while True:\n",
    "        emb.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29bf49",
   "metadata": {},
   "source": [
    "## Aligning Text Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2c830cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = torch.load(\"E:/train_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cf374e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_val = torch.load(\"E:/val_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "50525ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = torch.load(\"E:/test_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab798657",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test_full = []\n",
    "with open('E:/test_text_full.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_test_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_test_ingredients = []\n",
    "with open('E:/test_text_ingredients.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_test_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_test_instructions = []\n",
    "with open('E:/test_text_instructions.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_test_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_test_title = []\n",
    "with open('E:/test_text_title.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_test_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8da30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_val_title = []\n",
    "with open('E:/val_text_title.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_val_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_val_instructions = []\n",
    "with open('E:/val_text_instructions.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_val_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_val_ingredients = []\n",
    "with open('E:/val_text_ingredients.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_val_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_val_full = []\n",
    "with open('E:/val_text_full.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_val_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f8815",
   "metadata": {},
   "source": [
    "### Test Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fcbc118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 0, 0\n",
    "text_test_full_final = []\n",
    "text_test_ingredients_final = []\n",
    "text_test_instructions_final = []\n",
    "text_test_title_final = []\n",
    "\n",
    "while i < len(img_test):\n",
    "    id = img_test[i][0]\n",
    "\n",
    "    if text_test_full[j][0][0] == id and text_test_ingredients[j][0][0] == id and \\\n",
    "    text_test_instructions[j][0][0] == id and text_test_title[j][0][0] == id:\n",
    "        text_test_full_final.append(text_test_full[j][1])\n",
    "        text_test_ingredients_final.append(text_test_ingredients[j][1])\n",
    "        text_test_instructions_final.append(text_test_instructions[j][1])\n",
    "        text_test_title_final.append(text_test_title[j][1])\n",
    "\n",
    "        i += 1\n",
    "    else:\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2a5ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:/text_test_full_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_test_full_final ,f)\n",
    "with open('E:/text_test_instructions_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_test_instructions_final ,f)\n",
    "with open('E:/text_test_ingredients_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_test_ingredients_final ,f)\n",
    "with open('E:/text_test_title_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_test_title_final ,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57daa58",
   "metadata": {},
   "source": [
    "### Validation Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "490a916f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60422"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_val_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "66313ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133842"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fea234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i, j = 0, 0\n",
    "# text_val_full_final = []\n",
    "text_val_ingredients_final = []\n",
    "text_val_instructions_final = []\n",
    "text_val_title_final = []\n",
    "\n",
    "while i < len(img_val):\n",
    "    id = img_val[i][0]\n",
    "#     print(id, text_val_full[j][0][0])\n",
    "    if text_val_ingredients[j][0][0] == id and \\\n",
    "    text_val_instructions[j][0][0] == id and text_val_title[j][0][0] == id:\n",
    "#         text_val_full_final.append(text_val_full[j][1])\n",
    "        text_val_ingredients_final.append(text_val_ingredients[j][1])\n",
    "        text_val_instructions_final.append(text_val_instructions[j][1])\n",
    "        text_val_title_final.append(text_val_title[j][1])\n",
    "\n",
    "        i += 1\n",
    "    else:\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54d99555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133842"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_val_ingredients_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a6923c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('E:/text_val_full_final.pkl', 'wb') as f:\n",
    "#     pickle.dump(text_val_full_final ,f)\n",
    "with open('E:/text_val_instructions_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_val_instructions_final ,f)\n",
    "with open('E:/text_val_ingredients_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_val_ingredients_final ,f)\n",
    "with open('E:/text_val_title_final.pkl', 'wb') as f:\n",
    "    pickle.dump(text_val_title_final ,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28742682",
   "metadata": {},
   "source": [
    "## Train Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f326772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_title = []\n",
    "with open('E:/train_text_title_1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_title2.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_title_3.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_title_200000.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_title.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "text_train_ingredients = []\n",
    "with open('E:/train_text_ingredients_1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_ingredients2.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_ingredients_3.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_ingredients_200000.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_ingredients.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "text_train_instructions = []\n",
    "with open('E:/train_text_instructions_1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_instructions2.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_instructions_3.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_instructions_200000.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_instructions.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_train_full = []\n",
    "with open('E:/train_text_full_1.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_full2.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_full_3.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass\n",
    "with open('E:/train_text_full_200000.pkl', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            text_train_full.append(pickle.load(f))\n",
    "    except:\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85309bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 0, 0\n",
    "text_train_full_final = []\n",
    "text_train_ingredients_final = []\n",
    "text_train_instructions_final = []\n",
    "text_train_title_final = []\n",
    "\n",
    "while i < len(img_train):\n",
    "    id = img_train[i][0]\n",
    "#     print(id, text_train_full[j][0][0])\n",
    "    if text_train_ingredients[j][0][0] == id and \\\n",
    "    text_train_instructions[j][0][0] == id and text_train_title[j][0][0] == id:\n",
    "        text_train_full_final.append(text_train_full[j][1])\n",
    "        text_train_ingredients_final.append(text_train_ingredients[j][1])\n",
    "        text_train_instructions_final.append(text_train_instructions[j][1])\n",
    "        text_train_title_final.append(text_train_title[j][1])\n",
    "\n",
    "        i += 1\n",
    "    else:\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a084433",
   "metadata": {},
   "source": [
    "## Formatting Image Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8bb31638",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_final = [img_train[i][2] for i in range(len(img_train))]\n",
    "img_val_final = [img_val[i][2] for i in range(len(img_val))]\n",
    "img_test_final = [img_test[i][2] for i in range(len(img_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "618706e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(img_train_final, \"E:/img_train_final.pt\")\n",
    "torch.save(img_val_final, \"E:/img_val_final.pt\")\n",
    "torch.save(img_test_final, \"E:/img_test_final.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee5b0b",
   "metadata": {},
   "source": [
    "## Loading Encodings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoencoder",
   "language": "python",
   "name": "autoencoder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
